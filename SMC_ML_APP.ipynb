{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYRo15yGj33S"
   },
   "outputs": [],
   "source": [
    "# prompt: import python required library for a data analysis\n",
    "# import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hvUOPHeaAvJ"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2RWwsewVKBsw"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UkItsqU2kQ-N"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel('SSL_T.xlsx')\n",
    "# df = pd.read_excel('SSL_T_MR.xlsx')\n",
    "# df = pd.read_excel('SSL_M.xlsx')\n",
    "\n",
    "# df = pd.read_excel('Train.xlsx')\n",
    "# df = pd.read_excel('Test.xlsx')\n",
    "# df = pd.read_excel('Train_Test.xlsx')\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxCj5ma-lYlU"
   },
   "source": [
    "##Overall Ratio Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L5o9rUQov7Lb"
   },
   "outputs": [],
   "source": [
    "def get_feature_data(p_state, index,row):\n",
    "       # Retrieve stats for individual features\n",
    "      row_data = {}\n",
    "      time_15min = row['15Min']\n",
    "      trade_count_15m, pl_15m, win_rate_15m = precomputed_stats[('15Min', time_15min)]\n",
    "      row_data['15Min_Trade Count'] = trade_count_15m\n",
    "      row_data['15Min_Win Rate'] = win_rate_15m\n",
    "      row_data['15Min_Profit/Loss'] = pl_15m\n",
    "\n",
    "      hour = row['Hour']\n",
    "      trade_count_hour, pl_hour, win_rate_hour = precomputed_stats[('Hour', hour)]\n",
    "      row_data['Hour_Trade Count'] = trade_count_hour\n",
    "      row_data['Hour_Win Rate'] = win_rate_hour\n",
    "      row_data['Hour_Profit/Loss'] = pl_hour\n",
    "\n",
    "      weekday = row['Start_Weekday']\n",
    "      trade_count_weekday, pl_weekday, win_rate_weekday = precomputed_stats[('Weekday', weekday)]\n",
    "      row_data['Weekday_Trade Count'] = trade_count_weekday\n",
    "      row_data['Weekday_Win Rate'] = win_rate_weekday\n",
    "      row_data['Weekday_Profit/Loss'] = pl_weekday\n",
    "\n",
    "      month = row['Month']\n",
    "      trade_count_month, pl_month, win_rate_month = precomputed_stats[('Month', month)]\n",
    "      row_data['Month_Trade Count'] = trade_count_month\n",
    "      row_data['Month_Win Rate'] = win_rate_month\n",
    "      row_data['Month_Profit/Loss'] = pl_month\n",
    "\n",
    "      criteria = row['Criteria']\n",
    "      trade_count_criteria, pl_criteria, win_rate_criteria = precomputed_stats[('Criteria', criteria)]\n",
    "      row_data['Criteria_Trade Count'] = trade_count_criteria\n",
    "      row_data['Criteria_Win Rate'] = win_rate_criteria\n",
    "      row_data['Criteria_Profit/Loss'] = pl_criteria\n",
    "\n",
    "\n",
    "      # Retrieve stats for combined features\n",
    "      trade_count_weekday_15m, pl_weekday_15m, win_rate_weekday_15m = precomputed_stats[('Weekday_15Min', weekday, time_15min)]\n",
    "      row_data['Weekday_15Min_Trade Count'] = trade_count_weekday_15m\n",
    "      row_data['Weekday_15Min_Win Rate'] = win_rate_weekday_15m\n",
    "      row_data['Weekday_15Min_Profit/Loss'] = pl_weekday_15m\n",
    "\n",
    "      trade_count_weekday_hour, pl_weekday_hour, win_rate_weekday_hour = precomputed_stats[('Weekday_Hour', weekday, hour)]\n",
    "      row_data['Weekday_Hour_Trade Count'] = trade_count_weekday_hour\n",
    "      row_data['Weekday_Hour_Win Rate'] = win_rate_weekday_hour\n",
    "      row_data['Weekday_Hour_Profit/Loss'] = pl_weekday_hour\n",
    "\n",
    "      trade_count_weekday_month, pl_weekday_month, win_rate_weekday_month = precomputed_stats[('Weekday_Month', weekday, month)]\n",
    "      row_data['Weekday_Month_Trade Count'] = trade_count_weekday_month\n",
    "      row_data['Weekday_Month_Win Rate'] = win_rate_weekday_month\n",
    "      row_data['Weekday_Month_Profit/Loss'] = pl_weekday_month\n",
    "\n",
    "      trade_count_criteria_15m, pl_criteria_15m, win_rate_criteria_15m = precomputed_stats[('Criteria_15Min', criteria, time_15min)]\n",
    "      row_data['Criteria_15Min_Trade Count'] = trade_count_criteria_15m\n",
    "      row_data['Criteria_15Min_Win Rate'] = win_rate_criteria_15m\n",
    "      row_data['Criteria_15Min_Profit/Loss'] = pl_criteria_15m\n",
    "\n",
    "      trade_count_criteria_hour, pl_criteria_hour, win_rate_criteria_hour = precomputed_stats[('Criteria_Hour', criteria, hour)]\n",
    "      row_data['Criteria_Hour_Trade Count'] = trade_count_criteria_hour\n",
    "      row_data['Criteria_Hour_Win Rate'] = win_rate_criteria_hour\n",
    "      row_data['Criteria_Hour_Profit/Loss'] = pl_criteria_hour\n",
    "\n",
    "      trade_count_criteria_weekday, pl_criteria_weekday, win_rate_criteria_weekday = precomputed_stats[('Criteria_Weekday', criteria, weekday)]\n",
    "      row_data['Criteria_Weekday_Trade Count'] = trade_count_criteria_weekday\n",
    "      row_data['Criteria_Weekday_Win Rate'] = win_rate_criteria_weekday\n",
    "      row_data['Criteria_Weekday_Profit/Loss'] = pl_criteria_weekday\n",
    "\n",
    "      trade_count_criteria_month, pl_criteria_month, win_rate_criteria_month = precomputed_stats[('Criteria_Month', criteria, month)]\n",
    "      row_data['Criteria_Month_Trade Count'] = trade_count_criteria_month\n",
    "      row_data['Criteria_Month_Win Rate'] = win_rate_criteria_month\n",
    "      row_data['Criteria_Month_Profit/Loss'] = pl_criteria_month\n",
    "\n",
    "      trade_count_hour_month, pl_hour_month, win_rate_hour_month = precomputed_stats[('Hour_Month', hour, month)]\n",
    "      row_data['Hour_Month_Trade Count'] = trade_count_hour_month\n",
    "      row_data['Hour_Month_Win Rate'] = win_rate_hour_month\n",
    "      row_data['Hour_Month_Profit/Loss'] = pl_hour_month\n",
    "\n",
    "      trade_count_15min_month, pl_15min_month, win_rate_15min_month = precomputed_stats[('15Min_Month', time_15min, month)]\n",
    "      row_data['15Min_Month_Trade Count'] = trade_count_15min_month\n",
    "      row_data['15Min_Month_Win Rate'] = win_rate_15min_month\n",
    "      row_data['15Min_Month_Profit/Loss'] = pl_15min_month\n",
    "\n",
    "      return row_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7rMTsrgZc7Eb"
   },
   "outputs": [],
   "source": [
    "def show_model_result(model_name, accuracy, class_report):\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6HOBC9hrIjA"
   },
   "source": [
    "##Get Train Data From Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9u1ALKrL9kRT"
   },
   "outputs": [],
   "source": [
    "# prompt: get_train_data_for_input(df, time_input, date_input, criteria_input): instead of this get_train_data_for_input_optimized(precompute_stats, time_input, date_input, criteria_input) so that it can take data from precompute state instead of df\n",
    "\n",
    "def get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols=[]):\n",
    "\n",
    "    # Convert inputs\n",
    "    try:\n",
    "        input_time = datetime.datetime.strptime(time_input, '%H:%M').time()\n",
    "    except ValueError:\n",
    "        print(\"Invalid time format. Use HH:MM.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        input_date = datetime.datetime.strptime(date_input, '%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        print(\"Invalid date format. Use M/D/YYYY.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    row_data = {}\n",
    "    input_datetime = datetime.datetime.combine(input_date, input_time)\n",
    "\n",
    "    time_15min = input_datetime.strftime('%H:%M')\n",
    "    hour = input_datetime.hour\n",
    "    weekday = input_datetime.strftime('%A')\n",
    "    month = input_datetime.strftime('%B')\n",
    "    criteria = criteria_input\n",
    "\n",
    "    # Retrieve stats from precomputed_stats dictionary\n",
    "    try:\n",
    "        row = {'15Min': time_15min, 'Hour': hour, 'Start_Weekday': weekday, 'Month': month, 'Criteria': criteria}\n",
    "        row_data = get_feature_data(precomputed_stats, 0, row)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing precomputed statistic for key {e}. Ensure create_precomputed_stats covers all combinations you need.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Create DataFrame from the calculated row_data\n",
    "    input_features_df = pd.DataFrame([row_data])\n",
    "    # Reindex the input_features_df to match the training columns, filling missing with 0\n",
    "    input_features_df = input_features_df.reindex(columns=training_feature_cols, fill_value=0)\n",
    "\n",
    "    # Convert all columns to the same data type as the training features (assuming int from previous steps)\n",
    "    for col in input_features_df.columns:\n",
    "        try:\n",
    "             input_features_df[col] = pd.to_numeric(input_features_df[col], errors='coerce')\n",
    "             input_features_df[col] = input_features_df[col].fillna(0).astype(int)\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not convert input column '{col}' to integer.\")\n",
    "\n",
    "\n",
    "    return input_features_df\n",
    "\n",
    "# Example usage (assuming X_train is defined from the previous code):\n",
    "# Get the column names from your training features DataFrame\n",
    "\n",
    "# Call the optimized function\n",
    "# input_data = get_train_data_for_input_optimized(precomputed_stats, '09:30', '01/8/2023', 'ELC', training_feature_cols)\n",
    "# print(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5V2f13WrWM2"
   },
   "source": [
    "##Show Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bXjEgBs5UmuC"
   },
   "outputs": [],
   "source": [
    "# --- Prediction using the trained model ---\n",
    "def predict_trade_result(model, input_features_df):\n",
    "    \"\"\"\n",
    "    Predicts the result of a trade based on the input features using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: The trained machine learning model.\n",
    "        input_features_df (pd.DataFrame): A DataFrame with one row containing\n",
    "                                          the features for prediction, matching\n",
    "                                          the format of the training features.\n",
    "\n",
    "    Returns:\n",
    "        int: The predicted class (e.g., 1 for Win, 0 for Loss).\n",
    "        float: The predicted probability of the positive class (Win).\n",
    "    \"\"\"\n",
    "    if input_features_df.empty:\n",
    "        print(\"Cannot predict: Invalid input features.\")\n",
    "        return None, None\n",
    "\n",
    "    # Make prediction\n",
    "    predicted_class = model.predict(input_features_df)[0]\n",
    "    if predicted_class == 0:\n",
    "        predicted_proba = model.predict_proba(input_features_df)\n",
    "    else:\n",
    "        predicted_proba = model.predict_proba(input_features_df)\n",
    "\n",
    "    return predicted_class, predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FMTN_xdyVTPP"
   },
   "outputs": [],
   "source": [
    "  # pip install tabulate if needed\n",
    "\n",
    "def show_predictions(time_input, date_input, criteria_input, CW, CL, training_feature_cols, model_names, model_keys,b_models=None, m_models=None, b_acc=None, m_acc=None, Max_R=False, w_threshold=2):\n",
    "    mr = \"_max_r\" if Max_R else \"\"\n",
    "    # Initialize models and their keys\n",
    "    binary_models = b_models if b_models is not None else [globals()[f\"{k}_model{mr}\"] for k in model_keys]\n",
    "    binary_accuracies = b_acc if b_acc is not None else [globals()[f\"{k}_accuracy{mr}\"] for k in model_keys]\n",
    "\n",
    "    multiclass_models = m_models if m_models is not None else [globals()[f\"{k}_model_m{mr}\"] for k in model_keys]\n",
    "    multiclass_accuracies = m_acc if m_acc is not None else [globals()[f\"{k}_accuracy_m{mr}\"] for k in model_keys]\n",
    "\n",
    "    input_features = get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\n",
    "    input_features['CL'] = [CL]\n",
    "    input_features['CW'] = [CW]\n",
    "    predictions = []\n",
    "    predictions_multi = []\n",
    "    if not input_features.empty:\n",
    "        table_data = []\n",
    "\n",
    "        for i, name in enumerate(model_names):\n",
    "            # Predict binary\n",
    "            pred_bin, prob_bin = predict_trade_result(binary_models[i], input_features)\n",
    "            label_bin = 'Win' if pred_bin == 1 else 'Loss'\n",
    "            acc_bin = f\"{binary_accuracies[i]:.2f}\"\n",
    "            bin_str = f\"{label_bin} ({np.max(prob_bin):.2f}), Acc: {acc_bin}\"\n",
    "\n",
    "            # Predict multiclass\n",
    "            pred_multi, prob_multi = predict_trade_result(multiclass_models[i], input_features)\n",
    "            acc_multi = f\"{multiclass_accuracies[i]:.2f}\"\n",
    "            multi_str = f\"Class {label_encoder.inverse_transform([pred_multi])[0]} ({np.max(prob_multi):.2f}), Acc: {acc_multi}\"\n",
    "            table_data.append([name, bin_str, multi_str])\n",
    "            predictions.append(pred_bin)\n",
    "            predictions_multi.append(pred_multi)\n",
    "        predicted_win = predictions.count(1)\n",
    "        predicted_loss = predictions.count(0)\n",
    "        predicted_win_multi = len(predictions)-predictions_multi.count(0)\n",
    "        predicted_loss_multi = predictions_multi.count(0)\n",
    "        trade_decision = \"Win\" if predicted_win > w_threshold else \"Loss\"\n",
    "        trade_decision_multi = \"Win\" if predicted_win_multi >= w_threshold else \"Loss\"\n",
    "        max_r = \"\" if trade_decision_multi == \"Loss\" else \"- Max R: \"+str(np.max(predictions_multi))\n",
    "        avg_r = \"\" if trade_decision_multi == \"Loss\" else \"- Average R:\"+str(np.mean([x for x in predictions_multi if x>0]))\n",
    "        # Display table\n",
    "        print(f\"\\n--- ðŸ“Š Combined Model Predictions for {date_input} {time_input} ({criteria_input}) -{mr} ---\\n\")\n",
    "        print(f\"Overall decision: ---- Binary: ** {trade_decision} **  Multi: ** {trade_decision_multi}** ---- {max_r} {avg_r}\")\n",
    "        print(f\"Binary Models: Win Predicted **{predicted_win} time **    Multi Models: Win Predicted **{predicted_win_multi}**\")\n",
    "        print(tabulate(table_data, headers=[\"Model\", \"ðŸ“˜ Binary (Win/Loss)\", \"ðŸ“— Multi-Class (R Bucket)\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    else:\n",
    "        print(\"âŒ Prediction could not be made due to invalid inputs or data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REMqQ7JqUyi-"
   },
   "source": [
    "#Read Require Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETy_lAgrU44I"
   },
   "source": [
    "##Read Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TlL6vo3JhEe"
   },
   "source": [
    "##Read From Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYbNFeahJcm5"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF4KtKXOH8JJ",
    "outputId": "a7128652-7de4-4081-eb3c-da4b82cf132e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "# prompt: remove SMC directory from my files\n",
    "%cd /content/\n",
    "!rm -rf SMC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFtIkA05JgHj",
    "outputId": "92f70fd5-da52-48c1-9fcd-70917e9d52d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/content/drive/MyDrive/SMC': No such file or directory\n",
      "[Errno 2] No such file or directory: '/content/SMC'\n",
      "/content\n",
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "# Copy SMC folder from Drive to current working directory (optional)\n",
    "!cp -r /content/drive/MyDrive/SMC /content/\n",
    "\n",
    "# Move into the project directory\n",
    "%cd /content/SMC\n",
    "\n",
    "# List contents to confirm\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Oo8913xJjcl"
   },
   "source": [
    "##Read From Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByL4dhZ45eKu",
    "outputId": "516f5f4d-29ac-4d41-98a0-b1fd1e14c63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SMC'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 31 (delta 16), reused 31 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (31/31), 6.73 MiB | 13.71 MiB/s, done.\n",
      "Resolving deltas: 100% (16/16), done.\n",
      "/content/SMC\n",
      "max_r_model_accuracies.xlsx    saved_models\n",
      "precomputed_stats.pkl\t       SSL_T_MR.xlsx\n",
      "README.md\t\t       SSL_T.xlsx\n",
      "regular_model_accuracies.xlsx  training_feature_cols.pkl\n"
     ]
    }
   ],
   "source": [
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/MIARD/SMC.git\n",
    "\n",
    "# Move into the cloned directory\n",
    "%cd SMC\n",
    "\n",
    "# List files to confirm\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7DkoswOLCTP"
   },
   "source": [
    "##Read info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4dI44CFLBwW",
    "outputId": "4ada8fff-73fb-407b-d7d3-55259dfddb78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regular Model Accuracies ---\n",
      "+----+---------------------+-------------------+-----------------------------------+\n",
      "|    | Model               |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
      "|----+---------------------+-------------------+-----------------------------------|\n",
      "|  0 | RandomForest        |          0.878689 |                          0.790164 |\n",
      "|  1 | XGBoost             |          0.852459 |                          0.796721 |\n",
      "|  2 | Logistic Regression |          0.898361 |                          0.829508 |\n",
      "|  3 | Voting Classifier   |          0.885246 |                          0.819672 |\n",
      "|  4 | Stacking Classifier |          0.898361 |                          0.829508 |\n",
      "+----+---------------------+-------------------+-----------------------------------+\n",
      "\n",
      "--- Max R Model Accuracies ---\n",
      "+----+---------------------------+-------------------+-----------------------------------+\n",
      "|    | Model                     |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
      "|----+---------------------------+-------------------+-----------------------------------|\n",
      "|  0 | RandomForest Max R        |          0.878689 |                          0.721311 |\n",
      "|  1 | XGBoost Max R             |          0.852459 |                          0.718033 |\n",
      "|  2 | Logistic Regression Max R |          0.898361 |                          0.731148 |\n",
      "|  3 | Voting Classifier Max R   |          0.885246 |                          0.727869 |\n",
      "|  4 | Stacking Classifier Max R |          0.898361 |                          0.731148 |\n",
      "+----+---------------------------+-------------------+-----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# prompt: read both accuracies from save xlxs and show their tables\n",
    "\n",
    "# Read the saved accuracy dataframes\n",
    "try:\n",
    "  precomputed_stats = joblib.load('precomputed_stats.pkl')\n",
    "  training_feature_cols = joblib.load('training_feature_cols.pkl')\n",
    "  regular_accuracies = pd.read_excel(\"regular_model_accuracies.xlsx\")\n",
    "  max_r_accuracies = pd.read_excel(\"max_r_model_accuracies.xlsx\")\n",
    "\n",
    "  print(\"\\n--- Regular Model Accuracies ---\")\n",
    "  print(tabulate(regular_accuracies, headers='keys', tablefmt='psql'))\n",
    "\n",
    "  print(\"\\n--- Max R Model Accuracies ---\")\n",
    "  print(tabulate(max_r_accuracies, headers='keys', tablefmt='psql'))\n",
    "\n",
    "except FileNotFoundError:\n",
    "  print(\"Accuracy files not found. Please run the model training section first.\")\n",
    "except Exception as e:\n",
    "  print(f\"An error occurred while reading the accuracy files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx9wuV6GJoS4"
   },
   "source": [
    "##Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vtlJirpHqOk",
    "outputId": "cddd9540-a2db-4148-c71b-f7f6e9fb2e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading regular binary models...\n",
      "Loaded RF_model\n",
      "Loaded XVG_model\n",
      "Loaded LR_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:36:24] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\gbm\\../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded VC_model\n",
      "Loaded S_model\n",
      "\n",
      "Loading regular multi-class models...\n",
      "Loaded RF_model_m\n",
      "Loaded XVG_model_m\n",
      "Loaded LR_model_m\n",
      "Loaded VC_model_m\n",
      "Loaded S_model_m\n",
      "\n",
      "Loading Max R binary models...\n",
      "Loaded RF_model_max_r\n",
      "Loaded XVG_model_max_r\n",
      "Loaded LR_model_max_r\n",
      "Loaded VC_model_max_r\n",
      "Loaded S_model_max_r\n",
      "\n",
      "Loading Max R multi-class models...\n",
      "Loaded RF_model_m_max_r\n",
      "Loaded XVG_model_m_max_r\n",
      "Loaded LR_model_m_max_r\n",
      "Loaded VC_model_m_max_r\n",
      "Loaded S_model_m_max_r\n",
      "\n",
      "Loading Label Encoders...\n",
      "Loaded label_encoder\n",
      "Loaded label_encoder_max_r\n"
     ]
    }
   ],
   "source": [
    "# prompt: read all 20 models separately  regular binary, regular multi, max r binary, max r multi, . so that i can pass binary model and multi models list to function easily\n",
    "\n",
    "# Define a directory to save the models\n",
    "model_dir = 'saved_models'\n",
    "\n",
    "# Define lists to store the loaded models\n",
    "regular_binary_models = []\n",
    "regular_multi_models = []\n",
    "max_r_binary_models = []\n",
    "max_r_multi_models = []\n",
    "\n",
    "# List of model base names (keys used in filenames)\n",
    "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
    "\n",
    "# Load regular binary models\n",
    "print(\"Loading regular binary models...\")\n",
    "for key in model_keys:\n",
    "    filename = os.path.join(model_dir, f'{key}_model.pkl')\n",
    "    try:\n",
    "        model = joblib.load(filename)\n",
    "        regular_binary_models.append(model)\n",
    "        print(f\"Loaded {key}_model\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {key}_model.pkl not found. Please run the saving section first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {key}_model: {e}\")\n",
    "\n",
    "# Load regular multi-class models\n",
    "print(\"\\nLoading regular multi-class models...\")\n",
    "for key in model_keys:\n",
    "    filename = os.path.join(model_dir, f'{key}_model_m.pkl')\n",
    "    try:\n",
    "        model = joblib.load(filename)\n",
    "        regular_multi_models.append(model)\n",
    "        print(f\"Loaded {key}_model_m\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {key}_model_m.pkl not found. Please run the saving section first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {key}_model_m: {e}\")\n",
    "\n",
    "# Load max R binary models\n",
    "print(\"\\nLoading Max R binary models...\")\n",
    "for key in model_keys:\n",
    "    filename = os.path.join(model_dir, f'{key}_model_max_r.pkl')\n",
    "    try:\n",
    "        model = joblib.load(filename)\n",
    "        max_r_binary_models.append(model)\n",
    "        print(f\"Loaded {key}_model_max_r\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {key}_model_max_r.pkl not found. Please run the saving section first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {key}_model_max_r: {e}\")\n",
    "\n",
    "# Load max R multi-class models\n",
    "print(\"\\nLoading Max R multi-class models...\")\n",
    "for key in model_keys:\n",
    "    filename = os.path.join(model_dir, f'{key}_model_m_max_r.pkl')\n",
    "    try:\n",
    "        model = joblib.load(filename)\n",
    "        max_r_multi_models.append(model)\n",
    "        print(f\"Loaded {key}_model_m_max_r\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {key}_model_m_max_r.pkl not found. Please run the saving section first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {key}_model_m_max_r: {e}\")\n",
    "\n",
    "# Load Label Encoders\n",
    "print(\"\\nLoading Label Encoders...\")\n",
    "try:\n",
    "    label_encoder = joblib.load(os.path.join(model_dir, 'label_encoder.pkl'))\n",
    "    print(\"Loaded label_encoder\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: label_encoder.pkl not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading label_encoder: {e}\")\n",
    "\n",
    "try:\n",
    "    label_encoder_max_r = joblib.load(os.path.join(model_dir, 'label_encoder_max_r.pkl'))\n",
    "    print(\"Loaded label_encoder_max_r\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: label_encoder_max_r.pkl not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading label_encoder_max_r: {e}\")\n",
    "\n",
    "\n",
    "# Now you have the models loaded into these lists:\n",
    "# regular_binary_models\n",
    "# regular_multi_models\n",
    "# max_r_binary_models\n",
    "# max_r_multi_models\n",
    "\n",
    "# You can pass these lists to other functions as needed.\n",
    "# For example, you could create a function that takes a list of models and a dataframe\n",
    "# and performs predictions or evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcKc6Ob3JsIO"
   },
   "source": [
    "##Prediction App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/29/2025\n",
      "15:39\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now(datetime.UTC).strftime('%m/%d/%Y'))\n",
    "print(datetime.datetime.now(datetime.UTC).strftime('%H:%M'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2zJXVA3f_TA",
    "outputId": "28b45d96-35d4-4c8e-95d7-24e8b67a96c9"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'strptime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model_names_max_r \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVoting Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStacking Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m model_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXVG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names, model_keys, b_models\u001b[38;5;241m=\u001b[39mregular_binary_models, m_models\u001b[38;5;241m=\u001b[39mregular_multi_models, b_acc\u001b[38;5;241m=\u001b[39mregular_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinary Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], m_acc\u001b[38;5;241m=\u001b[39mregular_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti-Class (R Bucket) Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names_max_r, model_keys, b_models\u001b[38;5;241m=\u001b[39mmax_r_binary_models, m_models\u001b[38;5;241m=\u001b[39mmax_r_multi_models, b_acc\u001b[38;5;241m=\u001b[39mmax_r_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinary Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], m_acc\u001b[38;5;241m=\u001b[39mmax_r_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti-Class (R Bucket) Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], Max_R\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mshow_predictions\u001b[1;34m(time_input, date_input, criteria_input, CW, CL, training_feature_cols, model_names, model_keys, b_models, m_models, b_acc, m_acc, Max_R, w_threshold)\u001b[0m\n\u001b[0;32m      9\u001b[0m multiclass_models \u001b[38;5;241m=\u001b[39m m_models \u001b[38;5;28;01mif\u001b[39;00m m_models \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model_m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_keys]\n\u001b[0;32m     10\u001b[0m multiclass_accuracies \u001b[38;5;241m=\u001b[39m m_acc \u001b[38;5;28;01mif\u001b[39;00m m_acc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_accuracy_m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_keys]\n\u001b[1;32m---> 12\u001b[0m input_features \u001b[38;5;241m=\u001b[39m get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\n\u001b[0;32m     13\u001b[0m input_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [CL]\n\u001b[0;32m     14\u001b[0m input_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCW\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [CW]\n",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mget_train_data_for_input\u001b[1;34m(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_train_data_for_input\u001b[39m(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols\u001b[38;5;241m=\u001b[39m[]):\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert inputs\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m         input_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(time_input, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid time format. Use HH:MM.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'strptime'"
     ]
    }
   ],
   "source": [
    "# time_input = \"15:00\"  #@param {type:\"string\"}\n",
    "# date_input = \"6/29/2025\"  #@param {type:\"string\"}\n",
    "# criteria_input = \"LG RGC\"  #@param {type:\"string\"}\n",
    "# CW = 0 #@param {type:\"integer\"}\n",
    "# CL = 3 #@param {type:\"integer\"}\n",
    "\n",
    "time_input = \"15:45\"  #@param {type:\"string\"}\n",
    "date_input = datetime.datetime.now(datetime.UTC).strftime('%m/%d/%Y')  #@param {type:\"string\"}\n",
    "criteria_input = \"ELC\"  #@param {type:\"string\"}\n",
    "CW = 0 #@param {type:\"integer\"}\n",
    "CL = 3 #@param {type:\"integer\"}\n",
    "\n",
    "model_names = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
    "model_names_max_r = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
    "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
    "\n",
    "show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names, model_keys, b_models=regular_binary_models, m_models=regular_multi_models, b_acc=regular_accuracies['Binary Accuracy'], m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names_max_r, model_keys, b_models=max_r_binary_models, m_models=max_r_multi_models, b_acc=max_r_accuracies['Binary Accuracy'], m_acc=max_r_accuracies['Multi-Class (R Bucket) Accuracy'], Max_R=True)\n",
    "# List of predictions from the trained models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2ifFdTqpKwG0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudioop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:14\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maudioop\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'audioop'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_trading\u001b[39m(time_input, date_input, criteria_input, CW, CL):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Your existing code: preprocess, predict, return result text\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     result_text \u001b[38;5;241m=\u001b[39m show_predictions(time_input, date_input, criteria_input, CW, CL,\n\u001b[0;32m      6\u001b[0m                                    training_feature_cols, model_names, model_keys,\n\u001b[0;32m      7\u001b[0m                                    b_models\u001b[38;5;241m=\u001b[39mregular_binary_models, m_models\u001b[38;5;241m=\u001b[39mregular_multi_models,\n\u001b[0;32m      8\u001b[0m                                    b_acc\u001b[38;5;241m=\u001b[39mregular_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinary Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m                                    m_acc\u001b[38;5;241m=\u001b[39mregular_accuracies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti-Class (R Bucket) Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpkgutil\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomponents\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minputs\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moutputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\components.py:51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m _Image  \u001b[38;5;66;03m# using _ to minimize namespace pollution\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m media_data, processing_utils, utils\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Block, BlockContext\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m document, set_documentation_group\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\processing_utils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     19\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ignore pydub warning if ffmpeg is not installed\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#########################\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# GENERAL\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#########################\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_binary\u001b[39m(x: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pydub\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_segment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pydub\\audio_segment.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_conversion, log_subprocess_output\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mediainfo_json, fsdecode\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maudioop\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyaudioop\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maudioop\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     19\u001b[0m     basestring \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudioop'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict_trading(time_input, date_input, criteria_input, CW, CL):\n",
    "    # Your existing code: preprocess, predict, return result text\n",
    "    result_text = show_predictions(time_input, date_input, criteria_input, CW, CL,\n",
    "                                   training_feature_cols, model_names, model_keys,\n",
    "                                   b_models=regular_binary_models, m_models=regular_multi_models,\n",
    "                                   b_acc=regular_accuracies['Binary Accuracy'],\n",
    "                                   m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'])\n",
    "    return result_text\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=predict_trading,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Time\"),\n",
    "        gr.Textbox(label=\"Date\"),\n",
    "        gr.Textbox(label=\"Criteria\"),\n",
    "        gr.Number(label=\"CW\"),\n",
    "        gr.Number(label=\"CL\")\n",
    "    ],\n",
    "    outputs=\"text\"\n",
    ")\n",
    "\n",
    "app.launch(share=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
