{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIARD/SMC/blob/main/SMC_ML_APP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYRo15yGj33S"
      },
      "outputs": [],
      "source": [
        "# prompt: import python required library for a data analysis\n",
        "# import time\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import plotly.express as px\n",
        "# import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hvUOPHeaAvJ"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.feature_selection import RFE\n",
        "# from sklearn.ensemble import VotingClassifier\n",
        "# from sklearn.ensemble import StackingClassifier\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2RWwsewVKBsw"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UkItsqU2kQ-N"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_excel('SSL_T.xlsx')\n",
        "# df = pd.read_excel('SSL_T_MR.xlsx')\n",
        "# df = pd.read_excel('SSL_M.xlsx')\n",
        "\n",
        "# df = pd.read_excel('Train.xlsx')\n",
        "# df = pd.read_excel('Test.xlsx')\n",
        "# df = pd.read_excel('Train_Test.xlsx')\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxCj5ma-lYlU"
      },
      "source": [
        "##Overall Ratio Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L5o9rUQov7Lb"
      },
      "outputs": [],
      "source": [
        "# prompt: change get_feature_data function according to get_precomputed_stats just add code to get feature data so that it add new features as well\n",
        "\n",
        "def get_feature_data(p_state, index, row):\n",
        "    # Retrieve stats for individual features\n",
        "    row_data = {}\n",
        "    time_15min = row['15Min']\n",
        "    trade_count_15m, pl_15m, win_rate_15m = precomputed_stats[('15Min', time_15min)]\n",
        "    row_data['15Min_Trade Count'] = trade_count_15m\n",
        "    row_data['15Min_Win Rate'] = win_rate_15m\n",
        "    row_data['15Min_Profit/Loss'] = pl_15m\n",
        "\n",
        "    hour = row['Hour']\n",
        "    trade_count_hour, pl_hour, win_rate_hour = precomputed_stats[('Hour', hour)]\n",
        "    row_data['Hour_Trade Count'] = trade_count_hour\n",
        "    row_data['Hour_Win Rate'] = win_rate_hour\n",
        "    row_data['Hour_Profit/Loss'] = pl_hour\n",
        "    weekday = row['Start_Weekday']\n",
        "    trade_count_weekday, pl_weekday, win_rate_weekday = precomputed_stats[('Weekday', weekday)]\n",
        "    row_data['Weekday_Trade Count'] = trade_count_weekday\n",
        "    row_data['Weekday_Win Rate'] = win_rate_weekday\n",
        "    row_data['Weekday_Profit/Loss'] = pl_weekday\n",
        "\n",
        "    month = row['Month']\n",
        "    trade_count_month, pl_month, win_rate_month = precomputed_stats[('Month', month)]\n",
        "    row_data['Month_Trade Count'] = trade_count_month\n",
        "    row_data['Month_Win Rate'] = win_rate_month\n",
        "    row_data['Month_Profit/Loss'] = pl_month\n",
        "\n",
        "    criteria = row['Criteria']\n",
        "    trade_count_criteria, pl_criteria, win_rate_criteria = precomputed_stats[('Criteria', criteria)]\n",
        "    row_data['Criteria_Trade Count'] = trade_count_criteria\n",
        "    row_data['Criteria_Win Rate'] = win_rate_criteria\n",
        "    row_data['Criteria_Profit/Loss'] = pl_criteria\n",
        "\n",
        "    # Add features for Day of Month and Week of Month\n",
        "    day_of_month = row['Day_of_Month']\n",
        "    trade_count_day, pl_day, win_rate_day = precomputed_stats[('Day_of_Month', day_of_month)]\n",
        "    row_data['Day_of_Month_Trade Count'] = trade_count_day\n",
        "    row_data['Day_of_Month_Win Rate'] = win_rate_day\n",
        "    row_data['Day_of_Month_Profit/Loss'] = pl_day\n",
        "\n",
        "    week_of_month = row['Week_of_Month']\n",
        "    trade_count_week, pl_week, win_rate_week = precomputed_stats[('Week_of_Month', week_of_month)]\n",
        "    row_data['Week_of_Month_Trade Count'] = trade_count_week\n",
        "    row_data['Week_of_Month_Win Rate'] = win_rate_week\n",
        "    row_data['Week_of_Month_Profit/Loss'] = pl_week\n",
        "\n",
        "    # Retrieve stats for combined features\n",
        "    trade_count_weekday_15m, pl_weekday_15m, win_rate_weekday_15m = precomputed_stats[('Weekday_15Min', weekday, time_15min)]\n",
        "    row_data['Weekday_15Min_Trade Count'] = trade_count_weekday_15m\n",
        "    row_data['Weekday_15Min_Win Rate'] = win_rate_weekday_15m\n",
        "    row_data['Weekday_15Min_Profit/Loss'] = pl_weekday_15m\n",
        "\n",
        "    trade_count_weekday_hour, pl_weekday_hour, win_rate_weekday_hour = precomputed_stats[('Weekday_Hour', weekday, hour)]\n",
        "    row_data['Weekday_Hour_Trade Count'] = trade_count_weekday_hour\n",
        "    row_data['Weekday_Hour_Win Rate'] = win_rate_weekday_hour\n",
        "    row_data['Weekday_Hour_Profit/Loss'] = pl_weekday_hour\n",
        "\n",
        "    trade_count_weekday_month, pl_weekday_month, win_rate_weekday_month = precomputed_stats[('Weekday_Month', weekday, month)]\n",
        "    row_data['Weekday_Month_Trade Count'] = trade_count_weekday_month\n",
        "    row_data['Weekday_Month_Win Rate'] = win_rate_weekday_month\n",
        "    row_data['Weekday_Month_Profit/Loss'] = pl_weekday_month\n",
        "\n",
        "    trade_count_criteria_15m, pl_criteria_15m, win_rate_criteria_15m = precomputed_stats[('Criteria_15Min', criteria, time_15min)]\n",
        "    row_data['Criteria_15Min_Trade Count'] = trade_count_criteria_15m\n",
        "    row_data['Criteria_15Min_Win Rate'] = win_rate_criteria_15m\n",
        "    row_data['Criteria_15Min_Profit/Loss'] = pl_criteria_15m\n",
        "\n",
        "    trade_count_criteria_hour, pl_criteria_hour, win_rate_criteria_hour = precomputed_stats[('Criteria_Hour', criteria, hour)]\n",
        "    row_data['Criteria_Hour_Trade Count'] = trade_count_criteria_hour\n",
        "    row_data['Criteria_Hour_Win Rate'] = win_rate_criteria_hour\n",
        "    row_data['Criteria_Hour_Profit/Loss'] = pl_criteria_hour\n",
        "\n",
        "    trade_count_criteria_weekday, pl_criteria_weekday, win_rate_criteria_weekday = precomputed_stats[('Criteria_Weekday', criteria, weekday)]\n",
        "    row_data['Criteria_Weekday_Trade Count'] = trade_count_criteria_weekday\n",
        "    row_data['Criteria_Weekday_Win Rate'] = win_rate_criteria_weekday\n",
        "    row_data['Criteria_Weekday_Profit/Loss'] = pl_criteria_weekday\n",
        "\n",
        "    trade_count_criteria_month, pl_criteria_month, win_rate_criteria_month = precomputed_stats[('Criteria_Month', criteria, month)]\n",
        "    row_data['Criteria_Month_Trade Count'] = trade_count_criteria_month\n",
        "    row_data['Criteria_Month_Win Rate'] = win_rate_criteria_month\n",
        "    row_data['Criteria_Month_Profit/Loss'] = pl_criteria_month\n",
        "\n",
        "    trade_count_hour_month, pl_hour_month, win_rate_hour_month = precomputed_stats[('Hour_Month', hour, month)]\n",
        "    row_data['Hour_Month_Trade Count'] = trade_count_hour_month\n",
        "    row_data['Hour_Month_Win Rate'] = win_rate_hour_month\n",
        "    row_data['Hour_Month_Profit/Loss'] = pl_hour_month\n",
        "\n",
        "    trade_count_15min_month, pl_15min_month, win_rate_15min_month = precomputed_stats[('15Min_Month', time_15min, month)]\n",
        "    row_data['15Min_Month_Trade Count'] = trade_count_15min_month\n",
        "    row_data['15Min_Month_Win Rate'] = win_rate_15min_month\n",
        "    row_data['15Min_Month_Profit/Loss'] = pl_15min_month\n",
        "\n",
        "    # Add combined features for Day of Month and Week of Month\n",
        "    trade_count_weekday_day, pl_weekday_day, win_rate_weekday_day = precomputed_stats[('Weekday_Day', weekday, day_of_month)]\n",
        "    row_data['Weekday_Day_Trade Count'] = trade_count_weekday_day\n",
        "    row_data['Weekday_Day_Win Rate'] = win_rate_weekday_day\n",
        "    row_data['Weekday_Day_Profit/Loss'] = pl_weekday_day\n",
        "\n",
        "    trade_count_weekday_week, pl_weekday_week, win_rate_weekday_week = precomputed_stats[('Weekday_Week', weekday, week_of_month)]\n",
        "    row_data['Weekday_Week_Trade Count'] = trade_count_weekday_week\n",
        "    row_data['Weekday_Week_Win Rate'] = win_rate_weekday_week\n",
        "    row_data['Weekday_Week_Profit/Loss'] = pl_weekday_week\n",
        "\n",
        "    trade_count_criteria_day, pl_criteria_day, win_rate_criteria_day = precomputed_stats[('Criteria_Day', criteria, day_of_month)]\n",
        "    row_data['Criteria_Day_Trade Count'] = trade_count_criteria_day\n",
        "    row_data['Criteria_Day_Win Rate'] = win_rate_criteria_day\n",
        "    row_data['Criteria_Day_Profit/Loss'] = pl_criteria_day\n",
        "\n",
        "    trade_count_criteria_week, pl_criteria_week, win_rate_criteria_week = precomputed_stats[('Criteria_Week', criteria, week_of_month)]\n",
        "    row_data['Criteria_Week_Trade Count'] = trade_count_criteria_week\n",
        "    row_data['Criteria_Week_Win Rate'] = win_rate_criteria_week\n",
        "    row_data['Criteria_Week_Profit/Loss'] = pl_criteria_week\n",
        "\n",
        "    trade_count_hour_day, pl_hour_day, win_rate_hour_day = precomputed_stats[('Hour_Day', hour, day_of_month)]\n",
        "    row_data['Hour_Day_Trade Count'] = trade_count_hour_day\n",
        "    row_data['Hour_Day_Win Rate'] = win_rate_hour_day\n",
        "    row_data['Hour_Day_Profit/Loss'] = pl_hour_day\n",
        "\n",
        "    trade_count_hour_week, pl_hour_week, win_rate_hour_week = precomputed_stats[('Hour_Week', hour, week_of_month)]\n",
        "    row_data['Hour_Week_Trade Count'] = trade_count_hour_week\n",
        "    row_data['Hour_Week_Win Rate'] = win_rate_hour_week\n",
        "    row_data['Hour_Week_Profit/Loss'] = pl_hour_week\n",
        "\n",
        "    trade_count_15min_day, pl_15min_day, win_rate_15min_day = precomputed_stats[('15Min_Day', time_15min, day_of_month)]\n",
        "    row_data['15Min_Day_Trade Count'] = trade_count_15min_day\n",
        "    row_data['15Min_Day_Win Rate'] = win_rate_15min_day\n",
        "    row_data['15Min_Day_Profit/Loss'] = pl_15min_day\n",
        "\n",
        "    trade_count_15min_week, pl_15min_week, win_rate_15min_week = precomputed_stats[('15Min_Week', time_15min, week_of_month)]\n",
        "    row_data['15Min_Week_Trade Count'] = trade_count_15min_week\n",
        "    row_data['15Min_Week_Win Rate'] = win_rate_15min_week\n",
        "    row_data['15Min_Week_Profit/Loss'] = pl_15min_week\n",
        "\n",
        "    trade_count_month_day, pl_month_day, win_rate_month_day = precomputed_stats[('Month_Day', month, day_of_month)]\n",
        "    row_data['Month_Day_Trade Count'] = trade_count_month_day\n",
        "    row_data['Month_Day_Win Rate'] = win_rate_month_day\n",
        "    row_data['Month_Day_Profit/Loss'] = pl_month_day\n",
        "\n",
        "    trade_count_month_week, pl_month_week, win_rate_month_week = precomputed_stats[('Month_Week', month, week_of_month)]\n",
        "    row_data['Month_Week_Trade Count'] = trade_count_month_week\n",
        "    row_data['Month_Week_Win Rate'] = win_rate_month_week\n",
        "    row_data['Month_Week_Profit/Loss'] = pl_month_week\n",
        "\n",
        "    trade_count_day_week, pl_day_week, win_rate_day_week = precomputed_stats[('Day_Week', day_of_month, week_of_month)]\n",
        "    row_data['Day_Week_Trade Count'] = trade_count_day_week\n",
        "    row_data['Day_Week_Win Rate'] = win_rate_day_week\n",
        "    row_data['Day_Week_Profit/Loss'] = pl_day_week\n",
        "\n",
        "    return row_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7rMTsrgZc7Eb"
      },
      "outputs": [],
      "source": [
        "def show_model_result(model_name, accuracy, class_report):\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6HOBC9hrIjA"
      },
      "source": [
        "##Get Train Data From Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9u1ALKrL9kRT"
      },
      "outputs": [],
      "source": [
        "# prompt: get_train_data_for_input(df, time_input, date_input, criteria_input): instead of this get_train_data_for_input_optimized(precompute_stats, time_input, date_input, criteria_input) so that it can take data from precompute state instead of df\n",
        "\n",
        "def get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols=[]):\n",
        "\n",
        "    # Convert inputs\n",
        "    try:\n",
        "        input_time = datetime.strptime(time_input, '%H:%M').time()\n",
        "    except ValueError:\n",
        "        print(\"Invalid time format. Use HH:MM.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        input_date = datetime.strptime(date_input, '%m/%d/%Y')\n",
        "    except ValueError:\n",
        "        print(\"Invalid date format. Use M/D/YYYY.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    row_data = {}\n",
        "    input_datetime = datetime.combine(input_date, input_time)\n",
        "\n",
        "    time_15min = input_datetime.strftime('%H:%M')\n",
        "    hour = input_datetime.hour\n",
        "    weekday = input_datetime.strftime('%A')\n",
        "    month = input_datetime.strftime('%B')\n",
        "    criteria = criteria_input\n",
        "    day_of_month = input_datetime.day\n",
        "    week_of_month = (input_datetime.day - 1) // 7 + 1\n",
        "\n",
        "    # Retrieve stats from precomputed_stats dictionary\n",
        "    try:\n",
        "        row = {'15Min': time_15min, 'Hour': hour, 'Start_Weekday': weekday, 'Month': month, 'Criteria': criteria, 'Day_of_Month':day_of_month, 'Week_of_Month':week_of_month}\n",
        "        row_data = get_feature_data(precomputed_stats, 0, row)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Missing precomputed statistic for key {e}. Ensure create_precomputed_stats covers all combinations you need.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Create DataFrame from the calculated row_data\n",
        "    input_features_df = pd.DataFrame([row_data])\n",
        "    # Reindex the input_features_df to match the training columns, filling missing with 0\n",
        "    input_features_df = input_features_df.reindex(columns=training_feature_cols, fill_value=0)\n",
        "\n",
        "    # Convert all columns to the same data type as the training features (assuming int from previous steps)\n",
        "    for col in input_features_df.columns:\n",
        "        try:\n",
        "             input_features_df[col] = pd.to_numeric(input_features_df[col], errors='coerce')\n",
        "             input_features_df[col] = input_features_df[col].fillna(0).astype(int)\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Could not convert input column '{col}' to integer.\")\n",
        "\n",
        "\n",
        "    return input_features_df\n",
        "\n",
        "# Example usage (assuming X_train is defined from the previous code):\n",
        "# Get the column names from your training features DataFrame\n",
        "\n",
        "# Call the optimized function\n",
        "# input_data = get_train_data_for_input_optimized(precomputed_stats, '09:30', '01/8/2023', 'ELC', training_feature_cols)\n",
        "# print(input_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5V2f13WrWM2"
      },
      "source": [
        "##Show Prediciton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bXjEgBs5UmuC"
      },
      "outputs": [],
      "source": [
        "# --- Prediction using the trained model ---\n",
        "def predict_trade_result(model, input_features_df):\n",
        "    \"\"\"\n",
        "    Predicts the result of a trade based on the input features using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained machine learning model.\n",
        "        input_features_df (pd.DataFrame): A DataFrame with one row containing\n",
        "                                          the features for prediction, matching\n",
        "                                          the format of the training features.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted class (e.g., 1 for Win, 0 for Loss).\n",
        "        float: The predicted probability of the positive class (Win).\n",
        "    \"\"\"\n",
        "    if input_features_df.empty:\n",
        "        print(\"Cannot predict: Invalid input features.\")\n",
        "        return None, None\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_class = model.predict(input_features_df)[0]\n",
        "    if predicted_class == 0:\n",
        "        predicted_proba = model.predict_proba(input_features_df)\n",
        "    else:\n",
        "        predicted_proba = model.predict_proba(input_features_df)\n",
        "\n",
        "    return predicted_class, predicted_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FMTN_xdyVTPP"
      },
      "outputs": [],
      "source": [
        "  # pip install tabulate if needed\n",
        "\n",
        "def show_predictions(time_input, date_input, criteria_input, CW, CL, training_feature_cols,model_names, model_keys, precomputed_stats=None,label_encoder=None, b_models=None, m_models=None, b_acc=None, m_acc=None, Max_R=False, s_print=True, w_threshold=1):\n",
        "    mr = \"_max_r\" if Max_R else \"\"\n",
        "    # Initialize models and their keys\n",
        "    binary_models = b_models if b_models is not None else [globals()[f\"{k}_model{mr}\"] for k in model_keys]\n",
        "    binary_accuracies = b_acc if b_acc is not None else [globals()[f\"{k}_accuracy{mr}\"] for k in model_keys]\n",
        "\n",
        "    multiclass_models = m_models if m_models is not None else [globals()[f\"{k}_model_m{mr}\"] for k in model_keys]\n",
        "    multiclass_accuracies = m_acc if m_acc is not None else [globals()[f\"{k}_accuracy_m{mr}\"] for k in model_keys]\n",
        "    input_features = get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\n",
        "    input_features['CL'] = [CL]\n",
        "    input_features['CW'] = [CW]\n",
        "    predictions = []\n",
        "    predictions_multi = []\n",
        "    if not input_features.empty:\n",
        "        table_data = []\n",
        "\n",
        "        for i, name in enumerate(model_names):\n",
        "            # Predict binary\n",
        "            pred_bin, prob_bin = predict_trade_result(binary_models[i], input_features)\n",
        "            label_bin = 'Win' if pred_bin == 1 else 'Loss'\n",
        "            acc_bin = f\"{binary_accuracies[i]:.2f}\"\n",
        "            bin_str = f\"{label_bin} ({np.max(prob_bin):.2f}), Acc: {acc_bin}\"\n",
        "\n",
        "            # Predict multiclass\n",
        "            pred_multi, prob_multi = predict_trade_result(multiclass_models[i], input_features)\n",
        "            acc_multi = f\"{multiclass_accuracies[i]:.2f}\"\n",
        "            multi_str = f\"Class {label_encoder.inverse_transform([pred_multi])[0]} ({np.max(prob_multi):.2f}), Acc: {acc_multi}\"\n",
        "            table_data.append([name, bin_str, multi_str])\n",
        "            predictions.append(pred_bin)\n",
        "            predictions_multi.append(pred_multi)\n",
        "        predicted_win = predictions.count(1)\n",
        "        predicted_loss = predictions.count(0)\n",
        "        predicted_win_multi = len(predictions)-predictions_multi.count(0)\n",
        "        predicted_loss_multi = predictions_multi.count(0)\n",
        "        trade_decision = \"Win\" if predicted_win > w_threshold else \"Loss\"\n",
        "        trade_decision_multi = \"Win\" if predicted_win_multi >= w_threshold else \"Loss\"\n",
        "        max_r = \"\" if trade_decision_multi == \"Loss\" else \"- Max R: \"+str(np.max(predictions_multi))\n",
        "        avg_r = \"\" if trade_decision_multi == \"Loss\" else \"- Average R:\"+str(np.mean([x for x in predictions_multi if x>0]))\n",
        "        # Display table\n",
        "        if s_print:\n",
        "            print(f\"\\n--- 📊 Combined Model Predictions for {date_input} {time_input} ({criteria_input}) -{mr} ---\\n\")\n",
        "            print(f\"Overall decision: ---- Binary: ** {trade_decision} **  Multi: ** {trade_decision_multi}** ---- {max_r} {avg_r}\")\n",
        "            print(f\"Binary Models: Win Predicted **{predicted_win} time **    Multi Models: Win Predicted **{predicted_win_multi}**\")\n",
        "            print(tabulate(table_data, headers=[\"Model\", \"📘 Binary (Win/Loss)\", \"📗 Multi-Class (R Bucket)\"], tablefmt=\"fancy_grid\"))\n",
        "        return predictions, predictions_multi\n",
        "\n",
        "    else:\n",
        "        print(\"❌ Prediction could not be made due to invalid inputs or data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REMqQ7JqUyi-"
      },
      "source": [
        "#Read Require Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETy_lAgrU44I"
      },
      "source": [
        "##Read Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TlL6vo3JhEe"
      },
      "source": [
        "##Read From Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYbNFeahJcm5"
      },
      "outputs": [],
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF4KtKXOH8JJ"
      },
      "outputs": [],
      "source": [
        "# # prompt: remove SMC directory from my files\n",
        "# %cd /content/\n",
        "# !rm -rf SMC/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFtIkA05JgHj"
      },
      "outputs": [],
      "source": [
        "# Copy SMC folder from Drive to current working directory (optional)\n",
        "# !cp -r /content/drive/MyDrive/SMC /content/\n",
        "# %cd /content/SMC\n",
        "\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo8913xJjcl"
      },
      "source": [
        "##Read From Git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByL4dhZ45eKu",
        "outputId": "a0c3a477-74f2-4d19-aa30-2a962c747686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SMC'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 137 (delta 92), reused 110 (delta 72), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (137/137), 35.53 MiB | 8.01 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "Updating files: 100% (64/64), done.\n",
            "/content/SMC\n",
            "cmd_arg.txt    README.md\t\tSMC_ML_APP.ipynb  SSL_T_MR.xlsx\n",
            "Get_EMA.ipynb  saved_models\t\tsmc_ml_app.py\t  SSL_T.xlsx\n",
            "get-pip.py     SMC_Data_Analysis.ipynb\tSMC_ML.ipynb\n",
            "old_models     smc_data_analysis.py\tsmc_ml.py\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/MIARD/SMC.git\n",
        "\n",
        "# Move into the cloned directory\n",
        "%cd SMC\n",
        "\n",
        "# List files to confirm\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7DkoswOLCTP"
      },
      "source": [
        "##Read info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "o4dI44CFLBwW"
      },
      "outputs": [],
      "source": [
        "# prompt: read both accuracies from save xlxs and show their tables\n",
        "\n",
        "# Read the saved accuracy dataframes\n",
        "def read_accuracy_dataframes(file_dir):\n",
        "    try:\n",
        "      precomputed_stats = joblib.load(f'{file_dir}/precomputed_stats.pkl')\n",
        "      training_feature_cols = joblib.load(f'{file_dir}/training_feature_cols.pkl')\n",
        "      regular_accuracies = pd.read_excel(f'{file_dir}/regular_model_accuracies.xlsx')\n",
        "      max_r_accuracies = pd.read_excel(f'{file_dir}/max_r_model_accuracies.xlsx')\n",
        "\n",
        "      print(\"\\n--- Regular Model Accuracies ---\")\n",
        "      print(tabulate(regular_accuracies, headers='keys', tablefmt='psql'))\n",
        "\n",
        "      print(\"\\n--- Max R Model Accuracies ---\")\n",
        "      print(tabulate(max_r_accuracies, headers='keys', tablefmt='psql'))\n",
        "\n",
        "      return precomputed_stats, training_feature_cols, regular_accuracies, max_r_accuracies\n",
        "\n",
        "    except FileNotFoundError:\n",
        "      print(\"Accuracy files not found. Please run the model training section first.\")\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred while reading the accuracy files: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpRs1PQ43C2u",
        "outputId": "e5b741e7-d1e2-4f82-c9fa-a077c9d5500f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Regular Model Accuracies ---\n",
            "+----+---------------------+-------------------+-----------------------------------+\n",
            "|    | Model               |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
            "|----+---------------------+-------------------+-----------------------------------|\n",
            "|  0 | RandomForest        |          0.957792 |                          0.863636 |\n",
            "|  1 | XGBoost             |          0.961039 |                          0.87987  |\n",
            "|  2 | Logistic Regression |          0.970779 |                          0.863636 |\n",
            "|  3 | Voting Classifier   |          0.961039 |                          0.876623 |\n",
            "|  4 | Stacking Classifier |          0.964286 |                          0.873377 |\n",
            "+----+---------------------+-------------------+-----------------------------------+\n",
            "\n",
            "--- Max R Model Accuracies ---\n",
            "+----+---------------------------+-------------------+-----------------------------------+\n",
            "|    | Model                     |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
            "|----+---------------------------+-------------------+-----------------------------------|\n",
            "|  0 | RandomForest Max R        |          0.957792 |                          0.766234 |\n",
            "|  1 | XGBoost Max R             |          0.961039 |                          0.753247 |\n",
            "|  2 | Logistic Regression Max R |          0.970779 |                          0.753247 |\n",
            "|  3 | Voting Classifier Max R   |          0.961039 |                          0.772727 |\n",
            "|  4 | Stacking Classifier Max R |          0.964286 |                          0.74026  |\n",
            "+----+---------------------------+-------------------+-----------------------------------+\n"
          ]
        }
      ],
      "source": [
        "accuracies_dir = 'saved_models/accuracies'\n",
        "precomputed_stats, training_feature_cols, regular_accuracies, max_r_accuracies = read_accuracy_dataframes(accuracies_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBvlTErr3YlF",
        "outputId": "ed299f5d-8f0d-48df-a290-1961a7458641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OLD Model:\n",
            "\n",
            "--- Regular Model Accuracies ---\n",
            "+----+---------------------+-------------------+-----------------------------------+\n",
            "|    | Model               |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
            "|----+---------------------+-------------------+-----------------------------------|\n",
            "|  0 | RandomForest        |          0.960912 |                          0.86645  |\n",
            "|  1 | XGBoost             |          0.960912 |                          0.885993 |\n",
            "|  2 | Logistic Regression |          0.973941 |                          0.859935 |\n",
            "|  3 | Voting Classifier   |          0.967427 |                          0.882736 |\n",
            "|  4 | Stacking Classifier |          0.964169 |                          0.856678 |\n",
            "+----+---------------------+-------------------+-----------------------------------+\n",
            "\n",
            "--- Max R Model Accuracies ---\n",
            "+----+---------------------------+-------------------+-----------------------------------+\n",
            "|    | Model                     |   Binary Accuracy |   Multi-Class (R Bucket) Accuracy |\n",
            "|----+---------------------------+-------------------+-----------------------------------|\n",
            "|  0 | RandomForest Max R        |          0.960912 |                          0.749186 |\n",
            "|  1 | XGBoost Max R             |          0.960912 |                          0.758958 |\n",
            "|  2 | Logistic Regression Max R |          0.973941 |                          0.739414 |\n",
            "|  3 | Voting Classifier Max R   |          0.967427 |                          0.758958 |\n",
            "|  4 | Stacking Classifier Max R |          0.964169 |                          0.739414 |\n",
            "+----+---------------------------+-------------------+-----------------------------------+\n"
          ]
        }
      ],
      "source": [
        "old_accuracies_dir = 'old_models/accuracies'\n",
        "print('OLD Model:')\n",
        "old_precomputed_stats, old_training_feature_cols, old_regular_accuracies, old_max_r_accuracies = read_accuracy_dataframes(old_accuracies_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9wuV6GJoS4"
      },
      "source": [
        "##Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3vtlJirpHqOk"
      },
      "outputs": [],
      "source": [
        "# prompt: read all 20 models separately  regular binary, regular multi, max r binary, max r multi, . so that i can pass binary model and multi models list to function easily\n",
        "\n",
        "# Define a directory to save the models\n",
        "def read_models(model_dir):\n",
        "\n",
        "    # Define lists to store the loaded models\n",
        "    regular_binary_models = []\n",
        "    regular_multi_models = []\n",
        "    max_r_binary_models = []\n",
        "    max_r_multi_models = []\n",
        "\n",
        "    # List of model base names (keys used in filenames)\n",
        "    model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "\n",
        "    # Load regular binary models\n",
        "    print(\"Loading regular binary models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            regular_binary_models.append(model)\n",
        "            print(f\"Loaded {key}_model\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model: {e}\")\n",
        "\n",
        "    # Load regular multi-class models\n",
        "    print(\"\\nLoading regular multi-class models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_m.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            regular_multi_models.append(model)\n",
        "            print(f\"Loaded {key}_model_m\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_m.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_m: {e}\")\n",
        "\n",
        "    # Load max R binary models\n",
        "    print(\"\\nLoading Max R binary models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_max_r.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            max_r_binary_models.append(model)\n",
        "            print(f\"Loaded {key}_model_max_r\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_max_r.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_max_r: {e}\")\n",
        "\n",
        "    # Load max R multi-class models\n",
        "    print(\"\\nLoading Max R multi-class models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_m_max_r.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            max_r_multi_models.append(model)\n",
        "            print(f\"Loaded {key}_model_m_max_r\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_m_max_r.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_m_max_r: {e}\")\n",
        "\n",
        "    # Load Label Encoders\n",
        "    print(\"\\nLoading Label Encoders...\")\n",
        "    try:\n",
        "        label_encoder = joblib.load(os.path.join(model_dir, 'label_encoder.pkl'))\n",
        "        print(\"Loaded label_encoder\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: label_encoder.pkl not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label_encoder: {e}\")\n",
        "\n",
        "    try:\n",
        "        label_encoder_max_r = joblib.load(os.path.join(model_dir, 'label_encoder_max_r.pkl'))\n",
        "        print(\"Loaded label_encoder_max_r\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: label_encoder_max_r.pkl not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label_encoder_max_r: {e}\")\n",
        "\n",
        "    return regular_binary_models, regular_multi_models, max_r_binary_models, max_r_multi_models, label_encoder, label_encoder_max_r\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTDiG0or4TL6",
        "outputId": "5dd6f28c-c142-4361-d9df-6cce35c60618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading regular binary models...\n",
            "Loaded RF_model\n",
            "Loaded XVG_model\n",
            "Loaded LR_model\n",
            "Loaded VC_model\n",
            "Loaded S_model\n",
            "\n",
            "Loading regular multi-class models...\n",
            "Loaded RF_model_m\n",
            "Loaded XVG_model_m\n",
            "Loaded LR_model_m\n",
            "Loaded VC_model_m\n",
            "Loaded S_model_m\n",
            "\n",
            "Loading Max R binary models...\n",
            "Loaded RF_model_max_r\n",
            "Loaded XVG_model_max_r\n",
            "Loaded LR_model_max_r\n",
            "Loaded VC_model_max_r\n",
            "Loaded S_model_max_r\n",
            "\n",
            "Loading Max R multi-class models...\n",
            "Loaded RF_model_m_max_r\n",
            "Loaded XVG_model_m_max_r\n",
            "Loaded LR_model_m_max_r\n",
            "Loaded VC_model_m_max_r\n",
            "Loaded S_model_m_max_r\n",
            "\n",
            "Loading Label Encoders...\n",
            "Loaded label_encoder\n",
            "Loaded label_encoder_max_r\n"
          ]
        }
      ],
      "source": [
        "model_dir = 'saved_models'\n",
        "regular_binary_models, regular_multi_models, max_r_binary_models, max_r_multi_models, label_encoder, label_encoder_max_r = read_models(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u9CAoO14hOx",
        "outputId": "1689a71d-43dd-4cbd-89aa-5635ac9960cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OLD Model:\n",
            "Loading regular binary models...\n",
            "Loaded RF_model\n",
            "Loaded XVG_model\n",
            "Loaded LR_model\n",
            "Loaded VC_model\n",
            "Loaded S_model\n",
            "\n",
            "Loading regular multi-class models...\n",
            "Loaded RF_model_m\n",
            "Loaded XVG_model_m\n",
            "Loaded LR_model_m\n",
            "Loaded VC_model_m\n",
            "Loaded S_model_m\n",
            "\n",
            "Loading Max R binary models...\n",
            "Loaded RF_model_max_r\n",
            "Loaded XVG_model_max_r\n",
            "Loaded LR_model_max_r\n",
            "Loaded VC_model_max_r\n",
            "Loaded S_model_max_r\n",
            "\n",
            "Loading Max R multi-class models...\n",
            "Loaded RF_model_m_max_r\n",
            "Loaded XVG_model_m_max_r\n",
            "Loaded LR_model_m_max_r\n",
            "Loaded VC_model_m_max_r\n",
            "Loaded S_model_m_max_r\n",
            "\n",
            "Loading Label Encoders...\n",
            "Loaded label_encoder\n",
            "Loaded label_encoder_max_r\n"
          ]
        }
      ],
      "source": [
        "old_models_dir = 'old_models'\n",
        "print('OLD Model:')\n",
        "old_regular_binary_models, old_regular_multi_models, old_max_r_binary_models, old_max_r_multi_models, old_label_encoder, old_label_encoder_max_r = read_models(old_models_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWqwfET6E9np"
      },
      "source": [
        "##Prediction App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMMuQpLSE9nq",
        "outputId": "85ad3b87-4285-49a0-940b-865e6f2cbc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "...........................New Models...........................\n",
            "\n",
            "--- 📊 Combined Model Predictions for 7/1/2025 03:30 (ELC) - ---\n",
            "\n",
            "Overall decision: ---- Binary: ** Win **  Multi: ** Win** ---- - Max R: 2 - Average R:2.0\n",
            "Binary Models: Win Predicted **4 time **    Multi Models: Win Predicted **2**\n",
            "╒═════════════════════╤════════════════════════╤═════════════════════════════╕\n",
            "│ Model               │ 📘 Binary (Win/Loss)   │ 📗 Multi-Class (R Bucket)   │\n",
            "╞═════════════════════╪════════════════════════╪═════════════════════════════╡\n",
            "│ Random Forest       │ Win (0.55), Acc: 0.96  │ Class 1 (0.34), Acc: 0.86   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ XGBoost             │ Loss (0.96), Acc: 0.96 │ Class 1 (0.87), Acc: 0.88   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Logistic Regression │ Win (0.92), Acc: 0.97  │ Class 3 (0.59), Acc: 0.86   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Voting Classifier   │ Win (0.50), Acc: 0.96  │ Class 1 (0.40), Acc: 0.88   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Stacking Classifier │ Win (0.98), Acc: 0.96  │ Class 3 (0.99), Acc: 0.87   │\n",
            "╘═════════════════════╧════════════════════════╧═════════════════════════════╛\n",
            "...........................Old Models...........................\n",
            "\n",
            "--- 📊 Combined Model Predictions for 7/1/2025 03:30 (ELC) - ---\n",
            "\n",
            "Overall decision: ---- Binary: ** Win **  Multi: ** Win** ---- - Max R: 2 - Average R:1.5\n",
            "Binary Models: Win Predicted **2 time **    Multi Models: Win Predicted **2**\n",
            "╒═════════════════════╤════════════════════════╤═════════════════════════════╕\n",
            "│ Model               │ 📘 Binary (Win/Loss)   │ 📗 Multi-Class (R Bucket)   │\n",
            "╞═════════════════════╪════════════════════════╪═════════════════════════════╡\n",
            "│ Random Forest       │ Loss (0.55), Acc: 0.96 │ Class 1 (0.40), Acc: 0.87   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ XGBoost             │ Loss (0.97), Acc: 0.96 │ Class 1 (0.88), Acc: 0.89   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Logistic Regression │ Win (0.93), Acc: 0.97  │ Class 2 (0.71), Acc: 0.86   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Voting Classifier   │ Loss (0.53), Acc: 0.97 │ Class 1 (0.43), Acc: 0.88   │\n",
            "├─────────────────────┼────────────────────────┼─────────────────────────────┤\n",
            "│ Stacking Classifier │ Win (0.98), Acc: 0.96  │ Class 3 (0.99), Acc: 0.86   │\n",
            "╘═════════════════════╧════════════════════════╧═════════════════════════════╛\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)],\n",
              " [np.int64(0), np.int32(0), np.int64(1), np.int64(0), np.int64(2)])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_input = \"05:30\"  #@param {type:\"string\"}\n",
        "date_input = \"7/1/2025\"  #@param {type:\"string\"}\n",
        "criteria_input = \"LG PDL\"  #@param {type:\"string\"}\n",
        "CW = 0 #@param {type:\"integer\"}\n",
        "CL = 7 #@param {type:\"integer\"}\n",
        "\n",
        "model_names = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_names_max_r = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "\n",
        "print('...........................New Models...........................')\n",
        "show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names, model_keys,precomputed_stats=precomputed_stats,label_encoder=label_encoder, b_models=regular_binary_models, m_models=regular_multi_models, b_acc=regular_accuracies['Binary Accuracy'], m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                 w_threshold=1)\n",
        "\n",
        "print(\"...........................Old Models...........................\")\n",
        "show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names, model_keys,precomputed_stats=old_precomputed_stats,label_encoder=old_label_encoder, b_models=old_regular_binary_models, m_models=old_regular_multi_models, b_acc=old_regular_accuracies['Binary Accuracy'], m_acc=old_regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                 w_threshold=1)\n",
        "\n",
        "# print('...........................Max R Models...........................')\n",
        "# show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names_max_r, model_keys, b_models=max_r_binary_models, m_models=max_r_multi_models, b_acc=max_r_accuracies['Binary Accuracy'], m_acc=max_r_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "#                  Max_R=True, w_threshold=1)\n",
        "# print('...........................Old Max R Models...........................')\n",
        "\n",
        "# show_predictions(time_input, date_input, criteria_input, CW, CL,training_feature_cols, model_names_max_r, model_keys, b_models=old_max_r_binary_models, m_models=old_max_r_multi_models, b_acc=old_max_r_accuracies['Binary Accuracy'], m_acc=old_max_r_accuracies['Multi-Class (R Bucket) Accuracy'], \n",
        "#                  Max_R=True, w_threshold=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsL3jM92JJhq"
      },
      "source": [
        "##Predict with Excel File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BxbMT5_hkEq5"
      },
      "outputs": [],
      "source": [
        "def calculate_prior_streaks(df):\n",
        "    cl_list = [3]  # First trade starts with CL = 3\n",
        "    cw_list = [0]  # First trade starts with CW = 0\n",
        "\n",
        "    for i in range(1, len(df)):\n",
        "        prev_result = df.loc[i - 1, 'Result']\n",
        "        prev_cl = cl_list[-1]\n",
        "        prev_cw = cw_list[-1]\n",
        "\n",
        "        if prev_result == 'W':\n",
        "            cw = prev_cw + 1\n",
        "            cl = 0\n",
        "        elif prev_result == 'L':\n",
        "            cl = prev_cl + 1\n",
        "            cw = 0\n",
        "        else:\n",
        "            cl = prev_cl\n",
        "            cw = prev_cw\n",
        "\n",
        "        cl_list.append(cl)\n",
        "        cw_list.append(cw)\n",
        "\n",
        "    df['CL'] = cl_list\n",
        "    df['CW'] = cw_list\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "# df = calculate_prior_streaks(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UbauAfmR9i",
        "outputId": "05f6ae4c-a82d-44b4-829e-a812d54c5063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully read Excel file: /content/SSL_T.xlsx\n",
            "Calculated CL and CW columns.\n",
            "Created 'Start_Datetime' column.\n",
            "\n",
            "--- Processing rows from index 3060 to 3074 ---\n",
            "\n",
            "--- Predicting for Row Index: 3060 ---\n",
            "Date: 06/29/2025, Time: 19:45, Criteria: ELC, Prior CL: 4, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3061 ---\n",
            "Date: 06/29/2025, Time: 21:15, Criteria: LG SBPS, Prior CL: 5, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3062 ---\n",
            "Date: 06/30/2025, Time: 02:45, Criteria: LG C, Prior CL: 0, Prior CW: 1\n",
            "\n",
            "--- Predicting for Row Index: 3063 ---\n",
            "Date: 06/30/2025, Time: 07:00, Criteria: LG RGC, Prior CL: 1, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3064 ---\n",
            "Date: 06/30/2025, Time: 10:30, Criteria: ELC, Prior CL: 2, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3065 ---\n",
            "Date: 06/30/2025, Time: 10:45, Criteria: LG RGC UP, Prior CL: 3, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3066 ---\n",
            "Date: 06/30/2025, Time: 12:15, Criteria: LG C, Prior CL: 4, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3067 ---\n",
            "Date: 06/30/2025, Time: 12:45, Criteria: LG RGC, Prior CL: 5, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3068 ---\n",
            "Date: 06/30/2025, Time: 14:00, Criteria: ELC, Prior CL: 6, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3069 ---\n",
            "Date: 06/30/2025, Time: 17:45, Criteria: LG RGC, Prior CL: 0, Prior CW: 1\n",
            "\n",
            "--- Predicting for Row Index: 3070 ---\n",
            "Date: 06/30/2025, Time: 18:15, Criteria: EL SBPS, Prior CL: 1, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3071 ---\n",
            "Date: 06/30/2025, Time: 21:15, Criteria: ELUPF, Prior CL: 0, Prior CW: 1\n",
            "\n",
            "--- Predicting for Row Index: 3072 ---\n",
            "Date: 06/30/2025, Time: 22:00, Criteria: LG RGC, Prior CL: 1, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3073 ---\n",
            "Date: 06/30/2025, Time: 23:00, Criteria: EL SBPS, Prior CL: 2, Prior CW: 0\n",
            "\n",
            "--- Predicting for Row Index: 3074 ---\n",
            "Date: 06/30/2025, Time: 23:45, Criteria: LG C, Prior CL: 3, Prior CW: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Modify process_excel_and_predict to collect predictions and create a summary DataFrame\n",
        "def process_excel_and_predict(file_path, from_index, to_index, w_threshold = 1, s_print=False):\n",
        "    \"\"\"\n",
        "    Reads an Excel file, calculates prior streaks (CL and CW),\n",
        "    makes predictions for a specified range of rows, and returns\n",
        "    a summary DataFrame of predictions.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the Excel file.\n",
        "        from_index (int): The starting index (row number) to process.\n",
        "        to_index (int): The ending index (row number) to process.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame summarizing the predictions for each processed row.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        print(f\"Successfully read Excel file: {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading Excel file: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure 'Result' column exists for streak calculation\n",
        "    if 'Result' not in df.columns:\n",
        "        print(\"Error: 'Result' column not found in the Excel file. Cannot calculate streaks.\")\n",
        "        return None\n",
        "\n",
        "    # Calculate prior streaks (CL and CW)\n",
        "    df = calculate_prior_streaks(df)\n",
        "    print(\"Calculated CL and CW columns.\")\n",
        "\n",
        "    # Ensure 'Start_Time' and 'Start_Date' columns exist and are datetime objects\n",
        "    if 'Start Time' not in df.columns or 'Start Date' not in df.columns:\n",
        "         print(\"Error: 'Start Time' or 'Start Date' column not found in the Excel file. Cannot process dates.\")\n",
        "         return None\n",
        "\n",
        "    # Combine 'Start_Date' and 'Start_Time' and convert to datetime objects\n",
        "    try:\n",
        "        df['Start_Datetime'] = pd.to_datetime(df['Start Date'].astype(str) + ' ' + df['Start Time'].astype(str))\n",
        "        print(\"Created 'Start_Datetime' column.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error combining date and time or converting to datetime: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Check if the requested range is valid\n",
        "    if from_index < 0 or to_index >= len(df) or from_index > to_index:\n",
        "        print(f\"Error: Invalid index range. Data has {len(df)} rows (0 to {len(df)-1}).\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n--- Processing rows from index {from_index} to {to_index} ---\")\n",
        "\n",
        "    summary_data = []\n",
        "\n",
        "    # Process rows one by one\n",
        "    for i in range(from_index, to_index + 1):\n",
        "        row = df.loc[i]\n",
        "\n",
        "        time_input = row['Start_Datetime'].strftime('%H:%M')\n",
        "        date_input = row['Start_Datetime'].strftime('%m/%d/%Y')\n",
        "        criteria_input = row['Criteria']  # Assuming 'Criteria' column exists\n",
        "        cw_value = row['CW']\n",
        "        cl_value = row['CL']\n",
        "        actual_result = row['Result'] # Get the actual result\n",
        "\n",
        "        print(f\"\\n--- Predicting for Row Index: {i} ---\")\n",
        "        print(f\"Date: {date_input}, Time: {time_input}, Criteria: {criteria_input}, Prior CL: {cl_value}, Prior CW: {cw_value}\")\n",
        "\n",
        "        # Make predictions using the existing show_predictions function\n",
        "        # Ensure precomputed_stats, training_feature_cols, models, and encoders are loaded globally or passed\n",
        "        try:\n",
        "            # Get predictions for regular models\n",
        "            predictions_reg_bin, predictions_reg_multi = show_predictions(\n",
        "                time_input,\n",
        "                date_input,\n",
        "                criteria_input,\n",
        "                cw_value,\n",
        "                cl_value,\n",
        "                training_feature_cols,\n",
        "                model_names,\n",
        "                model_keys,\n",
        "                b_models=regular_binary_models,\n",
        "                m_models=regular_multi_models,\n",
        "                b_acc=regular_accuracies['Binary Accuracy'],\n",
        "                m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                s_print=s_print,\n",
        "                w_threshold=w_threshold\n",
        "            )\n",
        "\n",
        "            # Get predictions for max R models\n",
        "            predictions_max_r_bin, predictions_max_r_multi = show_predictions(\n",
        "                time_input,\n",
        "                date_input,\n",
        "                criteria_input,\n",
        "                cw_value,\n",
        "                cl_value,\n",
        "                training_feature_cols,\n",
        "                model_names_max_r,\n",
        "                model_keys,\n",
        "                b_models=max_r_binary_models,\n",
        "                m_models=max_r_multi_models,\n",
        "                b_acc=max_r_accuracies['Binary Accuracy'],\n",
        "                m_acc=max_r_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                s_print=s_print,\n",
        "                w_threshold=w_threshold,\n",
        "                Max_R=True\n",
        "            )\n",
        "            old_predictions_reg_bin, old_predictions_reg_multi = show_predictions(\n",
        "                time_input,\n",
        "                date_input,\n",
        "                criteria_input,\n",
        "                cw_value,\n",
        "                cl_value,\n",
        "                old_training_feature_cols,\n",
        "                model_names,\n",
        "                model_keys,\n",
        "                b_models=old_regular_binary_models,\n",
        "                m_models=old_regular_multi_models,\n",
        "                b_acc=old_regular_accuracies['Binary Accuracy'],\n",
        "                m_acc=old_regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                s_print=s_print,\n",
        "                w_threshold=w_threshold,\n",
        "            )\n",
        "\n",
        "            if predictions_reg_bin is not None and predictions_reg_multi is not None and \\\n",
        "               predictions_max_r_bin is not None and predictions_max_r_multi is not None:\n",
        "\n",
        "                row_summary = {\n",
        "                    'Index': i+1,\n",
        "                    'Date': date_input,\n",
        "                    'Time': time_input,\n",
        "                    'Criteria': criteria_input,\n",
        "                    'CL': cl_value,\n",
        "                    'CW': cw_value,\n",
        "                    'Actual_R': actual_result\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "                # Add combined binary prediction (Regular)\n",
        "                predicted_win_reg_bin = predictions_reg_bin.count(1)\n",
        "                trade_decision_reg_bin = \"Win\" if predicted_win_reg_bin >= w_threshold else \"Loss\"\n",
        "                row_summary['RC-BD'] = trade_decision_reg_bin\n",
        "                row_summary['RWC-B'] = predicted_win_reg_bin\n",
        "\n",
        "                # Add combined multi-class prediction (Regular)\n",
        "                predicted_win_reg_multi = len(predictions_reg_multi)-predictions_reg_multi.count(0)\n",
        "                trade_decision_reg_multi = \"Win\" if predicted_win_reg_multi >= w_threshold else \"Loss\"\n",
        "                row_summary['RC-MD'] = trade_decision_reg_multi\n",
        "                row_summary['RWC-M'] = predicted_win_reg_multi\n",
        "\n",
        "                row_summary['B_Pred'] = predictions_reg_bin\n",
        "                row_summary['M_Pred'] = predictions_reg_multi\n",
        "\n",
        "                row_summary['O_B_Pred'] = old_predictions_reg_bin\n",
        "                row_summary['O_M_Pred'] = old_predictions_reg_multi\n",
        "\n",
        "                row_summary['MR_B_Pred'] = predictions_max_r_bin\n",
        "                row_summary['MR_M_Pred'] = predictions_max_r_multi\n",
        "\n",
        "                if trade_decision_reg_multi == \"Win\":\n",
        "                    row_summary['R_M_R'] = np.max(predictions_reg_multi)\n",
        "                    row_summary['R_A_R'] = np.mean([x for x in predictions_reg_multi if x > 0])\n",
        "                else:\n",
        "                    row_summary['R_M_R'] = 0\n",
        "                    row_summary['R_A_R'] = 0\n",
        "\n",
        "                #ADD old Biinary\n",
        "                predicted_win_old_bin = old_predictions_reg_bin.count(1)\n",
        "                trade_decision_old_bin = \"Win\" if predicted_win_old_bin >= w_threshold else \"Loss\"\n",
        "                row_summary['O-C-BD'] = trade_decision_old_bin\n",
        "                row_summary['O-WC-B'] = predicted_win_old_bin\n",
        "\n",
        "                # Add combined multi-class prediction (Max R)\n",
        "                predicted_win_max_r_multi = len(predictions_max_r_multi)-predictions_max_r_multi.count(0)\n",
        "                trade_decision_max_r_multi = \"Win\" if predicted_win_max_r_multi >= w_threshold else \"Loss\"\n",
        "                row_summary['M-C-MD'] = trade_decision_max_r_multi\n",
        "                row_summary['M-WC-M'] = predicted_win_max_r_multi\n",
        "                if trade_decision_max_r_multi == \"Win\":\n",
        "                    row_summary['MR_M_R'] = np.max(predictions_max_r_multi)\n",
        "                    row_summary['MR_A_R'] = np.mean([x for x in predictions_max_r_multi if x > 0])\n",
        "                else:\n",
        "                    row_summary['MR_M_R'] = 0\n",
        "                    row_summary['MR_A_R'] = 0\n",
        "\n",
        "\n",
        "                summary_data.append(row_summary)\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"An error occurred during prediction for index {i}: {e}\")\n",
        "             # Append a row indicating an error if needed\n",
        "             error_row = {'Index': i, 'Date': date_input, 'Time': time_input, 'Criteria': criteria_input,\n",
        "                          'CL': cl_value, 'CW': cw_value, 'Actual_R': actual_result, 'Error': str(e)}\n",
        "             summary_data.append(error_row)\n",
        "\n",
        "\n",
        "    # Create DataFrame from the collected summary data\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "# --- User Inputs ---\n",
        "excel_file_path = '/content/SSL_T.xlsx'  # Replace with the path to your Excel file\n",
        "start_index = 3060 # Replace with the starting row index (0-based)\n",
        "end_index = 3075   # Replace with the ending row index (inclusive)\n",
        "\n",
        "prediction_summary_df = process_excel_and_predict(excel_file_path, start_index, end_index-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "r9i2zESXutoa",
        "outputId": "8b42b4ab-4ac0-42b1-f03b-36515b549475"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "prediction_summary_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-804e216e-df25-419c-be3d-81cdc792e5ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Criteria</th>\n",
              "      <th>CL</th>\n",
              "      <th>CW</th>\n",
              "      <th>Actual_Result</th>\n",
              "      <th>Binary_Pred</th>\n",
              "      <th>Multi_Pred</th>\n",
              "      <th>OLD_Binary_Pred</th>\n",
              "      <th>...</th>\n",
              "      <th>Regular_Combined_Multi_Decision</th>\n",
              "      <th>Regular_Win_Count_Multi</th>\n",
              "      <th>Regular_Max_R</th>\n",
              "      <th>Regular_Avg_R</th>\n",
              "      <th>OLD_Combined_Binary_Decision</th>\n",
              "      <th>OLD_Win_Count_Binary</th>\n",
              "      <th>MaxR_Combined_Multi_Decision</th>\n",
              "      <th>MaxR_Win_Count_Multi</th>\n",
              "      <th>MaxR_Max_R</th>\n",
              "      <th>MaxR_Avg_R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3061</td>\n",
              "      <td>06/29/2025</td>\n",
              "      <td>19:45</td>\n",
              "      <td>ELC</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3062</td>\n",
              "      <td>06/29/2025</td>\n",
              "      <td>21:15</td>\n",
              "      <td>LG SBPS</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>W</td>\n",
              "      <td>[1, 1, 1, 1, 1]</td>\n",
              "      <td>[2, 3, 1, 1, 2]</td>\n",
              "      <td>[1, 1, 1, 1, 1]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Win</td>\n",
              "      <td>5</td>\n",
              "      <td>Win</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3063</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>02:45</td>\n",
              "      <td>LG C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3064</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>07:00</td>\n",
              "      <td>LG RGC</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3065</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>10:30</td>\n",
              "      <td>ELC</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3066</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>10:45</td>\n",
              "      <td>LG RGC UP</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3067</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>12:15</td>\n",
              "      <td>LG C</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3068</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>12:45</td>\n",
              "      <td>LG RGC</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3069</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>14:00</td>\n",
              "      <td>ELC</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>W</td>\n",
              "      <td>[1, 1, 1, 1, 1]</td>\n",
              "      <td>[2, 2, 1, 1, 2]</td>\n",
              "      <td>[0, 1, 1, 1, 1]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Win</td>\n",
              "      <td>4</td>\n",
              "      <td>Win</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3070</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>17:45</td>\n",
              "      <td>LG RGC</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3071</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>18:15</td>\n",
              "      <td>EL SBPS</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>W</td>\n",
              "      <td>[0, 0, 1, 0, 1]</td>\n",
              "      <td>[0, 0, 2, 0, 2]</td>\n",
              "      <td>[0, 0, 1, 0, 1]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Win</td>\n",
              "      <td>2</td>\n",
              "      <td>Win</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3072</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>21:15</td>\n",
              "      <td>ELUPF</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3073</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>22:00</td>\n",
              "      <td>LG RGC</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3074</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>23:00</td>\n",
              "      <td>EL SBPS</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3075</td>\n",
              "      <td>06/30/2025</td>\n",
              "      <td>23:45</td>\n",
              "      <td>LG C</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 2]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>...</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Loss</td>\n",
              "      <td>0</td>\n",
              "      <td>Win</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-804e216e-df25-419c-be3d-81cdc792e5ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-804e216e-df25-419c-be3d-81cdc792e5ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-804e216e-df25-419c-be3d-81cdc792e5ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40da9173-3c64-4803-b23d-23e307e4cc45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40da9173-3c64-4803-b23d-23e307e4cc45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40da9173-3c64-4803-b23d-23e307e4cc45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_adf47fc9-bbe7-431b-bc79-ce5d66dee4bb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('prediction_summary_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_adf47fc9-bbe7-431b-bc79-ce5d66dee4bb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('prediction_summary_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Index        Date   Time   Criteria  CL  CW Actual_Result  \\\n",
              "0    3061  06/29/2025  19:45        ELC   4   0             L   \n",
              "1    3062  06/29/2025  21:15    LG SBPS   5   0             W   \n",
              "2    3063  06/30/2025  02:45       LG C   0   1             L   \n",
              "3    3064  06/30/2025  07:00     LG RGC   1   0             L   \n",
              "4    3065  06/30/2025  10:30        ELC   2   0             L   \n",
              "5    3066  06/30/2025  10:45  LG RGC UP   3   0             L   \n",
              "6    3067  06/30/2025  12:15       LG C   4   0             L   \n",
              "7    3068  06/30/2025  12:45     LG RGC   5   0             L   \n",
              "8    3069  06/30/2025  14:00        ELC   6   0             W   \n",
              "9    3070  06/30/2025  17:45     LG RGC   0   1             L   \n",
              "10   3071  06/30/2025  18:15    EL SBPS   1   0             W   \n",
              "11   3072  06/30/2025  21:15      ELUPF   0   1             L   \n",
              "12   3073  06/30/2025  22:00     LG RGC   1   0             L   \n",
              "13   3074  06/30/2025  23:00    EL SBPS   2   0             L   \n",
              "14   3075  06/30/2025  23:45       LG C   3   0             L   \n",
              "\n",
              "        Binary_Pred       Multi_Pred  OLD_Binary_Pred  ...  \\\n",
              "0   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  ...   \n",
              "1   [1, 1, 1, 1, 1]  [2, 3, 1, 1, 2]  [1, 1, 1, 1, 1]  ...   \n",
              "2   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "3   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "4   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "5   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "6   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "7   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "8   [1, 1, 1, 1, 1]  [2, 2, 1, 1, 2]  [0, 1, 1, 1, 1]  ...   \n",
              "9   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "10  [0, 0, 1, 0, 1]  [0, 0, 2, 0, 2]  [0, 0, 1, 0, 1]  ...   \n",
              "11  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "12  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "13  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "14  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 2]  [0, 0, 0, 0, 0]  ...   \n",
              "\n",
              "   Regular_Combined_Multi_Decision Regular_Win_Count_Multi Regular_Max_R  \\\n",
              "0                             Loss                       0             0   \n",
              "1                              Win                       5             3   \n",
              "2                              Win                       1             2   \n",
              "3                              Win                       1             2   \n",
              "4                              Win                       1             2   \n",
              "5                              Win                       1             2   \n",
              "6                              Win                       1             2   \n",
              "7                              Win                       1             2   \n",
              "8                              Win                       5             2   \n",
              "9                              Win                       1             2   \n",
              "10                             Win                       2             2   \n",
              "11                             Win                       1             2   \n",
              "12                             Win                       1             2   \n",
              "13                             Win                       1             2   \n",
              "14                             Win                       1             2   \n",
              "\n",
              "   Regular_Avg_R  OLD_Combined_Binary_Decision OLD_Win_Count_Binary  \\\n",
              "0            0.0                          Loss                    0   \n",
              "1            1.8                           Win                    5   \n",
              "2            2.0                          Loss                    0   \n",
              "3            2.0                          Loss                    0   \n",
              "4            2.0                          Loss                    0   \n",
              "5            2.0                          Loss                    0   \n",
              "6            2.0                          Loss                    0   \n",
              "7            2.0                          Loss                    0   \n",
              "8            1.6                           Win                    4   \n",
              "9            2.0                          Loss                    0   \n",
              "10           2.0                           Win                    2   \n",
              "11           2.0                          Loss                    0   \n",
              "12           2.0                          Loss                    0   \n",
              "13           2.0                          Loss                    0   \n",
              "14           2.0                          Loss                    0   \n",
              "\n",
              "    MaxR_Combined_Multi_Decision  MaxR_Win_Count_Multi  MaxR_Max_R MaxR_Avg_R  \n",
              "0                           Loss                     0           0       0.00  \n",
              "1                            Win                     4           6       4.25  \n",
              "2                            Win                     1           4       4.00  \n",
              "3                            Win                     1           4       4.00  \n",
              "4                            Win                     1           4       4.00  \n",
              "5                            Win                     1           4       4.00  \n",
              "6                           Loss                     0           0       0.00  \n",
              "7                            Win                     1           4       4.00  \n",
              "8                            Win                     4           6       4.25  \n",
              "9                            Win                     1           4       4.00  \n",
              "10                           Win                     2           4       2.50  \n",
              "11                          Loss                     0           0       0.00  \n",
              "12                           Win                     1           4       4.00  \n",
              "13                          Loss                     0           0       0.00  \n",
              "14                           Win                     1           4       4.00  \n",
              "\n",
              "[15 rows x 25 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn57glBhLKsA"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_excel(excel_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKfUS13MKLWu",
        "outputId": "c0b053a7-01dc-4346-e9a6-d2c2fa2dfd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sum of Binary Predictions for all Time/Criteria Combinations ---\n",
            "    Time Criteria  Binary_Prediction_Sum\n",
            "0  00:00      3FC                      0\n",
            "1  00:00     BTWT                      0\n",
            "2  00:00    DLTPS                      0\n",
            "3  00:00     DTLT                      0\n",
            "4  00:00       EL                      0\n"
          ]
        }
      ],
      "source": [
        "# prompt:  i have read a df . now Take a input Date ,CW, CL and  then try combination of all criteria  at 'Criteria' Column, and time at 'Start Time' collumn  in df to make predictions and make a show a heat map time in x and criteria in y and value is sum of binary prediction.. do not need multi and binary_mr, binary mult_mr.. just binary prediction sum..for example if df['Crietria'] has unique value ['a', 'b'] and time has ['00:00', 00:15'] the ntry combination [date, '00:00', 'a', CW, CL] , [date, '00:00', 'b', CW, CL]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def predict_for_combinations(date_input, CW, CL, training_feature_cols, regular_binary_models, model_keys, model_names, precomputed_stats):\n",
        "    \"\"\"\n",
        "    Generates predictions for all combinations of unique Criteria and Start Times\n",
        "    for a given date, CW, and CL.\n",
        "\n",
        "    Args:\n",
        "        date_input (str): The input date in M/D/YYYY format.\n",
        "        CW (int): The input Consecutive Wins.\n",
        "        CL (int): The input Consecutive Losses.\n",
        "        training_feature_cols (list): List of training feature column names.\n",
        "        regular_binary_models (list): List of trained regular binary models.\n",
        "        model_keys (list): List of keys for the models.\n",
        "        model_names (list): List of names for the models.\n",
        "        precomputed_stats (dict): Dictionary of precomputed statistics.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the sum of binary predictions\n",
        "                      for each combination of Time and Criteria.\n",
        "    \"\"\"\n",
        "    # Get unique Criteria and 15Min time values from the original dataframe\n",
        "    # Assuming 'Criteria' and '15Min' columns exist in the precomputed_stats keys or the original data source\n",
        "    # A safer way is to get these from the training data if available, or infer from precomputed_stats keys\n",
        "    criteria_values = set()\n",
        "    time_values = set()\n",
        "\n",
        "    for key in precomputed_stats:\n",
        "        if key[0] == 'Criteria':\n",
        "            criteria_values.add(key[1])\n",
        "        if key[0] == '15Min':\n",
        "            time_values.add(key[1])\n",
        "\n",
        "    criteria_values = sorted(list(criteria_values))\n",
        "    time_values = sorted(list(time_values))\n",
        "    print(f\"Unique Criteria: {criteria_values}\")\n",
        "    print(f\"Unique 15Min: {time_values}\")\n",
        "\n",
        "\n",
        "    prediction_results = []\n",
        "    for time_input in time_values:\n",
        "        if len(prediction_results) % 1000 == 0:\n",
        "          print(\"processsing.........:\", time_input)\n",
        "        for criteria_input in criteria_values:\n",
        "\n",
        "            input_features = get_train_data_for_input(\n",
        "                precomputed_stats,\n",
        "                time_input,\n",
        "                date_input,\n",
        "                criteria_input,\n",
        "                training_feature_cols\n",
        "            )\n",
        "\n",
        "            if not input_features.empty:\n",
        "                input_features['CL'] = CL\n",
        "                input_features['CW'] = CW\n",
        "\n",
        "                binary_predictions_sum = 0\n",
        "                for model in regular_binary_models:\n",
        "                    pred_bin, _ = predict_trade_result(model, input_features)\n",
        "                    if pred_bin is not None:\n",
        "                        binary_predictions_sum += pred_bin\n",
        "\n",
        "                prediction_results.append({\n",
        "                    'Time': time_input,\n",
        "                    'Criteria': criteria_input,\n",
        "                    'Binary_Prediction_Sum': binary_predictions_sum\n",
        "                })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    predictions_df = pd.DataFrame(prediction_results)\n",
        "\n",
        "    return predictions_df\n",
        "\n",
        "\n",
        "\n",
        "# --- User Inputs for Prediction Combination ---\n",
        "input_date_comb = \"7/01/2025\"  #@param {type:\"string\"}\n",
        "input_CW_comb = 0 #@param {type:\"integer\"}\n",
        "input_CL_comb = 1 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "# Get predictions for all combinations\n",
        "# prediction_combinations_df = predict_for_combinations(\n",
        "#     input_date_comb,\n",
        "#     input_CW_comb,\n",
        "#     input_CL_comb,\n",
        "#     training_feature_cols,\n",
        "#     regular_binary_models,\n",
        "#     model_keys,\n",
        "#     model_names,\n",
        "#     precomputed_stats\n",
        "# )\n",
        "\n",
        "# Display the prediction sums\n",
        "print(\"\\n--- Sum of Binary Predictions for all Time/Criteria Combinations ---\")\n",
        "print(prediction_combinations_df.head()) # Show first few rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSzRdMHpxCkc"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_heatmap(predictions_df):\n",
        "    \"\"\"\n",
        "    Generates a heatmap of the sum of binary predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions_df (pd.DataFrame): DataFrame containing 'Time', 'Criteria',\n",
        "                                      and 'Binary_Prediction_Sum' columns.\n",
        "    \"\"\"\n",
        "    if predictions_df.empty:\n",
        "        print(\"No prediction data to plot.\")\n",
        "        return\n",
        "\n",
        "    # Pivot the DataFrame to create a matrix for the heatmap\n",
        "    heatmap_data = predictions_df.pivot(index='Criteria', columns='Time', values='Binary_Prediction_Sum')\n",
        "\n",
        "    # Ensure all time values from the original list are present as columns\n",
        "    # This is important if some time/criteria combinations didn't appear in the data\n",
        "    all_times = sorted(predictions_df['Time'].unique())\n",
        "    heatmap_data = heatmap_data.reindex(columns=all_times)\n",
        "\n",
        "    num_intervals = len(all_times)  # should be 96\n",
        "    fig_width = num_intervals * 0.3\n",
        "    fig_height = len(predictions_df['Criteria'].unique())*.3\n",
        "\n",
        "    plt.figure(figsize=(fig_width, fig_height))\n",
        "    ax = sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='viridis', linewidths=.5)\n",
        "    ax.xaxis.set_ticks_position('both')\n",
        "    ax.tick_params(axis='x', which='both', labeltop=True, top=True, bottom=True, rotation=90)\n",
        "    plt.title('Sum of Binary Predictions Heatmap (Time vs Criteria)')\n",
        "    plt.xlabel('Start Time')\n",
        "    plt.ylabel('Criteria')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "    plt.show()\n",
        "# plot_prediction_heatmap(prediction_combinations_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLYP_gvHU5uz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM1XnVt/onLp6FDlSUbnaD2",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trading_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
