{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "aPJREcWCli0C",
        "dTVksY0OCWka"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIARD/SMC/blob/main/SMC_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYRo15yGj33S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import joblib\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "3hvUOPHeaAvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = pd.read_excel('SSL_T.xlsx')\n",
        "# df = pd.read_excel('SSL_T_MR.xlsx')\n",
        "# df = pd.read_excel('SSL_M.xlsx')\n",
        "\n",
        "# df = pd.read_excel('Train.xlsx')\n",
        "# df = pd.read_excel('Test.xlsx')\n",
        "# df = pd.read_excel('Train_Test.xlsx')\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "ZZBXo6unBhyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Train Data Functions"
      ],
      "metadata": {
        "id": "aPJREcWCli0C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qz3FF7W2SqF"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(group_df):\n",
        "    total_trades = len(group_df)\n",
        "    if total_trades == 0:\n",
        "        return 0, 0, 0.0  # Trade Count, Profit/Loss, Win Rate\n",
        "\n",
        "    total_pl = group_df['Profit/Loss'].sum()\n",
        "    total_wins = (group_df['Profit/Loss'] > 0).sum()\n",
        "    win_rate = total_wins / total_trades\n",
        "\n",
        "    return total_trades, total_pl, win_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_precomputed_stats(df):\n",
        "    # Pre-calculate all possible feature combinations\n",
        "    unique_15min = df['15Min'].unique()\n",
        "    unique_hours = df['Hour'].unique()\n",
        "    unique_weekdays = df['Start_Weekday'].unique()\n",
        "    unique_months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "    unique_criteria = df['Criteria'].unique()\n",
        "\n",
        "    # Extract Day of Month and Week of Month\n",
        "    df['Day_of_Month'] = df['startDateTime'].dt.day\n",
        "    df['Week_of_Month'] = df['startDateTime'].apply(lambda x: (x.day - 1) // 7 + 1)\n",
        "    unique_day_of_month = df['Day_of_Month'].unique()\n",
        "    unique_week_of_month = df['Week_of_Month'].unique()\n",
        "\n",
        "    # Store pre-calculated statistics in a dictionary for efficient lookup\n",
        "    precomputed_stats = {}\n",
        "\n",
        "    # Calculate stats for each individual feature value\n",
        "    for time_15min in unique_15min:\n",
        "        df_15min = df[df['15Min'] == time_15min]\n",
        "        stats = calculate_metrics(df_15min)\n",
        "        precomputed_stats[('15Min', time_15min)] = stats\n",
        "\n",
        "    for hour in unique_hours:\n",
        "        df_hour = df[df['Hour'] == hour]\n",
        "        stats = calculate_metrics(df_hour)\n",
        "        precomputed_stats[('Hour', hour)] = stats\n",
        "\n",
        "    for weekday in unique_weekdays:\n",
        "        df_weekday = df[df['Start_Weekday'] == weekday]\n",
        "        stats = calculate_metrics(df_weekday)\n",
        "        precomputed_stats[('Weekday', weekday)] = stats\n",
        "\n",
        "    for month in unique_months:\n",
        "        df_month = df[df['Month'] == month]\n",
        "        stats = calculate_metrics(df_month)\n",
        "        precomputed_stats[('Month', month)] = stats\n",
        "\n",
        "    for criteria in unique_criteria:\n",
        "        df_criteria = df[df['Criteria'] == criteria]\n",
        "        stats = calculate_metrics(df_criteria)\n",
        "        precomputed_stats[('Criteria', criteria)] = stats\n",
        "\n",
        "    # Calculate stats for Day of Month\n",
        "    for day in unique_day_of_month:\n",
        "        df_day = df[df['Day_of_Month'] == day]\n",
        "        stats = calculate_metrics(df_day)\n",
        "        precomputed_stats[('Day_of_Month', day)] = stats\n",
        "\n",
        "    # Calculate stats for Week of Month\n",
        "    for week in unique_week_of_month:\n",
        "        df_week = df[df['Week_of_Month'] == week]\n",
        "        stats = calculate_metrics(df_week)\n",
        "        precomputed_stats[('Week_of_Month', week)] = stats\n",
        "\n",
        "\n",
        "    # Calculate stats for combined features\n",
        "    for weekday in unique_weekdays:\n",
        "        for time_15min in unique_15min:\n",
        "            df_weekday_15m = df[(df['Start_Weekday'] == weekday) & (df['15Min'] == time_15min)]\n",
        "            stats = calculate_metrics(df_weekday_15m)\n",
        "            precomputed_stats[('Weekday_15Min', weekday, time_15min)] = stats\n",
        "\n",
        "        for hour in unique_hours:\n",
        "            df_weekday_hour = df[(df['Start_Weekday'] == weekday) & (df['Hour'] == hour)]\n",
        "            stats = calculate_metrics(df_weekday_hour)\n",
        "            precomputed_stats[('Weekday_Hour', weekday, hour)] = stats\n",
        "\n",
        "        for month in unique_months:\n",
        "            df_weekday_month = df[(df['Start_Weekday'] == weekday) & (df['Month'] == month)]\n",
        "            stats = calculate_metrics(df_weekday_month)\n",
        "            precomputed_stats[('Weekday_Month', weekday, month)] = stats\n",
        "\n",
        "        for day in unique_day_of_month:\n",
        "            df_weekday_day = df[(df['Start_Weekday'] == weekday) & (df['Day_of_Month'] == day)]\n",
        "            stats = calculate_metrics(df_weekday_day)\n",
        "            precomputed_stats[('Weekday_Day', weekday, day)] = stats\n",
        "\n",
        "        for week in unique_week_of_month:\n",
        "            df_weekday_week = df[(df['Start_Weekday'] == weekday) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_weekday_week)\n",
        "            precomputed_stats[('Weekday_Week', weekday, week)] = stats\n",
        "\n",
        "\n",
        "    for criteria in unique_criteria:\n",
        "        for time_15min in unique_15min:\n",
        "            df_criteria_15m = df[(df['Criteria'] == criteria) & (df['15Min'] == time_15min)]\n",
        "            stats = calculate_metrics(df_criteria_15m)\n",
        "            precomputed_stats[('Criteria_15Min', criteria, time_15min)] = stats\n",
        "\n",
        "        for hour in unique_hours:\n",
        "            df_criteria_hour = df[(df['Criteria'] == criteria) & (df['Hour'] == hour)]\n",
        "            stats = calculate_metrics(df_criteria_hour)\n",
        "            precomputed_stats[('Criteria_Hour', criteria, hour)] = stats\n",
        "\n",
        "        for weekday in unique_weekdays:\n",
        "            df_criteria_weekday = df[(df['Criteria'] == criteria) & (df['Start_Weekday'] == weekday)]\n",
        "            stats = calculate_metrics(df_criteria_weekday)\n",
        "            precomputed_stats[('Criteria_Weekday', criteria, weekday)] = stats\n",
        "\n",
        "        for month in unique_months:\n",
        "            df_criteria_month = df[(df['Criteria'] == criteria) & (df['Month'] == month)]\n",
        "            stats = calculate_metrics(df_criteria_month)\n",
        "            precomputed_stats[('Criteria_Month', criteria, month)] = stats\n",
        "\n",
        "        for day in unique_day_of_month:\n",
        "            df_criteria_day = df[(df['Criteria'] == criteria) & (df['Day_of_Month'] == day)]\n",
        "            stats = calculate_metrics(df_criteria_day)\n",
        "            precomputed_stats[('Criteria_Day', criteria, day)] = stats\n",
        "\n",
        "        for week in unique_week_of_month:\n",
        "            df_criteria_week = df[(df['Criteria'] == criteria) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_criteria_week)\n",
        "            precomputed_stats[('Criteria_Week', criteria, week)] = stats\n",
        "\n",
        "\n",
        "    for hour in unique_hours:\n",
        "        for month in unique_months:\n",
        "            df_hour_month = df[(df['Hour'] == hour) & (df['Month'] == month)]\n",
        "            stats = calculate_metrics(df_hour_month)\n",
        "            precomputed_stats[('Hour_Month', hour, month)] = stats\n",
        "\n",
        "        for day in unique_day_of_month:\n",
        "            df_hour_day = df[(df['Hour'] == hour) & (df['Day_of_Month'] == day)]\n",
        "            stats = calculate_metrics(df_hour_day)\n",
        "            precomputed_stats[('Hour_Day', hour, day)] = stats\n",
        "\n",
        "        for week in unique_week_of_month:\n",
        "            df_hour_week = df[(df['Hour'] == hour) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_hour_week)\n",
        "            precomputed_stats[('Hour_Week', hour, week)] = stats\n",
        "\n",
        "\n",
        "    for time_15min in unique_15min:\n",
        "        for month in unique_months:\n",
        "            df_15min_month = df[(df['15Min'] == time_15min) & (df['Month'] == month)]\n",
        "            stats = calculate_metrics(df_15min_month)\n",
        "            precomputed_stats[('15Min_Month', time_15min, month)] = stats\n",
        "\n",
        "        for day in unique_day_of_month:\n",
        "            df_15min_day = df[(df['15Min'] == time_15min) & (df['Day_of_Month'] == day)]\n",
        "            stats = calculate_metrics(df_15min_day)\n",
        "            precomputed_stats[('15Min_Day', time_15min, day)] = stats\n",
        "\n",
        "        for week in unique_week_of_month:\n",
        "            df_15min_week = df[(df['15Min'] == time_15min) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_15min_week)\n",
        "            precomputed_stats[('15Min_Week', time_15min, week)] = stats\n",
        "\n",
        "\n",
        "    for month in unique_months:\n",
        "        for day in unique_day_of_month:\n",
        "            df_month_day = df[(df['Month'] == month) & (df['Day_of_Month'] == day)]\n",
        "            stats = calculate_metrics(df_month_day)\n",
        "            precomputed_stats[('Month_Day', month, day)] = stats\n",
        "\n",
        "        for week in unique_week_of_month:\n",
        "            df_month_week = df[(df['Month'] == month) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_month_week)\n",
        "            precomputed_stats[('Month_Week', month, week)] = stats\n",
        "\n",
        "    for day in unique_day_of_month:\n",
        "        for week in unique_week_of_month:\n",
        "            df_day_week = df[(df['Day_of_Month'] == day) & (df['Week_of_Month'] == week)]\n",
        "            stats = calculate_metrics(df_day_week)\n",
        "            precomputed_stats[('Day_Week', day, week)] = stats\n",
        "\n",
        "    return precomputed_stats\n"
      ],
      "metadata": {
        "id": "VLsHEh7IISRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_data(precomputed_stats, index, row):\n",
        "    # Retrieve stats for individual features\n",
        "    row_data = {}\n",
        "    time_15min = row['15Min']\n",
        "    trade_count_15m, pl_15m, win_rate_15m = precomputed_stats[('15Min', time_15min)]\n",
        "    row_data['15Min_Trade Count'] = trade_count_15m\n",
        "    row_data['15Min_Win Rate'] = win_rate_15m\n",
        "    row_data['15Min_Profit/Loss'] = pl_15m\n",
        "\n",
        "    hour = row['Hour']\n",
        "    trade_count_hour, pl_hour, win_rate_hour = precomputed_stats[('Hour', hour)]\n",
        "    row_data['Hour_Trade Count'] = trade_count_hour\n",
        "    row_data['Hour_Win Rate'] = win_rate_hour\n",
        "    row_data['Hour_Profit/Loss'] = pl_hour\n",
        "\n",
        "    weekday = row['Start_Weekday']\n",
        "    trade_count_weekday, pl_weekday, win_rate_weekday = precomputed_stats[('Weekday', weekday)]\n",
        "    row_data['Weekday_Trade Count'] = trade_count_weekday\n",
        "    row_data['Weekday_Win Rate'] = win_rate_weekday\n",
        "    row_data['Weekday_Profit/Loss'] = pl_weekday\n",
        "\n",
        "    month = row['Month']\n",
        "    trade_count_month, pl_month, win_rate_month = precomputed_stats[('Month', month)]\n",
        "    row_data['Month_Trade Count'] = trade_count_month\n",
        "    row_data['Month_Win Rate'] = win_rate_month\n",
        "    row_data['Month_Profit/Loss'] = pl_month\n",
        "\n",
        "    criteria = row['Criteria']\n",
        "    trade_count_criteria, pl_criteria, win_rate_criteria = precomputed_stats[('Criteria', criteria)]\n",
        "    row_data['Criteria_Trade Count'] = trade_count_criteria\n",
        "    row_data['Criteria_Win Rate'] = win_rate_criteria\n",
        "    row_data['Criteria_Profit/Loss'] = pl_criteria\n",
        "\n",
        "    # Add features for Day of Month and Week of Month\n",
        "    day_of_month = row['Day_of_Month']\n",
        "    trade_count_day, pl_day, win_rate_day = precomputed_stats[('Day_of_Month', day_of_month)]\n",
        "    row_data['Day_of_Month_Trade Count'] = trade_count_day\n",
        "    row_data['Day_of_Month_Win Rate'] = win_rate_day\n",
        "    row_data['Day_of_Month_Profit/Loss'] = pl_day\n",
        "\n",
        "    week_of_month = row['Week_of_Month']\n",
        "    trade_count_week, pl_week, win_rate_week = precomputed_stats[('Week_of_Month', week_of_month)]\n",
        "    row_data['Week_of_Month_Trade Count'] = trade_count_week\n",
        "    row_data['Week_of_Month_Win Rate'] = win_rate_week\n",
        "    row_data['Week_of_Month_Profit/Loss'] = pl_week\n",
        "\n",
        "    # Retrieve stats for combined features\n",
        "    trade_count_weekday_15m, pl_weekday_15m, win_rate_weekday_15m = precomputed_stats[('Weekday_15Min', weekday, time_15min)]\n",
        "    row_data['Weekday_15Min_Trade Count'] = trade_count_weekday_15m\n",
        "    row_data['Weekday_15Min_Win Rate'] = win_rate_weekday_15m\n",
        "    row_data['Weekday_15Min_Profit/Loss'] = pl_weekday_15m\n",
        "\n",
        "    trade_count_weekday_hour, pl_weekday_hour, win_rate_weekday_hour = precomputed_stats[('Weekday_Hour', weekday, hour)]\n",
        "    row_data['Weekday_Hour_Trade Count'] = trade_count_weekday_hour\n",
        "    row_data['Weekday_Hour_Win Rate'] = win_rate_weekday_hour\n",
        "    row_data['Weekday_Hour_Profit/Loss'] = pl_weekday_hour\n",
        "\n",
        "    trade_count_weekday_month, pl_weekday_month, win_rate_weekday_month = precomputed_stats[('Weekday_Month', weekday, month)]\n",
        "    row_data['Weekday_Month_Trade Count'] = trade_count_weekday_month\n",
        "    row_data['Weekday_Month_Win Rate'] = win_rate_weekday_month\n",
        "    row_data['Weekday_Month_Profit/Loss'] = pl_weekday_month\n",
        "\n",
        "    trade_count_criteria_15m, pl_criteria_15m, win_rate_criteria_15m = precomputed_stats[('Criteria_15Min', criteria, time_15min)]\n",
        "    row_data['Criteria_15Min_Trade Count'] = trade_count_criteria_15m\n",
        "    row_data['Criteria_15Min_Win Rate'] = win_rate_criteria_15m\n",
        "    row_data['Criteria_15Min_Profit/Loss'] = pl_criteria_15m\n",
        "\n",
        "    trade_count_criteria_hour, pl_criteria_hour, win_rate_criteria_hour = precomputed_stats[('Criteria_Hour', criteria, hour)]\n",
        "    row_data['Criteria_Hour_Trade Count'] = trade_count_criteria_hour\n",
        "    row_data['Criteria_Hour_Win Rate'] = win_rate_criteria_hour\n",
        "    row_data['Criteria_Hour_Profit/Loss'] = pl_criteria_hour\n",
        "\n",
        "    trade_count_criteria_weekday, pl_criteria_weekday, win_rate_criteria_weekday = precomputed_stats[('Criteria_Weekday', criteria, weekday)]\n",
        "    row_data['Criteria_Weekday_Trade Count'] = trade_count_criteria_weekday\n",
        "    row_data['Criteria_Weekday_Win Rate'] = win_rate_criteria_weekday\n",
        "    row_data['Criteria_Weekday_Profit/Loss'] = pl_criteria_weekday\n",
        "\n",
        "    trade_count_criteria_month, pl_criteria_month, win_rate_criteria_month = precomputed_stats[('Criteria_Month', criteria, month)]\n",
        "    row_data['Criteria_Month_Trade Count'] = trade_count_criteria_month\n",
        "    row_data['Criteria_Month_Win Rate'] = win_rate_criteria_month\n",
        "    row_data['Criteria_Month_Profit/Loss'] = pl_criteria_month\n",
        "\n",
        "    trade_count_hour_month, pl_hour_month, win_rate_hour_month = precomputed_stats[('Hour_Month', hour, month)]\n",
        "    row_data['Hour_Month_Trade Count'] = trade_count_hour_month\n",
        "    row_data['Hour_Month_Win Rate'] = win_rate_hour_month\n",
        "    row_data['Hour_Month_Profit/Loss'] = pl_hour_month\n",
        "\n",
        "    trade_count_15min_month, pl_15min_month, win_rate_15min_month = precomputed_stats[('15Min_Month', time_15min, month)]\n",
        "    row_data['15Min_Month_Trade Count'] = trade_count_15min_month\n",
        "    row_data['15Min_Month_Win Rate'] = win_rate_15min_month\n",
        "    row_data['15Min_Month_Profit/Loss'] = pl_15min_month\n",
        "\n",
        "    # Add combined features for Day of Month and Week of Month\n",
        "    trade_count_weekday_day, pl_weekday_day, win_rate_weekday_day = precomputed_stats[('Weekday_Day', weekday, day_of_month)]\n",
        "    row_data['Weekday_Day_Trade Count'] = trade_count_weekday_day\n",
        "    row_data['Weekday_Day_Win Rate'] = win_rate_weekday_day\n",
        "    row_data['Weekday_Day_Profit/Loss'] = pl_weekday_day\n",
        "\n",
        "    trade_count_weekday_week, pl_weekday_week, win_rate_weekday_week = precomputed_stats[('Weekday_Week', weekday, week_of_month)]\n",
        "    row_data['Weekday_Week_Trade Count'] = trade_count_weekday_week\n",
        "    row_data['Weekday_Week_Win Rate'] = win_rate_weekday_week\n",
        "    row_data['Weekday_Week_Profit/Loss'] = pl_weekday_week\n",
        "\n",
        "    trade_count_criteria_day, pl_criteria_day, win_rate_criteria_day = precomputed_stats[('Criteria_Day', criteria, day_of_month)]\n",
        "    row_data['Criteria_Day_Trade Count'] = trade_count_criteria_day\n",
        "    row_data['Criteria_Day_Win Rate'] = win_rate_criteria_day\n",
        "    row_data['Criteria_Day_Profit/Loss'] = pl_criteria_day\n",
        "\n",
        "    trade_count_criteria_week, pl_criteria_week, win_rate_criteria_week = precomputed_stats[('Criteria_Week', criteria, week_of_month)]\n",
        "    row_data['Criteria_Week_Trade Count'] = trade_count_criteria_week\n",
        "    row_data['Criteria_Week_Win Rate'] = win_rate_criteria_week\n",
        "    row_data['Criteria_Week_Profit/Loss'] = pl_criteria_week\n",
        "\n",
        "    trade_count_hour_day, pl_hour_day, win_rate_hour_day = precomputed_stats[('Hour_Day', hour, day_of_month)]\n",
        "    row_data['Hour_Day_Trade Count'] = trade_count_hour_day\n",
        "    row_data['Hour_Day_Win Rate'] = win_rate_hour_day\n",
        "    row_data['Hour_Day_Profit/Loss'] = pl_hour_day\n",
        "\n",
        "    trade_count_hour_week, pl_hour_week, win_rate_hour_week = precomputed_stats[('Hour_Week', hour, week_of_month)]\n",
        "    row_data['Hour_Week_Trade Count'] = trade_count_hour_week\n",
        "    row_data['Hour_Week_Win Rate'] = win_rate_hour_week\n",
        "    row_data['Hour_Week_Profit/Loss'] = pl_hour_week\n",
        "\n",
        "    trade_count_15min_day, pl_15min_day, win_rate_15min_day = precomputed_stats[('15Min_Day', time_15min, day_of_month)]\n",
        "    row_data['15Min_Day_Trade Count'] = trade_count_15min_day\n",
        "    row_data['15Min_Day_Win Rate'] = win_rate_15min_day\n",
        "    row_data['15Min_Day_Profit/Loss'] = pl_15min_day\n",
        "\n",
        "    trade_count_15min_week, pl_15min_week, win_rate_15min_week = precomputed_stats[('15Min_Week', time_15min, week_of_month)]\n",
        "    row_data['15Min_Week_Trade Count'] = trade_count_15min_week\n",
        "    row_data['15Min_Week_Win Rate'] = win_rate_15min_week\n",
        "    row_data['15Min_Week_Profit/Loss'] = pl_15min_week\n",
        "\n",
        "    trade_count_month_day, pl_month_day, win_rate_month_day = precomputed_stats[('Month_Day', month, day_of_month)]\n",
        "    row_data['Month_Day_Trade Count'] = trade_count_month_day\n",
        "    row_data['Month_Day_Win Rate'] = win_rate_month_day\n",
        "    row_data['Month_Day_Profit/Loss'] = pl_month_day\n",
        "\n",
        "    trade_count_month_week, pl_month_week, win_rate_month_week = precomputed_stats[('Month_Week', month, week_of_month)]\n",
        "    row_data['Month_Week_Trade Count'] = trade_count_month_week\n",
        "    row_data['Month_Week_Win Rate'] = win_rate_month_week\n",
        "    row_data['Month_Week_Profit/Loss'] = pl_month_week\n",
        "\n",
        "    trade_count_day_week, pl_day_week, win_rate_day_week = precomputed_stats[('Day_Week', day_of_month, week_of_month)]\n",
        "    row_data['Day_Week_Trade Count'] = trade_count_day_week\n",
        "    row_data['Day_Week_Win Rate'] = win_rate_day_week\n",
        "    row_data['Day_Week_Profit/Loss'] = pl_day_week\n",
        "\n",
        "    return row_data"
      ],
      "metadata": {
        "id": "w5DzXKw_NP1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data(df, precomputed_stats):\n",
        "    # Prepare an empty DataFrame to store the results for each row\n",
        "    train_data_list = []\n",
        "\n",
        "    # Iterate through each row of the original DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        row_data = get_feature_data(precomputed_stats, index, row)\n",
        "        train_data_list.append(row_data)\n",
        "\n",
        "    # Create the new DataFrame\n",
        "    train_data = pd.DataFrame(train_data_list)\n",
        "    # train_data will now contain the calculated statistics for each row of the original df\n",
        "    # You can merge this back with the original df if needed:\n",
        "    # train_data = pd.concat([df.reset_index(drop=True), train_data], axis=1)\n",
        "    return train_data"
      ],
      "metadata": {
        "id": "FrkGcyT1CQEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get Train Data From Input"
      ],
      "metadata": {
        "id": "d6HOBC9hrIjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols):\n",
        "\n",
        "    # Convert inputs\n",
        "    try:\n",
        "        input_time = datetime.strptime(time_input, '%H:%M').time()\n",
        "    except ValueError:\n",
        "        print(\"Invalid time format. Use HH:MM.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        input_date = datetime.strptime(date_input, '%m/%d/%Y')\n",
        "    except ValueError:\n",
        "        print(\"Invalid date format. Use M/D/YYYY.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    row_data = {}\n",
        "    input_datetime = datetime.combine(input_date, input_time)\n",
        "    time_15min = input_datetime.strftime('%H:%M')\n",
        "    hour = input_datetime.hour\n",
        "    weekday = input_datetime.strftime('%A')\n",
        "    month = input_datetime.strftime('%B')\n",
        "    criteria = criteria_input\n",
        "    day_of_month = input_datetime.day\n",
        "    week_of_month = (input_datetime.day - 1) // 7 + 1\n",
        "\n",
        "    # Retrieve stats from precomputed_stats dictionary\n",
        "    try:\n",
        "        row = {'15Min': time_15min, 'Hour': hour, 'Start_Weekday': weekday, 'Month': month, 'Criteria': criteria, 'Day_of_Month':day_of_month, 'Week_of_Month':week_of_month}\n",
        "        row_data = get_feature_data(precomputed_stats, 0, row)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Missing precomputed statistic for key {e}. Ensure create_precomputed_stats covers all combinations you need.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Create DataFrame from the calculated row_data\n",
        "    input_features_df = pd.DataFrame([row_data])\n",
        "    # Reindex the input_features_df to match the training columns, filling missing with 0\n",
        "    input_features_df = input_features_df.reindex(columns=training_feature_cols, fill_value=0)\n",
        "\n",
        "    # Convert all columns to the same data type as the training features (assuming int from previous steps)\n",
        "    # for col in input_features_df.columns:\n",
        "    #     try:\n",
        "    #          input_features_df[col] = pd.to_numeric(input_features_df[col], errors='coerce')\n",
        "    #          input_features_df[col] = input_features_df[col].fillna(0).astype(int)\n",
        "    #     except ValueError:\n",
        "    #         print(f\"Warning: Could not convert input column '{col}' to integer.\")\n",
        "\n",
        "\n",
        "    return input_features_df\n",
        "\n",
        "\n",
        "# Call the optimized function\n",
        "# input_data = get_train_data_for_input_optimized(precomputed_stats, '09:30', '01/8/2023', 'ELC', training_feature_cols)\n",
        "# print(input_data)\n"
      ],
      "metadata": {
        "id": "9u1ALKrL9kRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test(Predicted) Data Analysis Functions"
      ],
      "metadata": {
        "id": "dTVksY0OCWka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_trade_result(model, input_features_df, training_feature_cols):\n",
        "\n",
        "    if input_features_df.empty:\n",
        "        print(\"Cannot predict: Invalid input features.\")\n",
        "        return None, None\n",
        "\n",
        "    # Make prediction\n",
        "    input_features_df = input_features_df[training_feature_cols]\n",
        "    predicted_class = model.predict(input_features_df)[0]\n",
        "    if predicted_class == 0:\n",
        "        predicted_proba = model.predict_proba(input_features_df)\n",
        "    else:\n",
        "        predicted_proba = model.predict_proba(input_features_df)\n",
        "\n",
        "    return predicted_class, predicted_proba"
      ],
      "metadata": {
        "id": "aTGB5KW8rSY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stats & Visualizations Functions"
      ],
      "metadata": {
        "id": "4Y-Citk6AQlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrices_horizontal(y_true, predictions, model_names, ticks=['LOSS', 'WIN'], multi=False):\n",
        "    num_models = len(predictions)\n",
        "    if num_models == 0 or len(predictions) != len(model_names):\n",
        "        print(\"Invalid input for plotting confusion matrices.\")\n",
        "        return None\n",
        "\n",
        "    fig, axes = plt.subplots(2, int(num_models / 2) + 1, figsize=(5 * (int(num_models / 2) + 1), 6))\n",
        "    axes = axes if isinstance(axes, np.ndarray) else np.array([[axes]])\n",
        "    r = 0\n",
        "\n",
        "    for i, y_pred in enumerate(predictions):\n",
        "        p_txt = \"\"\n",
        "        t_txt = \"\"\n",
        "        if i == 3:\n",
        "            r = 1\n",
        "\n",
        "        if multi == True:\n",
        "            ticks_u = np.union1d(y_true, y_pred)\n",
        "            p_txt = f\"Missing: {np.setdiff1d(ticks, y_pred).tolist()}\"\n",
        "            t_txt = f\"Missing: {np.setdiff1d(ticks, y_true).tolist()}\"\n",
        "            ticks = ticks_u\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        ax = axes[r, i % 3]\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, cbar=False)\n",
        "        ax.set_title(f'{model_names[i]}\\nAccuracy: {acc:.2f}', fontsize=11)\n",
        "        ax.set_xlabel(f'Predicted {p_txt}', fontsize=10)\n",
        "        ax.set_ylabel(f'True {t_txt}', fontsize=10)\n",
        "        ax.set_xticklabels(ticks)\n",
        "        ax.set_yticklabels(ticks)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "T31ozpHiANsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Prediciton"
      ],
      "metadata": {
        "id": "AOFVeBCVRDS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(time_input, date_input, criteria_input, CL, CW, training_feature_cols,model_names, model_keys, precomputed_stats=None,label_encoder=None, b_models=None, m_models=None, b_acc=None, m_acc=None, Max_R=False, s_print=True, w_threshold=1):\n",
        "    mr = \"_max_r\" if Max_R else \"\"\n",
        "    # Initialize models and their keys\n",
        "    binary_models = b_models if b_models is not None else [globals()[f\"{k}_model{mr}\"] for k in model_keys]\n",
        "    binary_accuracies = b_acc if b_acc is not None else [globals()[f\"{k}_accuracy{mr}\"] for k in model_keys]\n",
        "\n",
        "    multiclass_models = m_models if m_models is not None else [globals()[f\"{k}_model_m{mr}\"] for k in model_keys]\n",
        "    multiclass_accuracies = m_acc if m_acc is not None else [globals()[f\"{k}_accuracy_m{mr}\"] for k in model_keys]\n",
        "\n",
        "    time_input = datetime.strptime(time_input, '%H:%M').strftime('%H:%M')\n",
        "    date_input = datetime.strptime(date_input, '%m/%d/%Y').strftime('%m/%d/%Y')\n",
        "    if s_print:\n",
        "      print(f\"input:{date_input} {time_input} Criteria: {criteria_input} CL: {CL} CW: {CW}\")\n",
        "\n",
        "    input_features = get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\n",
        "    input_features['CL'] = [CL]\n",
        "    input_features['CW'] = [CW]\n",
        "    predictions = []\n",
        "    predictions_multi = []\n",
        "    if not input_features.empty:\n",
        "        table_data = []\n",
        "\n",
        "        for i, name in enumerate(model_names):\n",
        "            # Predict binary\n",
        "            pred_bin, prob_bin = predict_trade_result(binary_models[i], input_features, training_feature_cols)\n",
        "            label_bin = 'Win' if pred_bin == 1 else 'Loss'\n",
        "            acc_bin = f\"{binary_accuracies[i]:.2f}\"\n",
        "            bin_str = f\"{label_bin} ({np.max(prob_bin):.2f}), Acc: {acc_bin}\"\n",
        "\n",
        "            # Predict multiclass\n",
        "            pred_multi, prob_multi = predict_trade_result(multiclass_models[i], input_features, training_feature_cols)\n",
        "            acc_multi = f\"{multiclass_accuracies[i]:.2f}\"\n",
        "            multi_str = f\"Class {label_encoder.inverse_transform([pred_multi])[0]} ({np.max(prob_multi):.2f}), Acc: {acc_multi}\"\n",
        "            table_data.append([name, bin_str, multi_str])\n",
        "            predictions.append(pred_bin)\n",
        "            predictions_multi.append(pred_multi)\n",
        "        predicted_win = predictions.count(1)\n",
        "        predicted_loss = predictions.count(0)\n",
        "        predicted_win_multi = len(predictions)-predictions_multi.count(0)\n",
        "        predicted_loss_multi = predictions_multi.count(0)\n",
        "        trade_decision = \"Win\" if predicted_win > w_threshold else \"Loss\"\n",
        "        trade_decision_multi = \"Win\" if predicted_win_multi >= w_threshold else \"Loss\"\n",
        "        predictions_multi = label_encoder.inverse_transform(predictions_multi).tolist()\n",
        "        max_r = \"\" if trade_decision_multi == \"Loss\" else \"- Max R: \"+str(np.max(predictions_multi))\n",
        "        avg_r = \"\" if trade_decision_multi == \"Loss\" else \"- Average R:\"+str(np.mean([x for x in predictions_multi if x>0]))\n",
        "        # Display table\n",
        "        if s_print:\n",
        "            print(f\"\\n--- ðŸ“Š Combined Model Predictions for {date_input} {time_input} ({criteria_input}) -{mr} ---\\n\")\n",
        "            print(f\"Overall decision: ---- Binary: ** {trade_decision} **  Multi: ** {trade_decision_multi}** ---- {max_r} {avg_r}\")\n",
        "            print(f\"Binary Models: Win Predicted **{predicted_win} time **    Multi Models: Win Predicted **{predicted_win_multi}**\")\n",
        "            print(tabulate(table_data, headers=[\"Model\", \"ðŸ“˜ Binary (Win/Loss)\", \"ðŸ“— Multi-Class (R Bucket)\"], tablefmt=\"fancy_grid\"))\n",
        "        return predictions, predictions_multi\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Prediction could not be made due to invalid inputs or data.\")"
      ],
      "metadata": {
        "id": "x1m7AGY-Q1cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overall Statistic Using Model Prediction"
      ],
      "metadata": {
        "id": "E5V2f13WrWM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overall_stats(df, features_filtered, models, training_feature_cols):\n",
        "    overall_stats_df = pd.DataFrame()\n",
        "    # Ensure required columns for filtering exist in the original df\n",
        "    if 'Profit/Loss' not in df.columns:\n",
        "        df['Profit/Loss'] = df['Profit'] - df['Loss'] - df['Fee']\n",
        "    if 'Trade Duration (hours)' not in df.columns:\n",
        "        df['Trade Duration (hours)'] = (df['exitDateTime'] - df['startDateTime']).dt.total_seconds() / 3600\n",
        "\n",
        "    features_filtered = features_filtered[training_feature_cols]\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # 1. Calculate pred result using feature\n",
        "        # Predict on the entire feature set (features DataFrame)\n",
        "        pred_result = model.predict(features_filtered)\n",
        "\n",
        "        # 2. Use that result to filter df for took trade\n",
        "        # Create a new column based on the prediction\n",
        "        # We only consider trades where the model predicted a \"Win\" (class 1)\n",
        "        df_filtered = df.copy()\n",
        "        df_filtered['Predicted_Result'] = pred_result\n",
        "        df_took_trade = df_filtered[df_filtered['Predicted_Result'] >= 1]\n",
        "        # print(df_took_trade.head( ))\n",
        "        # 3. Overall statistic for filtered data frame\n",
        "        if not df_took_trade.empty:\n",
        "            total_trades = len(df_took_trade)\n",
        "            total_wins = (df_took_trade['Profit/Loss'] > 0).sum()\n",
        "            win_rate = total_wins / total_trades\n",
        "            total_profit = df_took_trade['Profit'].sum()\n",
        "            total_loss = df_took_trade['Loss'].sum()\n",
        "            total_fee = df_took_trade['Fee'].sum()\n",
        "            max_profit = df_took_trade['Profit/Loss'].max()\n",
        "            max_loss = df_took_trade['Profit/Loss'].min()\n",
        "            avg_profit = df_took_trade[df_took_trade['Profit/Loss'] > 0]['Profit/Loss'].mean() if (df_took_trade['Profit/Loss'] > 0).sum() > 0 else 0\n",
        "            avg_loss = df_took_trade[df_took_trade['Profit/Loss'] < 0]['Profit/Loss'].mean() if (df_took_trade['Profit/Loss'] < 0).sum() > 0 else 0\n",
        "            total_time = df_took_trade['Trade Duration (hours)'].sum()\n",
        "            average_time = df_took_trade['Trade Duration (hours)'].mean()\n",
        "            realized_pl = df_took_trade['Profit/Loss'].sum()\n",
        "            avg_r_positive_pl = df_took_trade[df_took_trade['Profit/Loss'] > 0]['R'].mean()\n",
        "            # Append the statistics as a new row to the overall_stats_df\n",
        "            model_stats = {\n",
        "                'Model': model_name,\n",
        "                'Total Trades': total_trades,\n",
        "                'Total Win Count': total_wins,\n",
        "                'Total Loss Count': (df_took_trade['Profit/Loss'] < 0).sum(),\n",
        "                'Total Profit': total_profit,\n",
        "                'Total Loss': total_loss,\n",
        "                'Total Fee': total_fee,\n",
        "                'Win Rate (%)': round(win_rate * 100, 2),\n",
        "                'Average R': round(avg_r_positive_pl, 2),\n",
        "                'Max Profit': round(max_profit, 2),\n",
        "                'Average Profit': round(avg_profit, 2),\n",
        "                'Average Loss': round(avg_loss, 2),\n",
        "                'Total Time (hours)': round(total_time, 2),\n",
        "                'Average Time (hours)': round(average_time, 2),\n",
        "                'Realized Profit/Loss': round(realized_pl, 2),\n",
        "                'R': round(total_profit / (total_loss + total_fee), 2)\n",
        "            }\n",
        "\n",
        "            overall_stats_df = pd.concat([overall_stats_df, pd.DataFrame([model_stats])], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "            print(f\"No trades were 'taken' based on {model_name} predictions.\")\n",
        "            # Add a row of zeros for models with no predicted 'Win' trades\n",
        "            model_stats = {\n",
        "                'Model': model_name,\n",
        "                'Total Trades': 0,\n",
        "                'Total Win Count': 0,\n",
        "                'Total Loss Count': 0,\n",
        "                'Total Profit': 0,\n",
        "                'Total Loss': 0,\n",
        "                'Total Fee': 0,\n",
        "                'Win Rate (%)': 0.0,\n",
        "                'Max Profit': 0.0,\n",
        "                'Average Profit': 0.0,\n",
        "                'Average Loss': 0.0,\n",
        "                'Total Time (hours)': 0.0,\n",
        "                'Average Time (hours)': 0.0,\n",
        "                'Realized Profit/Loss': 0.0\n",
        "            }\n",
        "            overall_stats_df = pd.concat([overall_stats_df, pd.DataFrame([model_stats])], ignore_index=True)\n",
        "    return overall_stats_df"
      ],
      "metadata": {
        "id": "M5zLZ8sTMH2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "LNtN_wbBlSNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df):\n",
        "    df['startDateTime']=pd.to_datetime(df['Start Date'].astype(str) + ' ' + df['Start Time'].astype(str))\n",
        "    # prompt: make Exit date and Exit time column as datetime. Time is on UTC.\n",
        "    df['exitDateTime'] = pd.to_datetime(df['Exit Date'].astype(str) + ' ' + df['Exit Time'].astype(str),)\n",
        "    df['Trade Duration (hours)'] = (df['exitDateTime'] - df['startDateTime']).dt.total_seconds() / 3600\n",
        "    df['Start_Weekday'] = df['startDateTime'].dt.day_name()\n",
        "    df['Exit_Weekday'] = df['exitDateTime'].dt.day_name()\n",
        "    df['Profit/Loss']= df['Profit'] - df['Loss'] - df['Fee']\n",
        "    df['Hour'] = df['startDateTime'].dt.hour\n",
        "    df['Time'] = df['startDateTime'].dt.time\n",
        "    df['15Min'] = df['startDateTime'].dt.strftime('%H:%M')\n",
        "    df['Month'] = df['startDateTime'].dt.month_name()\n",
        "    return df"
      ],
      "metadata": {
        "id": "nNTdHocZkTlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prior_streaks(df):\n",
        "    cl_list = [3]  # First trade starts with CL = 3\n",
        "    cw_list = [0]  # First trade starts with CW = 0\n",
        "\n",
        "    for i in range(1, len(df)):\n",
        "        prev_result = df.loc[i - 1, 'Result']\n",
        "        prev_cl = cl_list[-1]\n",
        "        prev_cw = cw_list[-1]\n",
        "        if prev_result == 'W':\n",
        "            cw = prev_cw + 1\n",
        "            cl = 0\n",
        "        elif prev_result == 'L':\n",
        "            cl = prev_cl + 1\n",
        "            cw = 0\n",
        "        else:\n",
        "            cl = prev_cl\n",
        "            cw = prev_cw\n",
        "\n",
        "        cl_list.append(cl)\n",
        "        cw_list.append(cw)\n",
        "\n",
        "    df['CL'] = cl_list\n",
        "    df['CW'] = cw_list\n",
        "    return df"
      ],
      "metadata": {
        "id": "nQtxnxUj77fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Data Processing Functions"
      ],
      "metadata": {
        "id": "u6UeOEGWOIKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_train_data(train_data):\n",
        "  train_data = train_data.drop(columns=['R', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)','Profit/Loss', 'CL', 'CW'])\n",
        "# train_data = clean_train_data(train_data)"
      ],
      "metadata": {
        "id": "1ctlDP5YVwi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processing_train_data(df, train_data, R_threshold = 7):\n",
        "# Select the desired columns from the original DataFrame\n",
        "# columns_to_copy = ['R', 'Result', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)', ]\n",
        "  df['Result_R'] = df.apply(\n",
        "      lambda row: np.floor(min(row['R'], R_threshold)) if row['Result'] == 'W' else 1,\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  count_feature = ['CL','CW',]\n",
        "  ema_features = ['15M_9C21','15M_21C50', '1H_12C26', '1H_13C34', '4H_20C50', '4H_50C200',]\n",
        "  volume_features = [ '15M_volume_spike', '15M_volume_norm',\n",
        "                      '1H_volume_spike', '1H_volume_norm',\n",
        "                      '4H_volume_spike', '4H_volume_norm']\n",
        "\n",
        "  features_column_to_copy = count_feature + ema_features + volume_features\n",
        "\n",
        "  columns_to_copy = ['R', 'Result','Result_R', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)', ]\n",
        "  # columns_to_copy.extend(features_column_to_copy)\n",
        "  columns_to_copy.extend(count_feature)\n",
        "\n",
        "  # print(columns_to_copy)\n",
        "\n",
        "  # Copy these columns to the train_data DataFrame\n",
        "  for col in columns_to_copy:\n",
        "      if col in df.columns: # Check if the column exists in the original df\n",
        "          train_data[col] = df[col]\n",
        "      else:\n",
        "          print(f\"Warning: Column '{col}' not found in the original DataFrame.\")\n",
        "\n",
        "  # Convert 'Result' column to 0 or 1\n",
        "  train_data['Result'] = train_data['Result'].apply(lambda x: 1 if x == 'W' else 0)\n",
        "  return train_data\n",
        "\n"
      ],
      "metadata": {
        "id": "I2fpmW8ZUA6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_read_train_data(train_data, name ='train_data'):\n",
        "  train_data.to_excel('train_data.xlsx', index=False)\n",
        "  train_data = pd.read_excel('train_data.xlsx', index_col=None)\n",
        "  train_data = train_data.loc[:, ~train_data.columns.str.contains('^Unnamed')]\n",
        "  return train_data\n",
        "\n"
      ],
      "metadata": {
        "id": "qp8KP229XsaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_train_data(train_data):\n",
        "  print(train_data.shape)\n",
        "  print(train_data.columns)\n",
        "\n",
        "# check_train_data(train_data)"
      ],
      "metadata": {
        "id": "WTAXXLpTWR5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_train_data_type(train_data):\n",
        "    # Convert 'Result' column to 0 or 1\n",
        "    for col in train_data.columns:\n",
        "      try:\n",
        "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce') # Convert to numeric first\n",
        "        train_data[col] = train_data[col].fillna(0).astype(int) # Fill NaN created by coerce and convert to int\n",
        "      except ValueError:\n",
        "        print(f\"Could not convert column '{col}' to integer.\")\n",
        "        # Optionally handle columns that cannot be converted to int\n",
        "\n",
        "    # Display the first few rows and the data types to verify\n",
        "    # print(train_data.head())\n",
        "    # train_data.dtypes\n",
        "    return train_data\n",
        "\n",
        "# train_data = convert_train_data_type(train_data)"
      ],
      "metadata": {
        "id": "HK-eANL_XuU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ptarget_feature(train_data):\n",
        "    prediction_target = train_data[['Result', 'Result_R']]\n",
        "    # Features for the model will be the cleaned DataFrame without the target and original result/R columns\n",
        "    features = train_data.drop(columns=['Result', 'Result_R'], errors='ignore')\n",
        "    features_filtered = features.drop(columns=['R', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)','Profit/Loss'], errors='ignore')\n",
        "\n",
        "\n",
        "    return features, features_filtered, prediction_target"
      ],
      "metadata": {
        "id": "TWe4EwHnV4Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_ptarget_feature(features, prediction_target):\n",
        "    print(f\"number of features: {features_filtered.shape}\")\n",
        "    print(f\"Number of unique values in prediction target: {prediction_target['Result_R'].nunique()}\")\n",
        "    print(\"List of unique values in prediction target:\", prediction_target['Result_R'].unique().tolist())"
      ],
      "metadata": {
        "id": "849NB6r2bhpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Split"
      ],
      "metadata": {
        "id": "Psi3P9fXOokM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(features, prediction_target):\n",
        "    # X contains the features, y contains the target variable\n",
        "    # X_train_P, X_test_P, y_train, y_test = train_test_split(features, prediction_target, test_size=0.1, random_state=42, stratify=prediction_target['Result_R'])\n",
        "    # X_train_P, X_test_P, y_train, y_test = train_test_split( features, prediction_target, test_size=0.1, shuffle=False)\n",
        "    X_train_P, X_test_P, y_train, y_test = train_test_split( features, prediction_target, test_size=5, shuffle=False)\n",
        "\n",
        "    X_train = X_train_P.drop(columns=['R', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)','Profit/Loss'], errors='ignore')\n",
        "    X_test = X_test_P.drop(columns=['R', 'Profit', 'Loss', 'Fee', 'Trade Duration (hours)','Profit/Loss'], errors='ignore')\n",
        "\n",
        "    y_train_m = y_train['Result_R']\n",
        "    y_test_m = y_test['Result_R']\n",
        "\n",
        "    y_train = y_train['Result']\n",
        "    y_test = y_test['Result']\n",
        "    return X_train, X_test, y_train, y_test, y_train_m, y_test_m, X_train_P, X_test_P"
      ],
      "metadata": {
        "id": "s0Ti0A7QWlTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_split_data(X_train, X_test, y_train, y_test, y_train_m, y_test_m):\n",
        "  print(\"Shape of X_train:\", X_train.shape)\n",
        "  print(\"Shape of X_test:\", X_test.shape)\n",
        "  print(\"Shape of y_train:\", y_train.shape)\n",
        "  print(\"Shape of y_test:\", y_test.shape)\n",
        "  print(\"Shape of y_train_m:\", y_train_m.shape)\n",
        "  print(\"Shape of y_test_m:\", y_test_m.shape)"
      ],
      "metadata": {
        "id": "cASu5xr6cPUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_model_result(model_name, accuracy, class_report):\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(class_report)"
      ],
      "metadata": {
        "id": "7rMTsrgZc7Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Average-R Models"
      ],
      "metadata": {
        "id": "mH_G8GXLbYaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "s1dtW5rPAdZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = prepare_data(df_main)\n",
        "df= calculate_prior_streaks(df)\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w0zBzs6SyYY",
        "outputId": "17e9517d-7649-40a5-e33e-7ac1cdeed143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['S/l', 'Start Date', 'Start Time', 'Criteria', 'Candle/Days', 'Signal',\n",
              "       'Entry', 'Stop Loss', 'Profit Target', 'Result', 'SL', 'Profit', 'Loss',\n",
              "       'Fee', 'Remaining Balance', 'R', 'Target', 'CR', 'C Target', 'Comment',\n",
              "       'Cum Loss', 'Exit Date', 'Exit Time', 'startDateTime', 'exitDateTime',\n",
              "       'Trade Duration (hours)', 'Start_Weekday', 'Exit_Weekday',\n",
              "       'Profit/Loss', 'Hour', 'Time', '15Min', 'Month', 'CL', 'CW'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precomputed_stats = get_precomputed_stats(df)\n",
        "joblib.dump(precomputed_stats, 'precomputed_stats.pkl')\n",
        "precomputed_stats = joblib.load('precomputed_stats.pkl')"
      ],
      "metadata": {
        "id": "VdnXDeuEAkUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regular_binary_precomputed_stats = precomputed_stats"
      ],
      "metadata": {
        "id": "wqWBSCZcS8wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = get_train_data(df, precomputed_stats)\n",
        "# train_data.info()"
      ],
      "metadata": {
        "id": "D51ODVKKNJlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = processing_train_data(df, train_data)\n",
        "train_data = save_read_train_data(train_data)\n",
        "# train_data.info()"
      ],
      "metadata": {
        "id": "L86UbYulyj21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, features_filtered, prediction_target = extract_ptarget_feature(train_data)\n",
        "show_ptarget_feature(features, prediction_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvGRcsknTUNF",
        "outputId": "5c5d1393-7467-4269-91cb-7aeb97f88f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of features: (3134, 83)\n",
            "Number of unique values in prediction target: 7\n",
            "List of unique values in prediction target: [5, 7, 6, 1, 3, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, y_train_m, y_test_m, X_train_P, X_test_P= split_data(features, prediction_target)\n",
        "training_feature_cols = X_train.columns"
      ],
      "metadata": {
        "id": "3iOyarn2NcPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(training_feature_cols, 'training_feature_cols.pkl')\n",
        "training_feature_cols = joblib.load('training_feature_cols.pkl')\n",
        "show_split_data(X_train, X_test, y_train, y_test, y_train_m, y_test_m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "461IYVQ6Uflp",
        "outputId": "c98f47c5-5c54-492c-a155-0ab6cd91cbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (3129, 83)\n",
            "Shape of X_test: (5, 83)\n",
            "Shape of y_train: (3129,)\n",
            "Shape of y_test: (5,)\n",
            "Shape of y_train_m: (3129,)\n",
            "Shape of y_test_m: (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Binary Models - Average R"
      ],
      "metadata": {
        "id": "EZkWEHxsN1_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "s4xYPruLl4_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RF(X_train, X_test, y_train, y_test, n_estimators=100):\n",
        "    RF_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    RF_model.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    # print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "    importances = RF_model.feature_importances_\n",
        "    features_df = pd.DataFrame({\n",
        "        'Feature': X_train.columns,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot\n",
        "    # features_df.plot.bar(x='Feature', y='Importance', figsize=(12, 4), title='Feature Importances')\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    start_time = time.time()\n",
        "    y_pred_RF= RF_model.predict(X_test)\n",
        "    end_time = time.time()\n",
        "    # print(f\"Prediction time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    RF_accuracy = accuracy_score(y_test, y_pred_RF)\n",
        "    RF_class_report = classification_report(y_test, y_pred_RF)\n",
        "    return RF_model,y_pred_RF, RF_accuracy, RF_class_report\n",
        "\n",
        "RF_model,y_pred_RF, RF_accuracy, RF_class_report = RF(X_train, X_test, y_train, y_test, n_estimators=100)\n",
        "show_model_result(\"Random Forest\", RF_accuracy, RF_class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjRx2AH0W7CR",
        "outputId": "223a0c05-544e-40d7-dbc8-d94955f4dee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XVG Boost"
      ],
      "metadata": {
        "id": "kY7tQ8uAmA9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def XVG(X_train, X_test, y_train, y_test, eval_metric='loggloss'):\n",
        "    XVG_model = XGBClassifier(eval_metric=eval_metric)\n",
        "    XVG_model.fit(X_train, y_train)\n",
        "    importances = XVG_model.feature_importances_\n",
        "    features_df = pd.DataFrame({\n",
        "        'Feature': X_train.columns,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot\n",
        "    # features_df.plot.bar(x='Feature', y='Importance', figsize=(12, 4), title='Feature Importances')\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    y_pred_XVG = XVG_model.predict(X_test)\n",
        "    XVG_accuracy = accuracy_score(y_test, y_pred_XVG)\n",
        "    XVG_class_report = classification_report(y_test, y_pred_XVG)\n",
        "    return XVG_model,y_pred_XVG, XVG_accuracy, XVG_class_report\n",
        "\n",
        "XVG_model,y_pred_XVG, XVG_accuracy, XVG_class_report = XVG(X_train, X_test, y_train, y_test, eval_metric='logloss')\n",
        "show_model_result(\"XGBoost\", XVG_accuracy, XVG_class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfkslPnbe-Oy",
        "outputId": "2f81544f-06cb-4a37-af46-955d249cc087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: XGBoost\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistic Regression"
      ],
      "metadata": {
        "id": "XOMxKUO3mF31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def LR(X_train, X_test, y_train, y_test, solver='lbfgs', max_iter=10000):\n",
        "# Logistic Regression (with scaling\n",
        "# Pipeline: Scaling + Logistic Regression\n",
        "    LR_model = make_pipeline(StandardScaler(), LogisticRegression(solver=solver, max_iter=max_iter,random_state=42))\n",
        "    LR_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred_LR = LR_model.predict(X_test)\n",
        "    LR_accuracy = accuracy_score(y_test, y_pred_LR)\n",
        "    LR_class_report = classification_report(y_test, y_pred_LR)\n",
        "    # feature_ranking = pd.DataFrame({\n",
        "    #     'Feature': X_train.columns,\n",
        "    #     'Rank': ranking,\n",
        "    #     'Selected': lr_pipeline.support_\n",
        "    # }).sort_values(by='Rank')\n",
        "\n",
        "    # print(\"Top Selected Features:\")\n",
        "    # print(selected_features.tolist())\n",
        "    # print(\"\\nFull Feature Ranking:\\n\", feature_ranking)\n",
        "    return LR_model,y_pred_LR, LR_accuracy, LR_class_report\n",
        "\n",
        "LR_model,y_pred_LR, LR_accuracy, LR_class_report = LR(X_train, X_test, y_train, y_test, solver='lbfgs', max_iter=10000)\n",
        "show_model_result(\"Logistic Regression\", LR_accuracy, LR_class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0t_dF-0fZZ_",
        "outputId": "57964393-18af-4972-8871-d986d34cca95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voting Classifier"
      ],
      "metadata": {
        "id": "kFsx1eYqmQ_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def VC(X_train, X_test, y_train, y_test, max_iter= 1000, eval_metric='logloss', voting='soft', ul_enc=False):\n",
        "    lr_p1= make_pipeline(StandardScaler(), LogisticRegression(max_iter=max_iter, random_state=42))\n",
        "    VC_model = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', lr_p1),\n",
        "            ('rf', RandomForestClassifier(random_state=42)),\n",
        "            ('xgb', XGBClassifier(eval_metric=eval_metric, use_label_encoder=ul_enc, random_state=42))\n",
        "        ],\n",
        "        voting=voting  # use 'hard' for majority vote or 'soft' for averaged probabilities\n",
        "    )\n",
        "\n",
        "    VC_model.fit(X_train, y_train)\n",
        "    y_pred_VC = VC_model.predict(X_test)\n",
        "\n",
        "    VC_accuracy = accuracy_score(y_test, y_pred_VC)\n",
        "    VC_class_report = classification_report(y_test, y_pred_VC)\n",
        "    return VC_model,y_pred_VC, VC_accuracy, VC_class_report\n",
        "\n",
        "VC_model,y_pred_VC, VC_accuracy, VC_class_report = VC(X_train, X_test, y_train, y_test, max_iter= 1000, eval_metric='logloss', voting='soft', ul_enc=False)\n",
        "show_model_result(\"Voting Classifier\", VC_accuracy, VC_class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc1a9So_HIDf",
        "outputId": "947b1661-3d31-4da5-d3e8-fc24ba065ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:14:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Voting Classifier\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stacking Classifier"
      ],
      "metadata": {
        "id": "XcACfekrmU61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def S(X_train, X_test, y_train, y_test, max_iter= 1000, eval_metric='logloss', cv =5, n_jobs=-1, ul_enc=False):\n",
        "\n",
        "    lr_p2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=max_iter, random_state=42))\n",
        "    base_models = [\n",
        "        ('lr', lr_p2),\n",
        "        ('rf', RandomForestClassifier(random_state=42)),\n",
        "        ('xgb', XGBClassifier(eval_metric=eval_metric, use_label_encoder=ul_enc, random_state=42))\n",
        "    ]\n",
        "    final_estimator = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        LogisticRegression(max_iter=max_iter, random_state=42)\n",
        "    )\n",
        "    S_model = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=final_estimator,  # You can also use XGBClassifier here\n",
        "        passthrough=True,  # Optional: pass original features to meta-model\n",
        "        cv=cv,\n",
        "        n_jobs=n_jobs\n",
        "    )\n",
        "\n",
        "    S_model.fit(X_train, y_train)\n",
        "    y_pred_S = S_model.predict(X_test)\n",
        "\n",
        "    S_accuracy = accuracy_score(y_test, y_pred_S)\n",
        "    S_class_report = classification_report(y_test, y_pred_S)\n",
        "    return S_model, y_pred_S, S_accuracy, S_class_report\n",
        "\n",
        "S_model,y_pred_S, S_accuracy, S_class_report = S(X_train, X_test, y_train, y_test, max_iter= 1000, eval_metric='logloss', cv=5, n_jobs=-1, ul_enc=False)\n",
        "show_model_result(\"Stacking Classifier\", S_accuracy, S_class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHXXGjv_Hcfi",
        "outputId": "c18a9824-8fdb-4d64-eada-8cd96dd711ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Stacking Classifier\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Result Analysis & Visualization"
      ],
      "metadata": {
        "id": "YZAIk0iBmeAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['RandomForest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "\n",
        "regular_binary_predictions = [y_pred_RF, y_pred_XVG, y_pred_LR, y_pred_VC, y_pred_S]\n",
        "# Plot the confusion matrices horizontally\n",
        "regular_binary_confustion_matrix = plot_confusion_matrices_horizontal(y_test, regular_binary_predictions, model_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "fOxcdMRpAGyE",
        "outputId": "1c45a418-c0a0-4e1a-9219-d307466988e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAJOCAYAAABYwk4SAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAnsxJREFUeJzs3Wd0VNX79vFr0kOANCAJLfTelaZISEJRiiCCICJFREUUJdKVLiAWRBBF/UmRphQbRUUhKE2KiihVFKQYkZKEnpBkPy94Mn+GZCCBGWYC389aWcvZZ59z7hlXuDL3nNnHYowxAgAAAAAAAAAAWXi4ugAAAAAAAAAAANwVTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXTAiUaNGiWLxWL9CQ0NVaNGjbRixYqbWketWrXUo0ePm3a+NWvW2Dzvy3+OHz9+0+q4mgMHDmjUqFH6559/XF0KAOAWde+996p8+fJKSUmxGf/pp5/k5eWlt99+2zp24sQJDRkyRFWqVFG+fPmUL18+VatWTS+88IIOHDhgnXfgwAGbXPXw8FCxYsXUpUsX/f333zfrqWUxatQobdiwwWXnBwC4n1GjRil//vw35VyZ70G3bt2a433sZZfFYtHrr7/ukHoyfwICAlS9enW99dZbSk9Pv6Fju6sePXqoWrVqri4DcBovVxcA3Or8/f21evVqSdI///yj8ePHq02bNlq7dq3uuusuF1fnXDNnzlSlSpVsxoKCglxTzBUOHDig0aNHq3Xr1ipatKirywEA3IKmTZumatWqafz48Ro9erQkKT09XU8++aTq1Kmjp59+WpK0b98+xcTE6OLFi+rXr5/q1q0ri8Win3/+WdOnT9eGDRu0ceNGm2OPHz9e0dHRysjI0J9//qkRI0aoZcuW2r59uzw9PW/6cx09erTy589/y/9tAwBwT3Xq1NHGjRtVuXLlHO9jL7s2btyoyMhIh9SV+Z44OTlZs2fP1vPPP6/z589ryJAhDjm+Oxk+fLjOnj3r6jIAp6GJDjiZh4eHGjRoYH1cv359lShRQrNnz77l32hWq1ZNd955p8OOl56eroyMDHl7ezvsmAAAOEvZsmU1bNgwvfzyy+rSpYsqVqyoqVOnatu2bdqyZYs8PC59KbRLly5KS0vTTz/9ZPPBbmxsrJ577jnNnTs3y7HLly9v/fvirrvuUsGCBdWuXTvt2bNHVapUuTlPEAAAN1GwYEGb9903wlHHkWzfEzdr1ky//PKLZs6cedOa6OfPn5e/v/9NOVfZsmVvynkAV2E5F+AmK1asmAoXLqyDBw9KkhISEvTYY4+pTJky8vf3V/ny5TVs2LAsX/22WCx69dVXNWrUKIWFhalQoULq2bNnlk96N2zYoDvuuEN+fn6qVq2avvrqq2zr+PTTT1WrVi35+fmpaNGiiouL04ULF6zbM79+9s033+ihhx5S/vz5VbJkSc2fP1+SNGXKFJUsWVIhISF6/PHHs9R7LSdPntRjjz2mQoUKyd/fX3fddZd++OEHmzlNmjRR69atNXv2bFWsWFG+vr769ddfJUnLly9X/fr15e/vr8KFC6tPnz42r8XFixc1cOBAlSxZUr6+voqIiFCbNm2UnJysNWvWKDo6WpKsV/tZLJZc1Q8AQE4MHjxYpUuXVp8+fXTo0CENHz5czz77rGrXri1JWrt2rbZs2aKXXnop229G+fj46LHHHrvmeQoUKCDpUv5d7r333rNmaKlSpfTyyy8rIyPDZs5vv/2mFi1aKCAgQIGBgerQoYP175RMM2bMUNWqVeXv729dnm7Lli2SZM3QgQMHWjN1zZo1OXuBAAC3tZxkUHJysrp27aoCBQqoSJEiGjZsmN544w2b93DZLedyvdmV3XIuy5cv19133618+fIpODhYTZo00S+//JKr5+rh4aEaNWpkeX6HDx9W165dre+NGzdurJ9++slmTmpqqvr166eQkBAFBQXpySef1Pz582WxWKzLvmUu+TZr1iz17t1boaGhqlevniQpJSVFw4YNU2RkpHx9fVW5cmXre/tMO3bsUMuWLRUaGqp8+fKpYsWKevXVV3O8PbvlXHLy/zenvQ7A1bgSHbjJzpw5o5MnT6p06dKSpOPHjyskJESTJk1ScHCw9u7dq1GjRikhIUEzZ8602fftt9/WPffco9mzZ2vv3r0aOHCgwsLC9Morr0iS/v33X7Vo0ULVq1fXwoULlZiYaG0u16pVy3qcL7/8Uh06dFDnzp31yiuvaPfu3Ro2bJgOHjyoxYsX25yzT58+6tGjh3r37q0PPvhAjz76qH799Vf9/vvvmj59uv766y/FxcWpTJkyGjZsmM2+6enpSktLsz728PCQh4eH0tPTdd999+mvv/7SxIkTFRYWpilTpqhZs2bWDwEybd26VQcOHNCYMWMUHBysEiVKaPHixerUqZN69uyp0aNHKyEhQUOGDFFiYqI+/vhjSdKECRM0ffp0TZw4UVWrVtXx48e1cuVKpaSkqE6dOpo2bZr69u2b7ZIzAAA4io+Pj959913FxMSocePGCgoK0pgxY6zbM9+wN2/ePFfHzcjIUFpamnU5l1GjRqlSpUo2b16nTp2qfv366dlnn1Xr1q21YcMGjRo1SklJSdbmwKFDh9S4cWOVLVtWc+fO1YULF/Tiiy8qKipK27dvV4ECBfTDDz+oV69eGjBggFq2bKlz585p8+bNSkpKknTpa+8NGzbUs88+qy5dukgSV8MDAK4pJxkkST179tTq1av16quvKjIyUh988EGWJvOVHJldn3zyiR5++GG1bdtW8+fPl4+Pj9avX68jR45YPxTPqb///tvaC5CkxMRENWrUSPnz59fUqVMVGBioqVOnKiYmRn/88YeKFCkiSRoyZIjee+89jRkzRrVq1dLixYvtXs0+dOhQtWrVSgsWLLB+cP7QQw9p3bp1GjlypCpXrqwVK1aoa9euCg4O1n333SdJatOmjcLCwvThhx8qMDBQ+/bt0+HDh63Hvdb2K+X0/6907V4H4BYMAKcZOXKkCQgIMBcvXjQXL140f//9t+nUqZMJDg42u3fvznafixcvmnnz5hkvLy9z9uxZ67gkU69ePZu53bt3N2XLlrU+Hjx4sClQoIBJSkqyjq1atcpIMt27d7eO1a5d2zRs2NDmWO+9956RZLZv326MMSY+Pt5IMoMGDbLOSUpKMp6enqZEiRImNTXVOv7ggw+aWrVqWR9n7nvlT69evYwxxnzxxRdGkvn666+t+6SmppqSJUua9u3bW8eioqKMt7e3OXjwoHUsIyPDREZGmocfftim/q+++spYLBbz+++/G2OMadWqlc2xrpRZ45YtW+zOAQDAUWJiYowkM2/ePJvxp556ykgyFy5csBlPS0uz/v1w8eJF6/j+/fuzzdiSJUuaHTt22OxfqFAh07lzZ5vjDh061Pj4+Jjjx48bY4zp37+/CQgIMCdOnLDO2bVrl7FYLGbKlCnGGGNee+01ExISctXnJ8m89tpruXhFAAC3usz3w/bkJIN27NhhJJmPPvrIOic9Pd2UL1/eXN7SuvL93Y1k1+XjGRkZpnjx4qZFixY5eMb/J7OeH3/80Vy8eNEcP37cvPbaa8ZisZiPP/7YOm/EiBEmMDDQHD161Dp24cIFU7JkSTNw4EBjjDEnTpwwfn5+ZsyYMTbniI2NNZLM/v37jTH/9zfCvffeazNv9erVRpL55ptvbMY7depk6tata4wx5tixY0aS+fLLL7N9Ptfabsyl/kTVqlWtj3Py/9eYnPU6AHfAci6Ak509e1be3t7y9vZWZGSkFi9erDlz5qhixYqSJGOMJk+erCpVqsjf31/e3t565JFHlJaWpr/++svmWM2aNbN5XKVKFZtPfjdt2qTo6GgFBgZax2JiYhQSEmJ9fObMGW3btk0dOnSwOVanTp0kSevWrbN7zsDAQBUpUkSNGze2WZe8QoUKOnToUJbn/tFHH2nLli3Wn+HDh0u69NX1ggULqkWLFta53t7eat++fZbz16hRQyVKlLA+3rt3r/7++2899NBDSktLs/5ERUXJw8PD+vW9OnXqaMWKFRo1apS2bNmS5avrAADcLDt37tTatWuvuszJlcuK1axZ0/r3g7e3t44fP26zfeLEidqyZYs2b96szz77TEWLFtW9996rI0eOSJJ2796t48ePq2PHjjb7derUSampqdq8ebOkS5l85d8KlSpVUs2aNa2ZXKdOHZ08eVI9evTQt99+q3Pnzt3Q6wEAgJSzDMpcfuX++++3zvHw8FCbNm2uemxHZdeePXt0+PDhHC2tlp0GDRrI29tbhQoV0sCBAzV48GDre29JWrlypaKjoxUSEmJ9b+vp6amoqCjrc//tt9904cIFm9dAktq2bZvtOVu1amXzeOXKlQoJCVFMTIzNe+jMNdrT09MVGhqqyMhIDR06VLNnz85yhfm1tmcnJ/9/M12r1wG4A5rogJP5+/try5Yt2rRpk+bOnauIiAh169ZNCQkJkqTJkyfrhRdeUNu2bfXFF19o8+bNmjZtmiTZrFEuSUFBQTaPfXx8bNYiT0hIsH7d63KXjyUlJckYo7CwMJs5gYGB8vX11cmTJ695zuzGrqxVkipXrqw777zT+pN5h/PExMRs6wwLC8ty/ivrzGwiPPDAAzbNhXz58ik9Pd3azH/xxRc1ePBgzZ49W/Xq1VN4eLhGjx4tY0yW8wIA4CzGGPXp00fly5fX22+/rf/973/68ccfrdsz10G/8o3iJ598oi1btmjkyJHZHrdMmTK68847VbduXbVr105ffvmljhw5ojfffFPSpayVsuZo5uPMvE1MTMwyJ3Ne5pyYmBjNmTNHO3bsUIsWLVSoUCF169YtS2YDAJAbOcmghIQEeXt721woJinb95OXc1R2nThxQpKyvW9JTmReWLZ8+XI1atRIEydO1Ndff23dfvz4cX3++ec27229vb01Z84c63vbzN5B4cKFbY5t7zXI7j30yZMns5zj8ccfV1pamhISEmSxWLRy5UpVrlxZffv2VYkSJXTnnXda71t2re3Zycn/30zX6nUA7oA10QEn8/DwsN6Nu169eqpYsaLq16+vMWPG6N1339WiRYt0//33a8KECdZ9du7ceV3nioiI0H///Zdl/PKxoKAgWSyWLPOSk5OVkpJi8ymxs4SEhGRb59GjR7Oc/8or8zK3v/3226pfv36WY2T+cePr66tRo0Zp1KhR2rdvn2bMmKFRo0apTJkyevTRRx31VAAAuKpZs2Zp7dq1WrNmje655x7NnTtXffr00datW+Xp6akmTZpIunSV2FNPPWXdr2rVqpKk33//PUfnKVy4sAoVKqQdO3ZI+r+8vDJvjx49arP9aplcoUIF6+OuXbuqa9euOn78uL744gv1799f3t7e+vDDD3NUHwAAV8pJBkVEROjixYtKTk62aaRnt9+VHJFdoaGhkqR//vknx/tcLvPCMklq3LixKlasqBdeeEEtWrSQxWJRSEiI7r33Xo0dOzbLvr6+vpIuvQaSdOzYMZtmvr3XILv30IULF9aKFSuynZ/ZjK9QoYIWLVqkixcvasOGDRo2bJjatGmjI0eOKH/+/NfcfqWc/o0B5BVciQ7cZHfeeacefvhhzZw5U//++6/Onz8vHx8fmznz5s27rmPXq1dP8fHxSk5Oto6tXr3a5lPe/PnzW29EcrmFCxdKkho1anRd586NRo0a6dSpU1q5cqV1LC0tTZ999tk1z1+pUiUVL15cf/31l81V7pk/2V0hUK5cOY0fP14hISHatWuXJFlf8+yuoAcAwBFOnDihgQMHqnv37mrcuLEsFoveffdd/fbbb5o6daok6Z577lHdunX18ssvW680ux5Hjx7V8ePHVahQIUlSxYoVVbhwYS1atMhm3sKFC+Xj46N69epJupTJq1atsl65Ll366vr27duzzeRChQqpV69eatasmTVTpUvLspGpAIDcyEkGZTagv/jiC+ucjIwMLV26NMfnuZHsqlixoooXL66ZM2fm+Hz25M+fX6NHj9bOnTv1+eefS5KaNm2qnTt3ZvkW95133qnq1atLkqpVqyY/Pz+b10CS9RjX0rRpUx07dkw+Pj7Zvoe+sh/h7e2tqKgoDRkyRKdOncryAcK1tmfK7d8YgLvjSnTABYYPH66PP/5YkydPVrNmzfTWW2/p7bffVoUKFTR37lzt27fvuo77/PPPa9q0abrvvvs0ZMgQJSYmauTIkdZPzzONGjVK7dq1s34yv2fPHg0bNkwPPvigNaidqVWrVqpXr566du2qV155RWFhYZo6daoSEhI0bNiwq+5rsVg0adIkdenSRWfPnlWrVq0UEBCgv//+W8uXL9f48eNVoUIFtWvXTnfccYdq166tgIAALV26VImJiYqJiZF06VN2T09PzZgxQ15eXvLy8rL+gQYAgCMMHDhQkvTaa69Zx2rWrKlnn31WI0aM0EMPPaSiRYtq/vz5iomJUZ06dfTcc8+pbt268vDw0IEDBzR9+nT5+vra3ItEkv744w/9+OOPMsboyJEjeu2112SxWNS7d29Jkqenp4YPH65+/fqpSJEiatmypX788UdNnDhRzz//vPVvg/79+2vmzJlq3ry5XnzxRV24cEEvvfSSSpYsqR49ekiSRo4cqRMnTqhJkyYqUqSIfvvtN3399deKi4uz1lO5cmV98cUXuueeexQQEKCKFSuqQIECznx5AQB5QHp6epYLuKRLF4DlJIOqVq2qBx54QP369dO5c+cUGRmp999/X+fPn89yxfXlHJVdFotFr7/+uh5++GE9+OCD6tatm3x9fbVx40bVrVtXrVu3ztXr0b17d40fP14TJ07UAw88oLi4OM2bN09RUVF67rnnVLJkSR07dkybNm1S0aJF1b9/f4WGhqpPnz4aN26c/Pz8VKtWLS1atEh79+6VdOnb71fTrFkztWnTRvfee68GDRqkGjVq6OzZs9qxY4f27dun//3vf9q+fbteeOEFderUSWXLllVycrImTJigUqVKqWzZstfcnp2c/P8F8hSX3tYUuMVd7W7kjzzyiClYsKBJSkoyPXr0MMHBwSY4ONj07t3bLF261ObO4sZkf+fwN99801z5a/zDDz+YWrVqGR8fH1O5cmWzbNkyU7NmTdO9e3ebeYsXLzY1atQwPj4+Jjw83Dz//PPm/Pnz1u1X3t08U2RkpOnbt+9Vn6e9fS93/Phx06NHDxMSEmJ8fX1Nw4YNzZo1a2zmREVFmVatWmW7/8qVK01UVJQJCAgwAQEBpmrVquaFF14wSUlJxhhjXn31VXPnnXeawMBAExAQYOrUqWPmz59vc4zp06ebMmXKGC8vryyvIwAAN+KHH34wFovF/O9//8uy7dSpU6Zo0aLmoYceso4dO3bMDBo0yFSqVMn4+fkZf39/U7VqVRMXF2f++usv67z9+/cbSTY/hQoVMrGxseb777/Pcq53333XlC9f3nh7e5uSJUuasWPHmvT0dJs5v/76q2nWrJnJly+fKVCggGnfvr05cOCAdfvSpUtNbGysKVy4sPH19TVly5Y1I0eONBcvXrTOWbt2ralTp47x9/c3kkx8fPyNvHwAgFvAyJEjs2RW5s+cOXOMMdfOIGOMSUxMNI888ogJCAgwoaGhJi4uzrz00ksmKCjIOufK96A3kl3Zvff+8ssvTf369Y2fn58JCgoyMTEx5pdffrH73K/2nviDDz6wOV9CQoLp1auXiYiIMD4+PqZ48eKmQ4cOZv369dZ9UlJSzDPPPGOCgoJMwYIFTffu3c3bb79tJFnfA2f+jbBo0aIs50xJSTGjR4825cuXNz4+PqZw4cImOjrafPTRR8YYY44ePWq6du1qypQpY3x9fU2RIkXMgw8+aPbu3Zuj7cYY0717d1O1alWb8+bk/29Oex2Aq1mM4S57AAAAAAAAyBsaN24sT09PxcfHu7oUl3n00Ue1bt067d+/39WlALcFlnMBAAAAAACAW1qyZIkOHjyo6tWr69y5c5o/f77Wrl2rzz77zNWl3TTff/+91q9frzvuuEMZGRlatmyZ5s2bp0mTJrm6NOC2QRMdAAAAAAAAbil//vyaM2eO/vjjD6WmpqpSpUqaO3eu2rVr5+rSbpr8+fNr2bJlmjhxos6fP6/SpUtr0qRJev75511dGnDbYDkXAAAAAAAAAADsuPotfAEAAAAAAAAAuI3RRAecrGbNmrJYLFq7dq2rS8kTtm7dqp49e6py5cry8PBQ69atc7xvamqqBg4cqPDwcAUEBKhZs2bas2dPlnm7d+9Ws2bNFBAQoPDwcA0aNEipqamOfBoAgDyGvM4d8hoAcLOR1blDVgOORRMdcKIdO3Zo+/btkqT58+e7uJq8Yf369Vq7dq3q1KmjkiVL5mrffv366YMPPtD48eP16aefKiUlRbGxsUpOTrbOSUxMVExMjFJTU/Xpp59q/Pjxev/99xUXF+fopwIAyCPI69wjrwEANxNZnXtkNeBgBoDTDB061Hh4eJjo6GgTGhpqUlNTXV2S1YULF0x6erqry8ji8pqioqJMq1atcrTfoUOHjKenp3nvvfesYydOnDABAQFm4sSJ1rHx48ebgIAAc+LECevYe++9Zzw9Pc2RI0cc8AwAAHkNeZ175DUA4GYiq3OPrAYciyvRAScxxmjBggWKiYlRXFycTpw4oa+//jrLvF27dql9+/YKCQlRvnz5VLNmTS1YsMC6PSMjQ5MmTVLlypXl6+ur8PBwdezY0foJcI8ePVStWjWbYyYlJclisWjWrFnWsVKlSumZZ57Rq6++qsjISPn7++vkyZPavXu3OnfurBIlSihfvnyqUqWK3njjDWVkZNgcMyUlRS+99JLKlCkjX19fFS9eXD169JAkLV26VBaLRX/88YfNPomJifL399c777yT49fNw+P6/llauXKlMjIy1LFjR+tYSEiImjdvrhUrVljHvvrqKzVt2lQhISHWsYceekgZGRlauXLldZ0bAJB3kdfkNQDAvZHVZDXgDmiiA06yYcMGHThwQF26dFGLFi0UGhqa5Wtnf/zxhxo2bKg//vhDU6ZM0ZdffqmePXvq4MGD1jnPPvusBg0apNatW2vp0qWaNm2aChQooDNnzuS6piVLlmjZsmV666239MUXXyggIEBHjhxRxYoV9c4772jFihV64oknNGbMGI0dO9Zm3wcffFCTJk3SY489puXLl+u1117T2bNnJUktW7ZUsWLFNGPGDJt9Mp9vly5dNGvWLFksFq1ZsybXdefE7t27VaRIEQUHB9uMV65cWbt377aZV6lSJZs5QUFBioiIsJkHALg9kNfkNQDAvZHVZDXgDrxcXQBwq5o/f778/PzUvn17eXt7q0OHDpozZ47OnDmj/PnzS5JGjRolHx8frV+/XgULFpQkNW3a1HqMvXv36t1339W4ceM0dOhQ6/iDDz54XTVdvHhRX331lQICAqxjsbGxio2NlXTpE/5GjRrp3LlzevvttzVy5EhJ0rfffqvly5dr/vz5evjhh637Zv63p6enevbsqRkzZujll1+Wp6enJGnGjBlq3769goKC5OHhIU9PT1ksluuq/VoSExMVFBSUZTw4OFgnT57M9TwAwO2BvCavAQDujawmqwF3wJXogBOkpaVp0aJFatmypQIDAyVd+sT43Llz+uyzz6zzVq1apQ4dOlhD/kqrV6+WMUa9evVySF1NmjSxCXlJunDhgkaOHKly5crJ19dX3t7eevHFF5WQkGD9RH7VqlXKly+fOnfubPfYvXr1UkJCgvVrddu3b9fPP/9srb1bt25KS0tTVFSUQ54LAAA3irwmrwEA7o2sJqsBd0ETHXCClStX6tixY2rTpo2SkpKUlJSk6tWrKyIiwuZrZydOnFDRokXtHufEiRPy8vJSkSJFHFJXWFhYlrHBgwfrtddeU+/evbVixQpt2bJFL730kqRLfwRk1hEREXHVT7pLlSqlZs2a6cMPP5R06ZPy0qVLKzo62iG1X0twcLDNncIzJSYm2qzRltN5AIBbH3lNXgMA3BtZTVYD7oImOuAEmWHes2dPBQcHKzg4WCEhIUpISNB3332n//77T5IUGhqqf/75x+5xQkNDlZaWZp2fHT8/P6WmptqMJSYmZjs3u6BetGiRnnzySQ0ePFhNmzbVnXfeKS8v25WeQkNDlZCQIGOM3TokqXfv3lq2bJmOHDmiefPmqWfPnk77itmVKlWqpKNHj2Z57leu01apUqUs67MlJycrISEhy3puAIBbG3lNXgMA3BtZTVYD7oImOuBg586d0xdffKF27dopPj7e5mfBggVKS0vTJ598IunSGm2LFy/W6dOnsz1WTEyMLBaLZs6cafd8xYsX1+HDh21uhpKbO2GfP39ePj4+1sfp6en6+OOPbeY0bdpU586d08KFC696rLZt2yo4OFhdunTRyZMnrXcYvxmaN28uDw8PLVmyxDqWmJiolStXqmXLltax++67T999952SkpKsY4sWLZKHh4eaN29+0+oFALgWeU1eAwDcG1lNVgNuxQBwqPnz5xtJZvXq1dlur127tmnQoIExxpi9e/eawMBAU6NGDTN37lyzatUqM3XqVDNx4kTr/D59+hgvLy8zaNAg880335jPPvvMPP744+bw4cPGGGN27NhhLBaL6dixo1m5cqV58803TdWqVY0kM3PmTOtxIiMjTd++fbPU07FjRxMcHGxmzZplli1bZlq2bGlKly5tJJljx45Z57Vs2dLky5fPjBs3znz33Xdm4cKF5qGHHspyvIEDBxpJpkWLFjbjs2fPNp6enmbNmjVXff3+++8/s2jRIrNo0SJTpUoVc8cdd1gfnz171jqvbNmyJiYmxmbfJ5980gQFBZkZM2aYb775xkRFRZlixYqZpKQk65yTJ0+aiIgIExUVZb755hszY8YMExQUlO1rAwC4dZHX5DUAwL2R1WQ14E5oogMO1rp1a1OyZEmTkZGR7fbJkycbSWbfvn3GmEtBff/995uCBQuafPnymVq1apmPP/7YOj89Pd28+uqrpnz58sbb29uEh4ebTp06meTkZOucjz76yJQrV874+/ubZs2amW3btuU46P/991/Trl07U6BAARMWFmYGDx5sPvjggyxBf/78eTNkyBBTsmRJ4+3tbYoXL24ee+yxLMfbsGGDkWQ++eQTm/GZM2caSSY+Pv6qr198fLyRlO3P/v37bZ5PVFSUzb4XLlwwL7zwgilSpIjx9/c3TZs2Nbt27cpyjp07d5rY2Fjj7+9vihQpYgYMGGBSUlKuWhcA4NZCXpPXAAD3RlaT1YA7sRhzjYWYACAXRowYoXfeeUdHjhyRr6+vq8sBAADZIK8BAHBvZDXgXryuPQUArm3Pnj3as2ePpk6dqr59+xLyAAC4IfIaAAD3RlYD7okr0QE4RJMmTfTjjz/q3nvv1bx58xQQEODqkgAAwBXIawAA3BtZDbgnmugAAAAAAAAAANjh4eoCAAAAAAAAAABwVzTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANjh5eoCnMG/9jOuLgG4pSVuedvVJQC3LL9bMpmzR14DzkNWA851u+Q1WQ04D1kNOJejs5or0QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdri0ib53715t3rzZZmzVqlWKjo5WvXr1NH78eBdVBgAAJLIaAIC8gLwGAMC5XNpEHzx4sJYtW2Z9vH//frVp00Y+Pj5q2LChJkyYoMmTJ7uuQAAAbnNkNQAA7o+8BgDAubxcefKtW7dq0KBB1sfz5s1ThQoV9M0330iSatSooalTp+r55593UYUAANzeyGoAANwfeQ0AgHO59Er048ePq3jx4tbH8fHxatOmjfVxkyZNdODAARdUBgAAJLIaAIC8gLwGAMC5XNpEDwkJUUJCgiQpIyNDW7duVYMGDazbU1NTZYxxVXkAANz2yGoAANwfeQ0AgHO5tInepEkTjR07VocOHdLkyZOVkZGhJk2aWLfv3LlTpUqVcll9AADc7shqAADcH3kNAIBzuXRN9HHjxqlZs2aKjIyUp6enpkyZooCAAOv2OXPmKCYmxoUVAgBweyOrAQBwf+Q1AADOZTEu/k5XWlqaduzYocKFC6to0aI223799VcVL15coaGhuTqmf+1nHFkigCskbnnb1SUAtyw/l368nT1nZLVEXgPORFYDznW75DVZDTgPWQ04l6Oz2qXLuUiSl5eXatasaRPyaWlpOnPmjGrWrHldb8qR9wzo2Uznf3lbrw140NWlALeUj+fP033NYlS3dnU90rmjftu+3dUlIQ8iqyGR1YCzkNVwFPIaEnkNOANZDcnFTfSlS5dq1qxZNmPjxo1T/vz5FRQUpObNmysxMdE1xeGmuaNKSfV68G5t33vY1aUAt5Svv1qh11+doCef7quPF32mihUrqc+TvXTixAlXl4Y8hKyGRFYDzkJWw1HIa0jkNeAMZDUyubSJPmnSJJ09e9b6eMOGDRoxYoSGDx+uhQsX6tChQxo7dqwLK4SzBfj7aOb4Hnp67AIlnTrv6nKAW8qc2TPVvsNDavfAgypbrpxeGjlafn5++vzTJa4uDXkIWQ2yGnAeshqOQl6DvAacg6xGJpc20Xfs2KG77rrL+njx4sVq1qyZXnzxRbVv315vvPGGli5d6sIK4WyTh3bS12t/V/ymPa4uBbilXExN1a6dO9Sg4f/9G+vh4aEGDe7S9l9/cWFlyGvIapDVgHOQ1XAk8hrkNeB4ZDUu59Im+unTp23WZVu3bp1iY2Otj6tWrap//vnHFaXhJujY4g7VqlRCw6d+6epSgFtOYlKi0tPTs6x9GRoaquPHj7uoKuRFZPXtjawGnIeshiOR17c38hpwDrIal3NpE71YsWLatWuXJOnMmTP69ddfbT49P3HihPLly3fVY6SkpOjUqVM2PyYj3al148YVDwvSawMfVM8XZyklNc3V5QAA7HBEVkvkdV5EVgNA3sF769sXeQ0AN4eXK0/esWNHPf/88xo2bJhWrFih8PBwNWjQwLp969atqlix4lWPMWHCBI0ePdpmzDOsrrwj6jmlZjhG7colFRZaUBvnD7aOeXl5qlGdsnqqU2MF1n9eGRnGhRUCeVtwULA8PT2z3OzkxIkTKlSokIuqQl7kiKyWyOu8iKwGnIushiPx3vr2RV4DzkNW43IubaKPGDFCR44cUb9+/RQeHq65c+fK09PTun3BggVq06bNVY8xdOhQxcXF2YwVuWewndlwF/Gb9+iODuNsxt4f3VV79h/VG7O+JeSBG+Tt46PKVapq048bFRPbVJKUkZGhTZs2qvPDXV1cHfISR2S1RF7nRWQ14FxkNRyJ99a3L/IacB6yGpdzaRPd399fH330kd3t8fHx1zyGr6+vfH19bcYsHp52ZsNdnDmXop1/JtiMnT2fqpPJZ7OMA7g+j3bvqeHDBqtq1WqqVr2G5s6ZrfPnz6vdA+1dXRryEEdktURe50VkNeB8ZDUchffWty/yGnAushqZXNpEv9z27du1d+9eSVKFChVUo0YNF1cEAHnbvfe1VOLJk3rn7Sk6fvyYKlaqrHfe+59C+doZrhNZDQCORVbDGchrAHAcshqZLMYYl363Z/PmzerVq5d27typzFIsFouqVq2qDz/8UHXr1s31Mf1rP+PoMgFcJnHL264uAbhl+bnNx9v/xxlZLZHXgDOR1YBz3S55TVYDzkNWA87l6Kz2cOzhcmfnzp2KjY2Vv7+/5s6dq59//lk///yz5syZI19fX8XGxmrnzp2uLBEAgNsaWQ0AgPsjrwEAcC6XXon+0EMPKS0tTUuWLJHFYrHZZoxR+/bt5e3trYULF+bquHxaDjgXn5gDzuNuV7Y5K6sl8hpwJrIacK7bJa/JasB5yGrAuRyd1S6N/vj4eH311VdZQl669LWzYcOGqWXLli6oDAAASGQ1AAB5AXkNAIBzuXQ5l9OnTyssLMzu9vDwcJ0+ffomVgQAAC5HVgMA4P7IawAAnMulTfTIyEht3rzZ7vZNmzYpMjLyJlYEAAAuR1YDAOD+yGsAAJzLpU30zp07Ky4uTr///nuWbb/99psGDBigTp06uaAyAAAgkdUAAOQF5DUAAM7l0huLXrhwQbGxsdq0aZOaNWumypUryxijXbt26bvvvlO9evW0evVq+fn55eq43PwEcC5ugAI4j7vdqMxZWS2R14AzkdWAc90ueU1WA85DVgPO5eisdumV6H5+foqPj9e4ceOUkJCg6dOn67333tO///6rl19+WQsXLlS/fv1cWSIAALc1shoAAPdHXgMA4FwuvRL9Wn799VfVqVNH6enpudqPT8sB5+ITc8B53O3Ktmu53qyWyGvAmchqwLlul7wmqwHnIasB57qlrkQHAAAAAAAAAMCd0UQHAAAAAAAAAMAOmugAAAAAAAAAANjh0pXc2rdvf9XtSUlJN6cQAACQLbIaAAD3R14DAOBcLm2iBwYGXnN7t27dblI1AADgSmQ1AADuj7wGAMC5XNpEnzlzpitPDwAAroGsBgDA/ZHXAAA4F2uiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsuK4m+tq1a9W1a1c1bNhQR44ckSTNmTNH69atc2hxAADg+pDVAAC4P/IaAIC8IddN9CVLlqhFixby9/fXL7/8opSUFElScnKyxo8f7/ACAQBA7pDVAAC4P/IaAIC8I9dN9JdfflnTp0/XBx98IG9vb+v43XffrZ9//tmhxQEAgNwjqwEAcH/kNQAAeUeum+h79uxR48aNs4wHBgYqKSnJETUBAIAbQFYDAOD+yGsAAPKOXDfRw8PDtW/fvizj69atU5kyZRxSFAAAuH5kNQAA7o+8BgAg78h1E71379567rnntGnTJlksFv3zzz+aN2+eBgwYoD59+jijRgAAkAtkNQAA7o+8BgAg7/DK7Q5DhgxRRkaGYmNjde7cOTVu3Fi+vr4aMGCAnn32WWfUCAAAcoGsBgDA/ZHXAADkHRZjjLmeHVNTU7Vv3z6dOXNGVapUUf78+R1d23Xzr/2Mq0sAbmmJW952dQnALcsv1x9v2+fOWS2R14AzkdWAc90ueU1WA85DVgPO5cislq7jSvRMPj4+qlKliiNrAQAADkRWAwDg/shrAADcX66b6NHR0bJYLHa3r169+oYKAgAAN4asBgDA/ZHXAADkHbluoteqVcvm8cWLF7Vt2zb9/vvv6t69u6PqAgAA14msBgDA/ZHXAADkHde9JvqVRo0apTNnzuj11193xOFuyIU0V1cA3Np+OZDk6hKAW1bDckFOO7Y7ZbVEXgPORFYDznW75DVZDTgPWQ04l6Oz2mFN9H379qlevXo6efKkIw53Qwh6wLkIe8B5nPmm3J2yWiKvAWciqwHnul3ymqwGnIesBpzL0Vnt4agDbdy4UX5+fo46HAAAcDCyGgAA90deAwDgfnK9Jnr79u1tHhtjlJCQoK1bt2r48OEOKwwAAFwfshoAAPdHXgMAkHfkuokeGBho89jDw0MVK1bUmDFj1Lx5c4cVBgAArg9ZDQCA+yOvAQDIO3LVRE9PT1fPnj1VvXp1BQcHO6smAABwnchqAADcH3kNAEDekqs10T09PdW8eXMlJSU5qRwAAHAjyGoAANwfeQ0AQN6S6xuLVqtWTX/99ZczagEAAA5AVgMA4P7IawAA8o5cN9FffvllDRgwQMuWLVNCQoJOnTpl8wMAAFyLrAYAwP2R1wAA5B0WY4zJycQxY8bohRdeUIECBf5vZ4vF+t/GGFksFqWnpzu+yly6kObqCoBb2y8HklxdAnDLalgu6Lr3zUtZLZHXgDOR1YBz3S55TVYDzkNWA851I1mdnRw30T09PZWQkKBdu3ZddV5UVJRDCrsRBD3gXIQ94Dw3EvR5Kasl8hpwJrIacK7bJa/JasB5yGrAuRzdRPfK6cTMXrs7BDkAAMiKrAYAwP2R1wAA5D25WhP98q+YAQAA90NWAwDg/shrAADylhxfiS5JFSpUuGbYnzx58oYKAgAA14+sBgDA/ZHXAADkLblqoo8ePVqBgYHOqgUAANwgshoAAPdHXgMAkLfkqoneuXNnFSlSxFm1AACAG0RWAwDg/shrAADylhyvic6abQAAuDeyGgAA90deAwCQ9+S4iZ55B3EAAOCeyGoAANwfeQ0AQN6T4+VcMjIynFkHAAC4QWQ1AADuj7wGACDvyfGV6AAAAAAAAAAA3G5oogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7PBy1Ymjo6NlsViuOsdisWjVqlU3qSIAAHA5shoAAPdHXgMA4Hwua6LXqlXL7rbTp09r/vz5SklJuXkFAQAAG2Q1AADuj7wGAMD5XNZEf/PNN7OMpaWladq0aRo3bpyKFSumsWPHuqAyAAAgkdUAAOQF5DUAAM7nsib6lebNm6cRI0bo/PnzGjVqlJ544gl5eblNeQAA3PbIagAA3B95DQCA47k8Sb/++msNGTJE+/fv14ABAxQXF6eAgABXlwUAAP4/shoAAPdHXgMA4Dwerjrx5s2bFR0drQceeEDR0dH6888/NXz4cEL+NvPx/Hm6r1mM6taurkc6d9Rv27e7uiTglrDn91/05ugX9PyjrdSjVX39tPF7V5eEPIishkRWA85EXsMRyGtI5DXgLGQ1MrnsSvQGDRrI399fTz31lEqXLq358+dnO69fv343uTLcLF9/tUKvvzpBL40crerVa2renNnq82QvfbHsa4WGhrq6PCBPS7lwXiVLl1fjZm00ddxgV5eDPIqsBlkNOBd5DUcgr0FeA85DViOTxRhjXHHiUqVKyWKxXHWOxWLRX3/9letjX0i73qpwMz3SuaOqVquuYS+NkCRlZGSoeWyUHu7yqHr1fsLF1eFqfjmQ5OoSkAs9WtXXsy+9qjsaRrm6FORAw3JBri7ByplZLZHXeQFZnXeR1XkPeZ233C55TVbnDeR13kRW5z1kdd7i6Kx22ZXoBw4ccNWp4QYupqZq184d6tX7SeuYh4eHGjS4S9t//cWFlQEAMpHVtzeyGgDyBvL69kZeA8DN4bI10XF7S0xKVHp6epavloWGhur48eMuqgoAAGQiqwEAcH/kNQDcHC67En3KlCk5mnetddtSUlKUkpJiM2Y8feXr63vdtQEAAMdltUReAwDgLLy3BgDA+VzWRH/zzTevOcdisVwz6CdMmKDRo0fbjL04fKReGjHqRsqDkwUHBcvT01MnTpywGT9x4oQKFSrkoqoAAJdzVFZL5HVeRFYDQN7Ae+vbG3kNADeHy5roq1evVunSpW/4OEOHDlVcXJzNmPHkk3J35+3jo8pVqmrTjxsVE9tU0qWbn2zatFGdH+7q4uoAAJLjsloir/MishoA8gbeW9/eyGsAuDlc1kQvW7asIiMjFR0drZiYGEVHR6tYsWK5Po6vb9avl3EH8bzh0e49NXzYYFWtWk3VqtfQ3Dmzdf78ebV7oL2rSwPyvAvnz+noP4etj4//+4/+/nOv8hcoqNAi4S6sDHmJo7JaIq/zKrIacC7yGo7Ae2uQ14DzkNXIZDHGGFeceM2aNdafTZs2KTU1VWXKlLGGfnR0tMLCwq7r2AR93rFg3lzNnvmhjh8/poqVKmvwsJdUo0ZNV5eFa/jlQJKrS8A17Nr+kyYOfTrL+N2xrdQ7boQLKkJONSwX5OoSrJyZ1RJ5nVeQ1XkTWZ03kNd51+2S12R13kFe5z1kdd5AVuddjs5qlzXRL3fhwgVt2LDBGvybN2/WxYsXValSJe3YsSP3xyPoAaci7AHncac35ZdzdFZL5DXgTGQ14Fy3S16T1YDzkNWAc92STfRMqampWr9+vb766iu99957OnPmjNLT03N9HIIecC7CHnAed31TnslRWS2R14AzkdWAc90ueU1WA85DVgPO5eisdtma6NKlYP/xxx8VHx9v/epZiRIl1LhxY7399tuKiopyZXkAANz2yGoAANwfeQ0AgHO5rIkeExOjTZs2qXTp0oqKitKTTz6p+fPnKyIiwlUlAQCAy5DVAAC4P/IaAADnc1kTfe3atYqIiFBMTIyaNGmiqKgohYaGuqocAABwBbIaAAD3R14DAOB8Hq46cVJSkt5//33ly5dPEydOVNGiRVW9enU988wzWrx4sY4dO+aq0gAAgMhqAADyAvIaAADnc5sbi54+fVrr1q2zruH266+/qnz58vr9999zfSxufgI4FzdAAZzHnW9U5sislshrwJnIasC5bpe8JqsB5yGrAedydFa77Er0KwUEBCgkJEQhISEKDg6Wl5eXdu3a5eqyAADA/0dWAwDg/shrAAAcz2VromdkZGjr1q1as2aN4uPjtX79ep09e1bFihVTdHS0pk2bpujoaFeVBwDAbY+sBgDA/ZHXAAA4n8ua6EFBQTp79qzCw8MVHR2tN998U02aNFHZsmVdVRIAALgMWQ0AgPsjrwEAcD6XNdFfe+01RUdHq0KFCq4qAQAAXAVZDQCA+yOvAQBwPre5sagjcfMTwLm4AQrgPO58ozJHI68B5yGrAee6XfKarAach6wGnOuWvbEoAAAAAAAAAADuhiY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACww2KMMa4uAre3lJQUTZgwQUOHDpWvr6+rywFuKfx+AXAE/i0BnIffLwCOwL8lgHPxOwaa6HC5U6dOKTAwUMnJySpYsKCrywFuKfx+AXAE/i0BnIffLwCOwL8lgHPxOwaWcwEAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiw+V8fX01cuRIbswAOAG/XwAcgX9LAOfh9wuAI/BvCeBc/I6BG4sCAAAAAAAAAGAHV6IDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOm5Yjx491K5du2y3nT9/XiNHjlSFChXk6+urQoUKqWPHjtqxY4fNvHPnzmno0KEqW7as/Pz8VLhwYUVFRemLL76wztm/f7+6dOmiokWLys/PT8WLF1fbtm21e/duZz49wG1Mnz5dBQoUUFpamnXszJkz8vb2VpMmTWzmrlmzRhaLRX/++adKlSqlyZMnW7eVKlVKFotFP/74o80+zz//fJbjALg1kNXAzUNeA7he5DVwc5DVuB400eE0KSkpatq0qWbMmKGXX35Ze/fu1YoVK5SWlqb69evb/CPz1FNP6dNPP9XUqVO1e/duff311+rQoYNOnDghSbp48aKaNWum5ORkffrpp9qzZ48++eQTVa9eXUlJSS56hsDNFR0drTNnzmjr1q3WsbVr1yo8PFybNm3ShQsXrOPx8fEqWbKkypYtm+2x/Pz8NHjwYKfXDMC9kdWA45HXAByNvAYci6zG9fBydQG4dU2ePFkbN27UL7/8opo1a0qSIiMjtWTJEtWvX1+9evXS77//LovFoi+//FJvvfWWWrZsKenSp3l33HGH9Vg7duzQn3/+qVWrVikyMtJ6rLvvvvvmPzHARSpWrKiIiAitWbNGDRo0kHTpU/G2bdtq9erV+vHHH62fdq9Zs0bR0dF2j/XEE09o+vTpWrFihfX3DsDth6wGHI+8BuBo5DXgWGQ1rgdXosNp5s+fr2bNmllDPpOHh4f69++vnTt36tdff5UkhYeHa8WKFTp9+nS2xypcuLA8PDy0ePFipaenO712wF1FR0crPj7e+jg+Pl5NmjRRVFSUdfz8+fPatGnTVYO+dOnSeuqppzR06FBlZGQ4vW4A7omsBpyDvAbgSOQ14HhkNXKLJjqcZu/evapcuXK22zLH9+7dK0l6//33tWHDBoWGhqpu3brq37+/1q9fb51frFgxTZkyRSNGjFBwcLBiYmI0duxY/fXXX85/IoAbiY6O1vr165WWlqbTp0/rl19+UVRUlBo3bqw1a9ZIkjZu3KiUlJSrBr0kvfTSS9q/f7/mzZt3EyoH4I7IasA5yGsAjkReA45HViO3aKLDqYwxOZrXuHFj/fXXX1q1apU6dOigHTt26J577tHYsWOtc/r27at///1X8+bNU8OGDbVo0SJVrVpV3377rbPKB9xOkyZNdPbsWW3ZskVr165VhQoVrDcLyly7bc2aNSpTpoxKlix51WMVLlxYAwYM0IgRI5SamnqTngEAd0NWA45HXgNwNPIacCyyGrlFEx1OU6FCBe3atSvbbZnjFSpUsI55e3vrnnvu0eDBg7Vy5UqNGTNGY8eOtfkHqECBAmrTpo3GjRunX3/9Vffcc49efvll5z4RwI2UK1dOxYsXV3x8vOLj4xUVFSVJKlq0qEqUKKENGzYoPj5eMTExOTpeXFyczp8/r3feeceZZQNwU2Q14BzkNQBHIq8BxyOrkVs00eE0nTt31nfffWddmy1TRkaG3nzzTVWpUiXLmm6Xq1KlitLS0mzuinw5i8WiSpUq6ezZsw6tG3B30dHRWrNmjdasWWO92Yl06aqTr776Sps3b77m180y5c+fX8OHD9e4cePsrpsI4NZFVgPOQ14DcBTyGnAOshq5QRMdDpGcnKxt27bZ/HTt2lX16tVTmzZttGjRIh08eFBbtmzRgw8+qF27dunDDz+UxWKRdOlrNO+9955++uknHThwQCtWrNCwYcMUHR2tggULatu2bWrbtq0WL16snTt3at++ffrwww81Y8YMtW3b1sXPHri5oqOjtW7dOm3bts36abkkRUVF6b333lNqamqOg166dDfxwMBAzZ8/3xnlAnATZDVwc5HXAK4HeQ3cPGQ1csPL1QXg1rBmzRrVrl3bZqxXr15avXq1xo8fr2HDhunvv/9WgQIFFB0drR9//FHVqlWzzm3RooVmz56tYcOG6dy5cypatKhat26tESNGSJKKFy+uUqVKafTo0Tpw4IAsFov1cf/+/W/qcwVcLTo6WufPn1elSpUUFhZmHY+KitLp06dVsWJFRURE5Ph43t7eGjt2rLp06eKMcgG4CbIauLnIawDXg7wGbh6yGrlhMTm9OwUAAAAAAAAAALcZlnMBAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHkK0ePXqoXbt21sdNmjTR888/f9PrWLNmjSwWi5KSkm76uQEAcGdkNQAA7o+8Bm4NNNGBPKRHjx6yWCyyWCzy8fFRuXLlNGbMGKWlpTn93J9++qnGjh2bo7mEMwDgdkVWAwDg/shrALnl5eoCAOTOvffeq5kzZyolJUUrVqxQ37595e3traFDh2aZm5qaKh8fH4ecNyQkxCHHAQDgVkdWAwDg/shrALnBlehAHuPr66vw8HBFRkaqT58+atq0qb788ktJ//c1sXHjxqlo0aKqWLGiJOnQoUN66KGHFBQUpJCQELVt21YHDhywHjM9PV1xcXEKCgpSaGioBg0aJGOMzXmv/MpZSkqKBg8erBIlSsjX11flypXThx9+qAMHDig6OlqSFBwcLIvFoh49ekiSMjIyNGHCBJUuXVr+/v6qWbOmFi9ebHOeFStWqEKFCvL391d0dLRNnQAA5AVkNQAA7o+8BpAbNNGBPM7f31+pqanWx6tWrdKePXv07bffatmyZbp48aJatGihAgUKaO3atVq/fr3y58+ve++917rfG2+8oVmzZmnGjBlat26dTp48qc8+++yq5+3WrZsWLFigKVOmaNeuXXrvvfeUP39+lShRQkuWLJEk7dmzRwkJCXrrrbckSRMmTNBHH32k6dOna8eOHerfv7+6du2q77//XtKlP0jat2+vNm3aaNu2bXr88cc1ZMgQZ7xsAADcNGQ1AADuj7wGcFUGQJ7RvXt307ZtW2OMMRkZGebbb781vr6+ZsCAAdbtYWFhJiUlxbrPnDlzTMWKFU1GRoZ1LCUlxfj7+5tvvvnGGGNMRESEefXVV63bL168aIoXL249lzHGREVFmeeee84YY8yePXuMJPPtt99mW2d8fLyRZBITE61jFy5cMPny5TMbNmywmdurVy/z8MMPG2OMGTp0qKlSpYrN9sGDB2c5FgAA7oqsBgDA/ZHXAHKLNdGBPGbZsmXKnz+/Ll68qIyMDHXp0kWjRo2ybq9evbrNWm2//vqr9u3bpwIFCtgc58KFC/rzzz+VnJyshIQE1a9f37rNy8tLd955Z5avnWXatm2bPD09FRUVleO69+3bp3PnzqlZs2Y246mpqapdu7YkadeuXTZ1SFLDhg1zfA4AANwBWQ0AgPsjrwHkBk10II+Jjo7Wu+++Kx8fHxUtWlReXra/xgEBATaPz5w5ozvuuEPz5s3LcqzChQtfVw3+/v653ufMmTOSpOXLl6tYsWI223x9fa+rDgAA3BFZDQCA+yOvAeQGTXQgjwkICFC5cuVyPL9OnTr65JNPVKRIERUsWDDbOREREdq0aZMaN24sSUpLS9NPP/2kOnXqZDu/evXqysjI0Pfff6+mTZtm2Z75aX16erp1rEqVKvL19dXBgwftfspeuXJl641cMv3444/XfpIAALgRshoAAPdHXgPIDW4sCtziHnnkERUqVEht27bV2rVrtX//fq1Zs0b9+vXT4cOHJUnPPfecXnnlFX3++efavXu3nn76aSUlJdk9ZqlSpdS9e3c99thj+vzzz63HXLhwoSQpMjJSFotFy5Yt07Fjx3TmzBkVKFBAAwYMUP/+/TV79mz9+eef+vnnnzV16lTNnj1bkvTUU0/pjz/+0MCBA7Vnzx7Nnz9fs2bNcvZLBACAS5HVAAC4P/IauL3RRAducfny5dMPP/ygkiVLqn379qpcubJ69eqlCxcuWD89f+GFF/Too4+qe/fuatiwoQoUKKAHHnjgqsd999131aFDBz399NOqVKmSevfurbNnz0qSihUrptGjR2vIkCEKCwvTM888I0kaO3ashg8frgkTJqhy5cq69957tXz5cpUuXVqSVLJkSS1ZskSff/65atasqenTp2v8+PFOfHUAAHA9shoAAPdHXgO3N4uxd3cDAAAAAAAAAABuc1yJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDtyANm3aqHz58na3T506VRaLRX/++WeOjjdq1Cht2LAhy7jFYtHrr79+3XVer3Xr1qlt27YqUqSIfHx8VLx4cXXt2lVbt261zilVqpSeeeaZm1rXmjVrZLFYbOo4efKkHnjgAQUHB8tisejzzz9Xjx49VK1atZtaGwDANebNm6d69eopMDBQBQsWVOXKlfX444/rv//+s86ZPHmyVqxY4bQarpXXBw4ckMVi0eLFi51Wgz1ffvmlmjdvrpCQEPn4+Kh06dJ68skntXfvXuscV/y9MWvWLFksFh0/ftw6tn//fsXGxqpAgQKyWCzatm2bmjRpotatW9/U2gAAAIBMXq4uAMjLunTpoi5dumjLli2qW7dulu0LFixQgwYNVLZs2Rwdb/To0cqfP7/uuusum/GNGzcqMjLSITXn1DvvvKNnnnlGMTExeuutt1SsWDEdOXJE8+bNU7NmzZSYmHhT67lcnTp1tHHjRlWuXNk6NmnSJMXHx+ujjz5SkSJFVLFiRVWvXl1nz551WZ0AgJvj1Vdf1ZAhQ9S/f3+NGTNGxhj9/vvvmjdvnv755x8VKVJE0qUmeuvWrdWyZUuX1BkREaGNGzeqQoUKN/W8Q4YM0cSJE9WhQwd98MEHKly4sP7880/NmDFDnTp10i+//HJT67lcq1attHHjRgUFBVnHhg8frr/++kuLFy9WYGCgKlSooHfeeUeenp4uqxMAAAC3N5rowA1o27at8ufPr/nz52dpoh84cEAbN27UlClTbvg8DRo0uOFj5Mb27dv13HPP6dFHH7VeIZbp4Ycf1rJly25qPVcqWLBgltdk9+7dqlGjhu6//37rWHBwsEPOl5KSIm9vb3l48OUdAHBHU6ZMUY8ePfTGG29Yx+677z4NHDhQGRkZLqzMlq+v703P9BUrVmjixIkaPny4xowZYx1v3Lixevbs6fJML1y4sAoXLmwztnv3bt1zzz1q0aKFdaxKlSoOOd/58+fl7+/vkGMBAADg9kFHCLgB+fLlU9u2bbVw4cIsb9IXLFggT09PderUSZL022+/qUWLFgoICFBgYKA6dOiggwcPWudnNqoHDhwoi8Uii8WiNWvWWLdd/vXqzK80L168WBUrVlT+/PkVExOTZdmYw4cPq3Xr1sqXL59KlCihN998U88//7xKlSp11ef11ltvycPDQ2+88YZNAz3T1b5OvXHjRt1///0qWrSoAgICVKtWLc2ZM8dmzsWLFzVw4ECVLFlSvr6+ioiIUJs2bZScnJyj7Vcu52KxWLRkyRKtXbvW+tpJynY5l8OHD6tr164qVKiQ/P391bhxY/300082czKXqHn11VcVGRkpf39/nTx58qqvGQDAdRITExUREZHttswPQEuVKqW///5b06ZNs2bFrFmzJEkfffSRGjVqpJCQEAUHB6tJkybavHlzlmPt2rVL7du3V0hIiPLly6eaNWtqwYIFduvav3+/ypYtq/vuu0/nz5/PdjmXzMyZNm2aIiMjFRgYqHbt2unYsWM2x9qxY4caN24sPz8/lS9fXvPmzVO7du3UpEmTq742b7zxhsLCwjR8+PBst18t05cvX65mzZqpSJEiKliwoOrXr6+vv/7aZk5SUpJ69+6tYsWKyc/PTyVKlFDnzp1zvP3y5VwyX5+ffvpJc+bMkcVisf7Nkt1yLrt27VLbtm0VGBiogIAAtWrVKsvfQhaLRa+88ooGDx6s8PBw67cSAAAAgNzgSnTgBnXp0kXz5s3TmjVrFBMTYx2fP3++9Y3noUOH1LhxY5UtW1Zz587VhQsX9OKLLyoqKkrbt29XgQIFtHHjRjVs2FDPPvusunTpIunqV11t27ZNr732ml555RWlp6crLi5OXbt21caNGyVJxhi1bdtWR48e1XvvvafAwEC99tpr+vvvv695RfX333+vO++8U4UKFcr16/H333/r7rvv1lNPPSU/Pz+tX79evXr1UkZGhrp37y5JmjBhgqZPn66JEyeqatWqOn78uFauXKmUlJQcbb/Sxo0bNXjwYJ0+fVrvvPOO3doSExPVqFEj5c+fX1OnTlVgYKCmTp2qmJgY/fHHHzZvrJcsWaLy5cvrrbfekqenpwICAnL9WgAAbo477rhD06dPV+nSpdW6dWuFh4dnmfPZZ5+pZcuWatSokV544QVJsi63duDAAXXr1k1ly5ZVamqqFixYoMaNG2v79u3WpVf++OMPNWzYUCVKlNCUKVMUHh6u33//3eYD8cvt2bNHsbGxql+/vhYsWCAfHx+79X/55Zf6448/NG3aNB0/flz9+/fXs88+q48//ljSpaunmzdvrqCgIM2dO1fSpSXgkpKSrrpkXFpamtavX68HH3xQ3t7eOXglbe3fv19t2rTRgAED5OHhoa+++kotW7bU6tWrrc37uLg4ffXVV3rllVdUqlQpJSQk6KuvvrIe41rbL5e53E23bt1Uvnx5DR8+XL6+vtnO/euvv3TXXXepWrVqmjVrljw8PDRu3DjFxsZqz549Nvu99dZbatCggT788EOlpaXl+nUAAAAAZADckIsXL5rChQubxx9/3Dr222+/GUnmo48+MsYY079/fxMQEGBOnDhhnbNr1y5jsVjMlClTrGOSzGuvvZblHFeOR0VFmYCAAPPff/9Zx2bOnGkkmUOHDhljjFm+fLmRZH744QfrnNOnT5vAwEATGRl51efk5+dnOnfunKPnHxkZafr27ZvttoyMDHPx4kXzxBNPmIYNG1rHW7VqZdq3b2/3mNfaHh8fbySZLVu2WMfatm1roqKibOZ1797dVK1a1fp4xIgRJjAw0Bw9etQ6duHCBVOyZEkzcOBAm+cUGhpqzpw5Y7cGAID7+O2330y5cuWMJCPJlC5d2vTr18/s37/fZt7VMitTenq6uXjxoqlYsaIZOnSodbxLly6mcOHCJjk52e6+mXm9bds2U6RIEfPoo4+atLQ06/b9+/cbSWbRokU2NRUvXtxcuHDBOjZy5Ejj7e1t0tPTjTHGTJs2zXh6eto8n/379xtPT88s2Xe5f//910gyQ4YMuepzvrL+7GS+Ls2bNzcPP/ywdbxq1aomLi7O7jGvtT3z75djx45Zx2rWrGm6d+9uMy8qKsq0atXK+rhbt26mTJky5vz589ax//77z+TPn99MmzbN5jlVqVLFZGRk2K0BAAAAuBaWcwFukJeXlzp27KglS5YoNTVV0qWlXPLly6cHHnhAkrR27VrFxMQoJCTEul+lSpVUs2ZNrVu37rrOW6tWLZs1RDOvWj98+LAkacuWLQoKCtI999xjnZM/f37Fxsbm6PjZLeOSE4mJierXr58iIyPl7e0tb29vvf/++9q7d691Tp06dbRixQqNGjVKW7ZsybIUzrW2X6+VK1cqOjpaISEhSktLU1pamjw9PRUVFaUtW7bYzG3SpAlXnwNAHlGtWjXt2LFDy5cv13PPPafAwEBNmTJFNWrU0LZt2665/65du/TAAw8oLCxMnp6e8vb21p49e2yya9WqVerQoYMKFix41WNt2bJFTZo0Ufv27TV79uwc3QwzKirK5srpKlWq6OLFi/rvv/+sx6xevbrNcmylSpVSzZo1r3ls6foz/fDhw+revbuKFSsmLy8veXt7a+XKlVkyfdasWXr99df1+++/ZznGtbZfr5UrV+r++++Xl5eXNdODg4NVu3btLJl+3333XfdrAAAAAEisiQ44RJcuXZSYmGhdJ3TBggW6//77lT9/fkmXGsthYWFZ9gsLC7vutbaDgoJsHmd+TfzChQuSpISEhCw36pKUo7VAixUrZvfr6dfSo0cPLViwQAMGDNDKlSu1ZcsWPfbYY9a6JOnFF1/U4MGDNXv2bNWrV0/h4eEaPXq0jDE52n69jh8/rs8//9za3M/8mTNnjg4dOmQzN7v/XwAA9+Xj46OWLVtq8uTJ+uWXX/T111/r3LlzNjfTzM7p06fVvHlz/f3335o0aZLWrl2rLVu2qGbNmjbZdeLECRUtWvSadXz33Xc6e/asevXqlePGrbMyPTQ0VH5+fteV6RkZGbr//vu1bt06jRkzRvHx8dqyZYvuu+8+m9dl6tSpevTRR/XGG2+oevXqKlmypN59990cb79ex48f1+TJk7Nk+tq1a8l0AAAAOBxrogMOcNddd6lUqVJasGCBihQpov379+utt96ybg8JCbFeTXa5o0ePWtdadbSIiIgsNyWTlG0dV2rSpInmzp2rkydP2lw9fy0XLlzQsmXLNGnSJD377LPW8SuvJPf19dWoUaM0atQo7du3TzNmzNCoUaNUpkwZPfroo9fcfr1CQkJ07733auzYsVm2XbnmKlesAUDe1qJFC9WsWVO7du266ryNGzfq8OHDWrZsmc2V3cnJySpevLj1cWhoqP75559rnnfQoEHasmWLWrRooTVr1qh69erX/yT+v4iIiGyvqP/vv/9UoEABu/t5eXnp7rvv1qpVq5SWliYvr5z/6b9v3z798ssv+vzzz9W2bVvr+Pnz523mBQYGavLkyZo8ebJ+++03vfXWW3r66adVrVo13XPPPdfcfr1CQkLUqlUrPf3001m2XfmakOkAAAC4UVyJDjiAxWLRww8/rC+//FIffPCBQkNDde+991q3N2rUSKtWrVJiYqJ1bM+ePdq+fbsaNWpkHfP29ra5uutG1K1bV0lJSfrhhx+sY2fOnNGqVauuuW+/fv2Unp6uAQMGZLt9+fLl2Y6npKQoIyPD5uZpp0+f1pdffmn3XOXKldP48eMVEhKSbaPjWttzo2nTptq5c6cqV66sO++80+bHEU0OAIBrHD16NMvY+fPndejQIZubjPr4+GTJ2cym8OXZtWHDBh04cMBmXtOmTbV48WKdPn36qrV4enpqwYIFuuuuu9S0aVPt2bMnt08ni7p162r79u3av3+/dezAgQP69ddfr7lvXFyc/v33X40bNy7b7StWrMh2PLvX5e+//9b69evtnqt69ep68803JSnbzL7W9txo2rSpfv/9d9WuXTtLplesWPGGjg0AAABciSvRAQfp0qWLJkyYoJkzZ+rJJ5+Ut7e3dVv//v01c+ZMNW/eXC+++KIuXLigl156SSVLllSPHj2s8ypXrqwvvvhC99xzjwICAlSxYsWrXmF2Nffdd5/q1KljrSsoKEivvvqqChQoIA+Pq39+VqNGDb311lt65plndPjwYT322GMqVqyYjhw5oo8//lg//PBDtsvQBAYGqm7dunrllVdUuHBheXl56ZVXXlFgYKDNFfDt2rXTHXfcodq1aysgIEBLly5VYmKiYmJicrT9esXFxWnevHmKiorSc889p5IlS+rYsWPatGmTihYtqv79+9/Q8QEArlG9enW1adNGLVq0UEREhI4cOaK3335bx48f13PPPWedV7lyZa1evVrffvutgoODVbp0aTVo0ED58+dX3759NWTIEB05ckQjR45UsWLFbM4xcuRILVu2TI0aNdKgQYMUERGhnTt36ty5cxo0aJDNXG9vby1evFht2rRRbGysfvjhB5UpU+a6n1/Pnj01btw4tW7dWqNHj5YkjRo1SuHh4dfM9JYtW2rQoEEaNWqUdu7cqc6dO6tQoULav3+/ZsyYoeTkZLVs2TLLfpUqVVLx4sU1ZMgQpaen68yZM9m+LnfffbceeOABVatWTZ6envroo4/k4+Njvcr8Wtuv1+jRo1W3bl21aNFCTzzxhMLCwvTvv//q+++/1z333KOHH374ho4PAAAAXI4r0QEHqVatmmrUqCFjjLp06WKzrUSJEvr+++8VHBysRx55RE888YRq1qypNWvW2DTJp02bpoyMDN13332qW7eufvrpp+uux2Kx6IsvvlDNmjX1xBNP6Mknn1SrVq3UtGlTBQYGXnP/p59+Wt9//738/f31zDPPKCYmRi+88IIKFCig7777zu5+8+fPV7ly5dS9e3f169dPHTp0ULdu3Wzm3H333fryyy/VtWtXtWnTRt9//73mzZunpk2b5mj79QoNDdWPP/6oWrVqafDgwWrevLn69++vAwcOqH79+jd0bACA64waNUr//POP4uLi1LRpU2terVq1Su3atbPOGz9+vIoXL64HH3xQdevW1dKlSxUWFqZFixbpv//+U9u2bTV58mS99957KleunM05ypcvrw0bNqhUqVJ6+umn1aZNG3344YeKjIzMtiZfX199/vnnKlu2rGJjY7Os050b/v7+WrlypUJCQvTII49o0KBBeuGFF1S+fPkcZfrEiRP1+eef6+TJk3rssccUGxurkSNHqlKlSlq0aJHd+j/99FP5+vqqY8eOGjFihF588UVFRUXZzLv77rv10UcfqWPHjurQoYP279+vpUuXqnLlyjnafr3KlSunzZs3KzQ0VE8//bRatGihIUOG6OzZs6pRo8YNHRsAAAC4ksXc6J36AOQZqampqlKliu655x7NnDnT1eUAAIDrdPLkSZUpU0b9+/fXyJEjXV0OAAAAcEtjORfgFvb+++8rIyNDFStWVGJiot59910dOHBAH3/8satLAwAAuTBx4kSFhYWpVKlSSkhI0Ouvv6709HQ99thjri4NAAAAuOXRRAduYX5+fnrllVesN0erWbOmli9frjvvvNO1hQEAgFzx8PDQyy+/rCNHjsjLy0v169fX6tWrVaJECVeXBgAAANzyWM4FAAAAAAAAAAA7uLEoAAAAAAAAAAB20EQHAAAAAAAAAMAOmuiAk9WsWVMWi0Vr1651dSl5wtatW9WzZ09VrlxZHh4eat26dY73TU1N1cCBAxUeHq6AgAA1a9ZMe/bsyTJv9+7datasmQICAhQeHq5BgwYpNTXVkU8DAJDHkNe5Q14DAADgdkITHXCiHTt2aPv27ZKk+fPnu7iavGH9+vVau3at6tSpo5IlS+Zq3379+umDDz7Q+PHj9emnnyolJUWxsbFKTk62zklMTFRMTIxSU1P16aefavz48Xr//fcVFxfn6KcCAMgjyOvcI68BAABwO+HGooATDRs2TBMnTlRUVJS2b9+uhIQEeXt7u7osSVJKSoq8vb3l4eFen6VlZGRYa2rSpIny58+vZcuWXXO/w4cPq1SpUnrnnXf0xBNPSJJOnjypkiVLasSIERo0aJAkacKECRo3bpwOHjyokJAQSdL777+vp59+WgcPHlTRokWd9MwAAO6KvM498hoAAAC3E/f6axy4hRhjtGDBAsXExCguLk4nTpzQ119/nWXerl271L59e4WEhChfvnyqWbOmFixYYN2ekZGhSZMmqXLlyvL19VV4eLg6duxovVqrR48eqlatms0xk5KSZLFYNGvWLOtYqVKl9Mwzz+jVV19VZGSk/P39dfLkSe3evVudO3dWiRIllC9fPlWpUkVvvPGGMjIybI6ZkpKil156SWXKlJGvr6+KFy+uHj16SJKWLl0qi8WiP/74w2afxMRE+fv765133snx63a9TYKVK1cqIyNDHTt2tI6FhISoefPmWrFihXXsq6++UtOmTa1vyCXpoYceUkZGhlauXHld5wYA5F3kNXkNAAAAXAtNdMBJNmzYoAMHDqhLly5q0aKFQkNDs3xF/I8//lDDhg31xx9/aMqUKfryyy/Vs2dPHTx40Drn2Wef1aBBg9S6dWstXbpU06ZNU4ECBXTmzJlc17RkyRItW7ZMb731lr744gsFBAToyJEjqlixot555x2tWLFCTzzxhMaMGaOxY8fa7Pvggw9q0qRJeuyxx7R8+XK99tprOnv2rCSpZcuWKlasmGbMmGGzT+bz7dKli2bNmiWLxaI1a9bkuu6c2L17t4oUKaLg4GCb8cqVK2v37t028ypVqmQzJygoSBERETbzAAC3B/KavAYAAACuxcvVBQC3qvnz58vPz0/t27eXt7e3OnTooDlz5ujMmTPKnz+/JGnUqFHy8fHR+vXrVbBgQUlS06ZNrcfYu3ev3n33XY0bN05Dhw61jj/44IPXVdPFixf11VdfKSAgwDoWGxur2NhYSZeuxmvUqJHOnTunt99+WyNHjpQkffvtt1q+fLnmz5+vhx9+2Lpv5n97enqqZ8+emjFjhl5++WV5enpKkmbMmKH27dsrKChIHh4e8vT0lMViua7aryUxMVFBQUFZxoODg3Xy5MlczwMA3B7Ia/IaAAAAuBauRAecIC0tTYsWLVLLli0VGBgo6dLVXefOndNnn31mnbdq1Sp16NDB+ob8SqtXr5YxRr169XJIXU2aNLF5Qy5JFy5c0MiRI1WuXDn5+vrK29tbL774ohISEqxXz61atUr58uVT586d7R67V69eSkhIsH4Ffvv27fr555+ttXfr1k1paWmKiopyyHMBAOBGkdfkNQAAAJATNNEBJ1i5cqWOHTumNm3aKCkpSUlJSapevboiIiJsviJ+4sSJq94Y68SJE/Ly8lKRIkUcUldYWFiWscGDB+u1115T7969tWLFCm3ZskUvvfSSpEtv2DPriIiIuOpVaaVKlVKzZs304YcfSrp0VVvp0qUVHR3tkNqvJTg42Lru7OUSExNt1lPN6TwAwK2PvCavAQAAgJygiQ44QeYb7549eyo4OFjBwcEKCQlRQkKCvvvuO/3333+SpNDQUP3zzz92jxMaGqq0tDTr/Oz4+fkpNTXVZiwxMTHbudm9qV60aJGefPJJDR48WE2bNtWdd94pLy/blZ5CQ0OVkJAgY4zdOiSpd+/eWrZsmY4cOaJ58+apZ8+eTvs6+JUqVaqko0ePZnnuV66pWqlSpSxrqSYnJyshISHL2qsAgFsbeU1eAwAAADlBEx1wsHPnzumLL75Qu3btFB8fb/OzYMECpaWl6ZNPPpF0aT3VxYsX6/Tp09keKyYmRhaLRTNnzrR7vuLFi+vw4cM2Ny5buXJljus9f/68fHx8rI/T09P18ccf28xp2rSpzp07p4ULF171WG3btlVwcLC6dOmikydPqkePHjmu40Y1b95cHh4eWrJkiXUsMTFRK1euVMuWLa1j9913n7777jslJSVZxxYtWiQPDw81b978ptULAHAt8pq8BgAAAHLMAHCo+fPnG0lm9erV2W6vXbu2adCggTHGmL1795rAwEBTo0YNM3fuXLNq1SozdepUM3HiROv8Pn36GC8vLzNo0CDzzTffmM8++8w8/vjj5vDhw8YYY3bs2GEsFovp2LGjWblypXnzzTdN1apVjSQzc+ZM63EiIyNN3759s9TTsWNHExwcbGbNmmWWLVtmWrZsaUqXLm0kmWPHjlnntWzZ0uTLl8+MGzfOfPfdd2bhwoXmoYceynK8gQMHGkmmRYsWNuOzZ882np6eZs2aNVd9/f777z+zaNEis2jRIlOlShVzxx13WB+fPXvWOq9s2bImJibGZt8nn3zSBAUFmRkzZphvvvnGREVFmWLFipmkpCTrnJMnT5qIiAgTFRVlvvnmGzNjxgwTFBSU7WsDALh1kdfkNQAAAJBTNNEBB2vdurUpWbKkycjIyHb75MmTjSSzb98+Y8ylN9X333+/KViwoMmXL5+pVauW+fjjj63z09PTzauvvmrKly9vvL29TXh4uOnUqZNJTk62zvnoo49MuXLljL+/v2nWrJnZtm1bjt+U//vvv6Zdu3amQIECJiwszAwePNh88MEHWd6Unz9/3gwZMsSULFnSeHt7m+LFi5vHHnssy/E2bNhgJJlPPvnEZnzmzJlGkomPj7/q6xcfH28kZfuzf/9+m+cTFRVls++FCxfMCy+8YIoUKWL8/f1N06ZNza5du7KcY+fOnSY2Ntb4+/ubIkWKmAEDBpiUlJSr1gUAuLWQ1+Q1AAAAkFMWY66xaCIA5MKIESP0zjvv6MiRI/L19XV1OQAAIBvkNQAAAJBzXteeAgDXtmfPHu3Zs0dTp05V3759eUMOAIAbIq8BAACA3ONKdAAO0aRJE/3444+69957NW/ePAUEBLi6JAAAcAXyGgAAAMg9mugAAAAAAAAAANjh4eoCAAAAAACAfT/88IPatGmjokWLymKx6PPPP7/mPmvWrFGdOnXk6+urcuXKadasWU6vEwCAWxVNdAAAAAAA3NjZs2dVs2ZNTZs2LUfz9+/fr1atWik6Olrbtm3T888/r8cff1zffPONkysFAODWxHIuAAAAAADkERaLRZ999pnatWtnd87gwYO1fPly/f7779axzp07KykpSV9//fVNqBIAgFuLl6sLAAAAAAAAjrNx40Y1bdrUZqxFixZ6/vnn7e6TkpKilJQU6+OMjAydPHlSoaGhslgszioVAACHM8bo9OnTKlq0qDw8HLMQyy3ZRPev/YyrSwBuaYlb3nZ1CcAty++WTObskdeA85DVgHO5e17/+++/CgsLsxkLCwvTqVOndP78efn7+2fZZ8KECRo9evTNKhEAAKc7dOiQihcv7pBjuXn0AwAAAAAAZxs6dKji4uKsj5OTk1WyZEkdOnRIBQsWdGFlAADkzqlTp1SiRAkVKFDAYcekiQ4AAAAAwC0kPDxcR48etRk7evSoChYsmO1V6JLk6+srX1/fLOMFCxakiQ4AyJMcuRyZYxaFAQAAAAAAbqFhw4ZatWqVzdi3336rhg0buqgiAADyNproAAAAAAC4sTNnzmjbtm3atm2bJGn//v3atm2bDh48KOnSUizdunWzzn/qqaf0119/adCgQdq9e7feeecdLVy4UP3793dF+QAA5Hk00QEAAAAAcGNbt25V7dq1Vbt2bUlSXFycateurREjRkiSEhISrA11SSpdurSWL1+ub7/9VjVr1tQbb7yh//3vf2rRooVL6gcAIK9jTXQAAAAAANxYkyZNZIyxu33WrFnZ7vPLL784sSoAAG4fXIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6XNtH37t2rzZs324ytWrVK0dHRqlevnsaPH++iygAAgERWAwDgLqZNm6ZSpUrJz89P9evXz5LPV5o8ebIqVqwof39/lShRQv3799eFCxduUrUAANxaXNpEHzx4sJYtW2Z9vH//frVp00Y+Pj5q2LChJkyYoMmTJ7uuQAAAbnNkNQAArvfJJ58oLi5OI0eO1M8//6yaNWuqRYsW+u+//7KdP3/+fA0ZMkQjR47Url279OGHH+qTTz7RsGHDbnLlAADcGlzaRN+6davuu+8+6+N58+apQoUK+uabb/TWW29p8uTJmjVrlusKBADgNkdWAwDgepMmTVLv3r3Vs2dPValSRdOnT1e+fPk0Y8aMbOdv2LBBd999t7p06aJSpUqpefPmevjhh6959ToAAMieS5vox48fV/Hixa2P4+Pj1aZNG+vjJk2a6MCBAy6oDAAASGQ1AACulpqaqp9++klNmza1jnl4eKhp06bauHFjtvvcdddd+umnn6xN87/++ksrVqxQy5Ytb0rNAADcalzaRA8JCVFCQoIkKSMjQ1u3blWDBg2s21NTU2WMcVV5AADc9shqAABc6/jx40pPT1dYWJjNeFhYmP79999s9+nSpYvGjBmjRo0aydvbW2XLllWTJk2uupxLSkqKTp06ZfMDAAAucWkTvUmTJho7dqwOHTqkyZMnKyMjQ02aNLFu37lzp0qVKuWy+gAAuN2R1QAA5D1r1qzR+PHj9c477+jnn3/Wp59+quXLl2vs2LF295kwYYICAwOtPyVKlLiJFQMA4N68XHnycePGqVmzZoqMjJSnp6emTJmigIAA6/Y5c+YoJibGhRUCAHB7I6sBAHCtQoUKydPTU0ePHrUZP3r0qMLDw7PdZ/jw4Xr00Uf1+OOPS5KqV6+us2fP6oknntCLL74oD4+s19MNHTpUcXFx1senTp2ikQ4AwP/n0iZ6qVKltGvXLu3YsUOFCxdW0aJFbbaPHj3aZh1WAABwc5HVAAC4lo+Pj+644w6tWrVK7dq1k3RpibVVq1bpmWeeyXafc+fOZWmUe3p6SpLdZdh8fX3l6+vruMIBALiFuHQ5F0ny8vJSzZo1bd6Up6Wl6cyZM6pZs6ZCQ0NdWB1ulgE9m+n8L2/rtQEPuroU4Jby8fx5uq9ZjOrWrq5HOnfUb9u3u7ok5EFkNSSyGnAWsho5ERcXpw8++ECzZ8/Wrl271KdPH509e1Y9e/aUJHXr1k1Dhw61zm/Tpo3effddffzxx9q/f7++/fZbDR8+XG3atLE20wEAQM65tIm+dOlSzZo1y2Zs3Lhxyp8/v4KCgtS8eXMlJia6pjjcNHdUKaleD96t7XsPu7oU4Jby9Vcr9PqrE/Tk03318aLPVLFiJfV5spdOnDjh6tKQh5DVkMhqwFnIauRUp06d9Prrr2vEiBGqVauWtm3bpq+//tp6s9GDBw9abwQuSS+99JJeeOEFvfTSS6pSpYp69eqlFi1a6L333nPVUwAAIE9zaRN90qRJOnv2rPXxhg0bNGLECA0fPlwLFy7UoUOHrnrjE+R9Af4+mjm+h54eu0BJp867uhzgljJn9ky17/CQ2j3woMqWK6eXRo6Wn5+fPv90iatLQx5CVoOsBpyHrEZuPPPMM/r777+VkpKiTZs2qX79+tZta9assfnQ28vLSyNHjtS+fft0/vx5HTx4UNOmTVNQUNDNLxwAgFuAS5voO3bs0F133WV9vHjxYjVr1kwvvvii2rdvrzfeeENLly51YYVwtslDO+nrtb8rftMeV5cC3FIupqZq184datDw//6N9fDwUIMGd2n7r7+4sDLkNWQ1yGrAOchqAACAvMOlTfTTp0/brKO6bt06xcbGWh9XrVpV//zzjytKw03QscUdqlWphIZP/dLVpQC3nMSkRKWnp2dZqzo0NFTHjx93UVXIi8jq2xtZDTgPWQ0AAJB3uLSJXqxYMe3atUuSdObMGf366682V7udOHFC+fLlu+oxUlJSdOrUKZsfk5Hu1Lpx44qHBem1gQ+q54uzlJKa5upyAAB2OCKrJfI6LyKrAQAAAOASL1eevGPHjnr++ec1bNgwrVixQuHh4WrQoIF1+9atW1WxYsWrHmPChAkaPXq0zZhnWF15R9RzSs1wjNqVSyostKA2zh9sHfPy8lSjOmX1VKfGCqz/vDIyjAsrBPK24KBgeXp6Zrkx2YkTJ1SoUCEXVYW8yBFZLZHXeRFZDTgXWQ0AAJB3uLSJPmLECB05ckT9+vVTeHi45s6dK09PT+v2BQsWqE2bNlc9xtChQxUXF2czVuSewXZmw13Eb96jOzqMsxl7f3RX7dl/VG/M+pY35cAN8vbxUeUqVbXpx42KiW0qScrIyNCmTRvV+eGuLq4OeYkjsloir/MishpwLrIaAAAg73BpE93f318fffSR3e3x8fHXPIavr698fX1txiwennZmw12cOZeinX8m2IydPZ+qk8lns4wDuD6Pdu+p4cMGq2rVaqpWvYbmzpmt8+fPq90D7V1dGvIQR2S1RF7nRWQ14HxkNQAAQN7g0ib65bZv3669e/dKkipUqKAaNWq4uCIAyNvuva+lEk+e1DtvT9Hx48dUsVJlvfPe/xTKV8RxnchqAHAsshoAACBvsBhjXPpd3M2bN6tXr17auXOnMkuxWCyqWrWqPvzwQ9WtWzfXx/Sv/YyjywRwmcQtb7u6BOCW5ec2H2//H2dktUReA85EVgPO5Y557WinTp1SYGCgkpOTVbBgQVeXAwBAjjkjwzwccpTrtHPnTsXGxsrf319z587Vzz//rJ9//llz5syRr6+vYmNjtXPnTleWCADAbY2sBgAAAADc7lx6JfpDDz2ktLQ0LVmyRBaLxWabMUbt27eXt7e3Fi5cmKvjcmUb4Fxc3QY4j7td2easrJbIa8CZyGrAudwtr52BK9EBAHmVMzLMpdEfHx+vr776KsubcunS18SHDRumli1buqAyAAAgkdUAAAAAALh0OZfTp08rLCzM7vbw8HCdPn36JlYEAAAuR1YDAAAAAG53Lm2iR0ZGavPmzXa3b9q0SZGRkTexIgAAcDmyGgAAAABwu3NpE71z586Ki4vT77//nmXbb7/9pgEDBqhTp04uqAwAAEhkNQAAAAAALl0TfejQofruu+9Uq1YtNWvWTJUrV5YxRrt27dJ3332nevXqadiwYa4sEQCA2xpZDQAAAAC43bn0SnQ/Pz/Fx8dr3LhxSkhI0PTp0/Xee+/p33//1csvv6yFCxeqX79+riwRAIDbGlkNAAAAALjdWYwxxtVF2PPrr7+qTp06Sk9Pz9V+/rWfcVJFACQpccvbri4BuGX5ufQ7Yrl3vVktkdeAM5HVgHPltby+HqdOnVJgYKCSk5NVsGBBV5cDAECOOSPDXHolOgAAAAAAAAAA7owmOgAAAAAAAAAAdtBEBwAAAAAAAADADpeu5Na+ffurbk9KSro5hQAAgGyR1QAAAACA251Lm+iBgYHX3N6tW7ebVA0AALgSWQ0AAAAAuN25tIk+c+ZMV54eAABcA1kNAAAAALjdsSY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAA3Ny0adNUqlQp+fn5qX79+tq8efNV5yclJalv376KiIiQr6+vKlSooBUrVtykagEAuLV4uboAAAAAAABg3yeffKK4uDhNnz5d9evX1+TJk9WiRQvt2bNHRYoUyTI/NTVVzZo1U5EiRbR48WIVK1ZMf//9t4KCgm5+8QAA3AJoogMAAAAA4MYmTZqk3r17q2fPnpKk6dOna/ny5ZoxY4aGDBmSZf6MGTN08uRJbdiwQd7e3pKkUqVK3cySAQC4pbCcCwAAAAAAbio1NVU//fSTmjZtah3z8PBQ06ZNtXHjxmz3+fLLL9WwYUP17dtXYWFhqlatmsaPH6/09PSbVTYAALcUrkQHAAAAAMBNHT9+XOnp6QoLC7MZDwsL0+7du7Pd56+//tLq1av1yCOPaMWKFdq3b5+efvppXbx4USNHjsx2n5SUFKWkpFgfnzp1ynFPAgCAPI4r0QEAAAAAuIVkZGSoSJEiev/993XHHXeoU6dOevHFFzV9+nS7+0yYMEGBgYHWnxIlStzEigEAcG800QEAAAAAcFOFChWSp6enjh49ajN+9OhRhYeHZ7tPRESEKlSoIE9PT+tY5cqV9e+//yo1NTXbfYYOHark5GTrz6FDhxz3JAAAyONoogMAAAAA4KZ8fHx0xx13aNWqVdaxjIwMrVq1Sg0bNsx2n7vvvlv79u1TRkaGdWzv3r2KiIiQj49Ptvv4+vqqYMGCNj8AAOASmugAAAAAALixuLg4ffDBB5o9e7Z27dqlPn366OzZs+rZs6ckqVu3bho6dKh1fp8+fXTy5Ek999xz2rt3r5YvX67x48erb9++rnoKAADkadxYFAAAAAAAN9apUycdO3ZMI0aM0L///qtatWrp66+/tt5s9ODBg/Lw+L9r5EqUKKFvvvlG/fv3V40aNVSsWDE999xzGjx4sKueAgAAeZrFGGNcXYSj+dd+xtUlALe0xC1vu7oE4Jbldxt9vE1eA85DVgPOdTvk9alTpxQYGKjk5GSWdgEA5CnOyDCWcwEAAAAAAAAAwA6a6AAAAAAAAAAA2HFdTfS1a9eqa9euatiwoY4cOSJJmjNnjtatW+fQ4gAAwPUhqwEAAAAAcIxcN9GXLFmiFi1ayN/fX7/88otSUlIkScnJyRo/frzDCwQAALlDVgMAAAAA4Di5bqK//PLLmj59uj744AN5e3tbx++++279/PPPDi0OAADkHlkNAAAAAIDj5LqJvmfPHjVu3DjLeGBgoJKSkhxREwAAuAFkNQAAAAAAjpPrJnp4eLj27duXZXzdunUqU6aMQ4oCAADXj6wGAAAAAMBxct1E7927t5577jlt2rRJFotF//zzj+bNm6cBAwaoT58+zqgRAADkAlkNAAAAAIDjeOV2hyFDhigjI0OxsbE6d+6cGjduLF9fXw0YMEDPPvusM2oEAAC5QFYDAAAAAOA4FmOMuZ4dU1NTtW/fPp05c0ZVqlRR/vz5HV3bdfOv/YyrSwBuaYlb3nZ1CcAtyy/XH2/b585ZLZHXgDOR1YBzOTKv3dWpU6cUGBio5OTk/9fevYdVVed7HP9sQDZeuKmJQnjDwUuSTppEHcXtoHamxyTHspuSx2qcNEtyUivFS4p1avRUpqWZzhlNy8x61LGMgTIlPSp0yryUSjYzYloBigoCv/OH4z7tZBuXfcX363n287R/+7fW+u5f4Mf9da21FRYW5u1yAACoMXdkWJ2jPzg4WN26dXNJEQAAwPXIagAAAAAA6q/WTXSbzSaLxeL09b/97W/1KggAANQPWQ0AAAAAgOvUuones2dPh+fnz59Xfn6+vvjiC6WlpbmqLgAAUEdkNQAAAAAArlPrJvr8+fOrHZ8xY4ZOnz5d74JcgXtAAu6VV1Dk7RKABiupU0S99+EPWS2R14A7kdWAe7kirwEAgP8IcNWO7r33Xi1btsxVuwMAAC5GVgMAAAAAUHsua6Ln5uYqJCTEVbsDAAAuRlYDAAAAAFB7tb6dy7BhwxyeG2N07Ngx7dq1S9OmTXNZYQAAoG7IagAAAAAAXKfWTfTw8HCH5wEBAercubNmzZqlQYMGuawwAABQN2Q1AAAAAACuU6smemVlpUaPHq2EhARFRka6qyYAAFBHZDUAAAAAAK5Vq3uiBwYGatCgQSoqKnJTOQAAoD7IagAAAAAAXKvWXyzavXt3HT582B21AAAAFyCrAQAAAABwnVo30Z9++mlNmjRJGzZs0LFjx1RSUuLwAAAA3kVWAwAAAADgOhZjjKnJxFmzZumxxx5TaGjo/29ssdj/2xgji8WiyspK11dZS+cqvF0B0LDlFRR5uwSgwUrqFFHnbf0pqyXyGnAnshpwr/rktb8oKSlReHi4iouLFRYW5u1yAACoMXdkWI2b6IGBgTp27Jj27dt32XnJyckuKaw++FAOuBcfzAH3qc+Hcn/Kaom8BtyJrAbciyY6AAC+yx0ZFlTTiRd77b7ywRsAADgiqwEAAAAAcL1a3RP9p5eEAwAA30NWAwAAAADgWjU+E12S4uPjf/HD+Q8//FCvggAAQN2R1QAAAAAAuFatmugzZ85UeHi4u2oBAAD1RFYDAAAAAOBatWqi33nnnWrVqpW7agEAAPVEVgMAAAAA4Fo1vic691gFAMC3kdUAADRcCxcuVPv27RUSEqLExETt3LmzRtutXr1aFotFqamp7i0QAIAGrMZNdGOMO+sAAAD1RFYDANAwrVmzRunp6crIyNCePXvUo0cPDR48WN99991ltysoKNCkSZPUt29fD1UKAEDDVOMmelVVFZeHAwDgw8hqAAAapj/96U964IEHNHr0aHXr1k2LFy9WkyZNtGzZMqfbVFZW6p577tHMmTPVsWNHD1YLAEDDU+MmOgAAAAAA8Kzy8nLt3r1bKSkp9rGAgAClpKQoNzfX6XazZs1Sq1atNGbMmBodp6ysTCUlJQ4PAABwAU10AAAAAAB81MmTJ1VZWamoqCiH8aioKBUWFla7zSeffKLXXntNS5YsqfFxMjMzFR4ebn/ExsbWq24AABoSmugAAAAAADQQp06d0siRI7VkyRK1bNmyxttNnTpVxcXF9se3337rxioBAPAvQd4uAAAAAAAAVK9ly5YKDAzU8ePHHcaPHz+u1q1bXzL/0KFDKigo0JAhQ+xjVVVVkqSgoCAdOHBAcXFxl2xntVpltVpdXD0AAA0DZ6IDAAAAAOCjgoOD1atXL2VlZdnHqqqqlJWVpaSkpEvmd+nSRZ9//rny8/Ptj1tvvVU2m035+fncpgUAgDrgTHQAAAAAAHxYenq60tLS1Lt3b/Xp00cLFixQaWmpRo8eLUkaNWqUYmJilJmZqZCQEHXv3t1h+4iICEm6ZBwAANQMTXQAAAAAAHzYiBEjdOLECU2fPl2FhYXq2bOnNm/ebP+y0aNHjyoggAvNAQBwF4sxxni7CFc7V+HtCoCGLa+gyNslAA1WUqcIb5fgMeQ14D5kNeBeV0Jel5SUKDw8XMXFxQoLC/N2OQAA1Jg7Mox/qgYAAAAAAAAAwAma6AAAAAAAAAAAOEETHQAAAAAAAAAAJ2iiAwAAAAAAAADgBE10AAAAAAAAAACcoIkOAAAAAAAAAIATNNEBAAAAAAAAAHCCJjoAAAAAAAAAAE7QRAcAAAAAAAAAwAma6AAAAAAAAAAAOEETHQAAAAAAAAAAJ2iiAwAAAAAAAADgRJC3Dmyz2WSxWC47x2KxKCsry0MVAQCAnyKrAQAAAADwYhO9Z8+eTl87deqUVq1apbKyMs8VBAAAHJDVAAAAAAB4sYk+f/78S8YqKiq0cOFCzZkzRzExMZo9e7YXKgMAABJZDQAAAACA5MUm+s+tXLlS06dP19mzZzVjxgw9+OCDCgrymfIAALjikdUAAAAAgCuR1z/5bt68WVOmTNGRI0c0adIkpaenq2nTpt4uCwAA/AtZDQAAAAC4kgV468A7d+6UzWbTbbfdJpvNpkOHDmnatGl8KL/CrF61Uv8+cICu/3WC7rnzdn3+v//r7ZKABuHAF3maP/MxPTryFt13S6J2537k7ZLgh8hqSGQ14E7kNQAAgH/w2pnoN9xwgxo3bqyxY8eqQ4cOWrVqVbXzJkyY4OHK4Cmb/7pJzz2bqacyZiohoYdW/vcK/eH3Y/Tuhs1q0aKFt8sD/FrZubNq2+FX6jdwiF6cM9nb5cBPkdUgqwH3Iq8BAAD8g9ea6G3btpXFYtH69eudzrFYLHwwb8D+e8XrGjb8DqXe9jtJ0lMZM/Xxxzlav+5tjXngQS9XB/i3a3vfqGt73+jtMuDnyGqQ1YB7kdcAAAD+wWtN9IKCAm8dGj7gfHm59n25V2Me+L19LCAgQDfccKP+97M8L1YGALiIrL6ykdUAAAAAcIHX7omOK9uPRT+qsrLykkvBW7RooZMnT3qpKgAAcBFZDQAAAAAXeO1M9BdeeKFG837pEvGysjKVlZU5jJlAq6xWa51rAwAArstqibwGAAAAAPgvrzXR58+f/4tzanKf1czMTM2cOdNh7MlpGXpq+oz6lAc3i4yIVGBgoL7//nuH8e+//14tW7b0UlUAgJ9yVVZL5LU/IqsBAAAA4AKvNdH/9re/qUOHDvXez9SpU5Wenu4wZgI5q83XNQoOVtdu12jHp7ka8JsUSVJVVZV27MjVnXfd6+XqAACS67JaIq/9EVkNAAAAABd4rYkeFxendu3ayWazacCAAbLZbIqJian1fqzWSy8FP1fhqirhTiPTRmvaE5N1zTXd1T3hWv3lv1fo7NmzSr1tmLdLA/zeubNndPyff7c/P1n4T31z6KCahYapRavWXqwM/sRVWS2R1/6KrAbci7wGAADwD149Ez0nJ0c5OTl64403VF5ero4dO9o/pNtsNkVFRXmrPHjAzf/+W/34ww96+aUXdPLkCXXu0lUvv7JULbhEHKi3I1/t0zNTH7I/f2PpAknSTb+5RQ+kT/dSVfA3ZDXIasC9yGsAAAD/YDHGGG8Xce7cOW3fvt3+QX3nzp06f/68unTpor1799Z+f5zZBrhVXkGRt0sAGqykThHeLqFars5qibwG3ImsBtzLV/PalUpKShQeHq7i4mKFhYV5uxwAAGrMHRkW4JK91FNISIgGDBigp556SjNnztSECRPUrFkz7d+/39ulAQAAkdUAAHjbwoUL1b59e4WEhCgxMVE7d+50OnfJkiXq27evIiMjFRkZqZSUlMvOBwAAl+fVJnp5ebk+/vhjzZw5UzabTRERERo7dqx+/PFHvfTSSzpy5Ig3ywMA4IpHVgMA4H1r1qxRenq6MjIytGfPHvXo0UODBw/Wd999V+38nJwc3XXXXcrOzlZubq5iY2M1aNAg/eMf//Bw5QAANAxeu53LgAEDtGPHDnXo0EHJycnq27evkpOT1aZNm3rvm8vDAffiEnHAfXzp8nB3ZrVEXgPuRFYD7uXpvE5MTNT111+vl156SZJUVVWl2NhYPfzww5oyZcovbl9ZWanIyEi99NJLGjVqVI2Oye1cAAD+qkHdzmXr1q1q0aKFBgwYoN/85jcaOHCgyz6UAwCA+iOrAQDwvvLycu3evVspKSn2sYCAAKWkpCg3N7dG+zhz5ozOnz+v5s2bO51TVlamkpIShwcAALjAa030oqIivfrqq2rSpImeeeYZRUdHKyEhQePHj9fatWt14sQJb5UGAABEVgMA4AtOnjypyspKRUVFOYxHRUWpsLCwRvuYPHmyoqOjHRrxP5eZmanw8HD7IzY2tl51AwDQkHitid60aVPdfPPNmjdvnnbs2KGTJ0/q2WefVZMmTfTss8/q6quvVvfu3b1VHgAAVzyyGgAA/zdv3jytXr1a77zzjkJCQpzOmzp1qoqLi+2Pb7/91oNVAgDg24K8XcBFTZs2VfPmzdW8eXNFRkYqKChI+/bt83ZZAADgX8hqAAA8r2XLlgoMDNTx48cdxo8fP67WrVtfdtvnnntO8+bN04cffqhrr732snOtVqusVmu96wUAoCHyWhO9qqpKu3btUk5OjrKzs7Vt2zaVlpYqJiZGNptNCxculM1m81Z5AABc8chqAAC8Lzg4WL169VJWVpZSU1MlXcjorKwsjR8/3ul2zz77rObMmaP3339fvXv39lC1AAA0TF5rokdERKi0tFStW7eWzWbT/Pnz1b9/f8XFxXmrJAAA8BNkNQAAviE9PV1paWnq3bu3+vTpowULFqi0tFSjR4+WJI0aNUoxMTHKzMyUJD3zzDOaPn26Vq1apfbt29vvnd6sWTM1a9bMa+8DAAB/5bUm+n/+53/KZrMpPj7eWyUAAIDLIKsBAPANI0aM0IkTJzR9+nQVFhaqZ8+e2rx5s/3LRo8ePaqAgP//yrNFixapvLxcw4cPd9hPRkaGZsyY4cnSAQBoECzGGOPtIlztXIW3KwAatryCIm+XADRYSZ0ivF2Cx5DXgPuQ1YB7XQl5XVJSovDwcBUXFyssLMzb5QAAUGPuyLCAX54CAAAAAAAAAMCViSY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAB+3cOFCtW/fXiEhIUpMTNTOnTsvO/+tt95Sly5dFBISooSEBG3atMlDlQIA0PDQRAcAAAAAwIetWbNG6enpysjI0J49e9SjRw8NHjxY3333XbXzt2/frrvuuktjxoxRXl6eUlNTlZqaqi+++MLDlQMA0DBYjDHG20W42rkKb1cANGx5BUXeLgFosJI6RXi7BI8hrwH3IasB9/J0XicmJur666/XSy+9JEmqqqpSbGysHn74YU2ZMuWS+SNGjFBpaak2bNhgH7vhhhvUs2dPLV68uEbHLCkpUXh4uIqLixUWFuaaNwIAgAe4I8M4Ex0AAAAAAB9VXl6u3bt3KyUlxT4WEBCglJQU5ebmVrtNbm6uw3xJGjx4sNP5AADg8oK8XQAAAAAAAKjeyZMnVVlZqaioKIfxqKgo7d+/v9ptCgsLq51fWFjo9DhlZWUqKyuzPy8uLpZ04Ww+AAD8ycXscuUNWBpkEz2kQb6rhqusrEyZmZmaOnWqrFart8tBDVxJt5vwd/x+wZeR1/6DP0v8D1ntP/j9gq/IzMzUzJkzLxmPjY31QjUAANTf999/r/DwcJfsq0HeEx3+hXvtAe7D7xcAV+DPEsB9+P3CLykvL1eTJk20du1apaam2sfT0tJUVFSkd99995Jt2rZtq/T0dD366KP2sYyMDK1fv16fffZZtcf5+ZnoRUVFateunY4ePeqyBgQuKCkpUWxsrL799lt+712IdXUf1tY9WFf3KS4uVtu2bfXjjz8qIiLCJfvkHDAAAAAAAHxUcHCwevXqpaysLHsTvaqqSllZWRo/fny12yQlJSkrK8uhib5lyxYlJSU5PY7Vaq32aojw8HCaO24SFhbG2roB6+o+rK17sK7uExDguq8DpYkOAAAAAIAPS09PV1pamnr37q0+ffpowYIFKi0t1ejRoyVJo0aNUkxMjDIzMyVJjzzyiJKTk/X888/rlltu0erVq7Vr1y69+uqr3nwbAAD4LZroAAAAAAD4sBEjRujEiROaPn26CgsL1bNnT23evNn+5aFHjx51ONvuxhtv1KpVq/TUU0/piSee0K9+9SutX79e3bt399ZbAADAr9FEh9dZrVZlZGTwRUqAG/D7BcAV+LMEcB9+v1BT48ePd3r7lpycnEvGbr/9dt1+++11Ph4/m+7D2roH6+o+rK17sK7u44615YtFAQAAAAAAAABwwnV3VwcAAAAAAAAAoIGhiQ4AAAAAAAAAgBM00QEAAAAAAAAAcIImOurtvvvuU2pqarWvnT17VhkZGYqPj5fValXLli11++23a+/evQ7zzpw5o6lTpyouLk4hISG66qqrlJycrHfffdc+58iRI7r77rsVHR2tkJAQXX311Ro6dKj279/vzrcH+IzFixcrNDRUFRUV9rHTp0+rUaNG6t+/v8PcnJwcWSwWHTp0SO3bt9eCBQvsr7Vv314Wi0WffvqpwzaPPvroJfsB0DCQ1YDnkNfwJwsXLlT79u0VEhKixMRE7dy587Lz33rrLXXp0kUhISFKSEjQpk2bPFSpf6nNui5ZskR9+/ZVZGSkIiMjlZKS8ov/H65ktf2ZvWj16tWyWCxO/z6E2q9tUVGRxo0bpzZt2shqtSo+Pp4/E6pR23VdsGCBOnfurMaNGys2NlYTJ07UuXPnPFSt//j44481ZMgQRUdHy2KxaP369b+4TU5Ojq677jpZrVZ16tRJy5cvr9UxaaLDbcrKypSSkqJly5bp6aef1sGDB7Vp0yZVVFQoMTHR4QPB2LFjtW7dOr344ovav3+/Nm/erOHDh+v777+XJJ0/f14DBw5UcXGx1q1bpwMHDmjNmjVKSEhQUVGRl94h4Fk2m02nT5/Wrl277GNbt25V69attWPHDodgzc7OVtu2bRUXF1ftvkJCQjR58mS31wzAt5HVgOuR1/AXa9asUXp6ujIyMrRnzx716NFDgwcP1nfffVft/O3bt+uuu+7SmDFjlJeXp9TUVKWmpuqLL77wcOW+rbbrmpOTo7vuukvZ2dnKzc1VbGysBg0apH/84x8ertz31XZtLyooKNCkSZPUt29fD1Xqf2q7tuXl5Ro4cKAKCgq0du1aHThwQEuWLFFMTIyHK/dttV3XVatWacqUKcrIyNC+ffv02muvac2aNXriiSc8XLnvKy0tVY8ePbRw4cIazT9y5IhuueUW2Ww25efn69FHH9X999+v999/v+YHNUA9paWlmaFDh14yPm/ePGOxWEx+fr7DeGVlpendu7fp1q2bqaqqMsYYEx4ebpYvX+70GHl5eUaSKSgocGntgL9p06aNyczMtD9//PHHzbhx40zXrl1Ndna2fbxfv34mLS3NGGNMu3btzPz58+2vtWvXzkyYMMEEBwebjRs32scfeeQRk5yc7OZ3AMAbyGrAs8hr+IM+ffqYcePG2Z9XVlaa6Ohoh5/dn7rjjjvMLbfc4jCWmJhofv/737u1Tn9T23X9uYqKChMaGmpWrFjhrhL9Vl3WtqKiwtx4441m6dKlTv8+hNqv7aJFi0zHjh1NeXm5p0r0S7Vd13HjxpkBAwY4jKWnp5ubbrrJrXX6O0nmnXfeueycxx9/3FxzzTUOYyNGjDCDBw+u8XE4Ex1us2rVKg0cOFA9evRwGA8ICNDEiRP15Zdf6rPPPpMktW7dWps2bdKpU6eq3ddVV12lgIAArV27VpWVlW6vHfBVNptN2dnZ9ufZ2dnq37+/kpOT7eNnz57Vjh07ZLPZnO6nQ4cOGjt2rKZOnaqqqiq31w3AN5HVgHuQ1/B15eXl2r17t1JSUuxjAQEBSklJUW5ubrXb5ObmOsyXpMGDBzudfyWqy7r+3JkzZ3T+/Hk1b97cXWX6pbqu7axZs9SqVSuNGTPGE2X6pbqs7XvvvaekpCSNGzdOUVFR6t69u+bOncvfAX+iLut64403avfu3fZbvhw+fFibNm3Sb3/7W4/U3JC5IsNoosNtDh48qK5du1b72sXxgwcPSpJeffVVbd++XS1atND111+viRMnatu2bfb5MTExeuGFFzR9+nRFRkZqwIABmj17tg4fPuz+NwL4EJvNpm3btqmiokKnTp1SXl6ekpOT1a9fP+Xk5Ei6EA5lZWWX/VAuSU899ZSOHDmilStXeqByAL6IrAbcg7yGrzt58qQqKysVFRXlMB4VFaXCwsJqtyksLKzV/CtRXdb15yZPnqzo6OhLmj1Xurqs7SeffKLXXntNS5Ys8USJfqsua3v48GH7iRObNm3StGnT9Pzzz+vpp5/2RMl+oS7revfdd2vWrFn6t3/7NzVq1EhxcXHq378/t3NxAWcZVlJSorNnz9ZoHzTR4VYXrqr4Zf369dPhw4eVlZWl4cOHa+/everbt69mz55tnzNu3DgVFhZq5cqVSkpK0ltvvaVrrrlGW7ZscVf5gM/p37+/SktL9T//8z/aunWr4uPj7V/ud/E+qzk5OerYsaPatm172X1dddVVmjRpkqZPn67y8nIPvQMAvoasBlyPvAZQF/PmzdPq1av1zjvvKCQkxNvl+LVTp05p5MiRWrJkiVq2bOntchqcqqoqtWrVSq+++qp69eqlESNG6Mknn9TixYu9XZpfy8nJ0dy5c/Xyyy9rz549WrdunTZu3Ojw9214D010uE18fLz27dtX7WsXx+Pj4+1jjRo1Ut++fTV58mR98MEHmjVrlmbPnu3wYSE0NFRDhgzRnDlz9Nlnn6lv3778SyeuKJ06ddLVV1+t7OxsZWdnKzk5WZIUHR2t2NhYbd++XdnZ2RowYECN9peenq6zZ8/q5ZdfdmfZAHwUWQ24B3kNX9eyZUsFBgbq+PHjDuPHjx9X69atq92mdevWtZp/JarLul703HPPad68efrggw907bXXurNMv1TbtT106JAKCgo0ZMgQBQUFKSgoSH/+85/13nvvKSgoSIcOHfJU6T6vLj+3bdq0UXx8vAIDA+1jXbt2VWFhIf/g+y91Wddp06Zp5MiRuv/++5WQkKDbbrtNc+fOVWZmJrd1qydnGRYWFqbGjRvXaB800eE2d955pz788EP7vVQvqqqq0vz589WtW7dL7sH6U926dVNFRYXOnTtX7esWi0VdunRRaWmpS+sGfJ3NZlNOTo5ycnLUv39/+3i/fv3017/+VTt37vzFS8MvatasmaZNm6Y5c+Y4vc8xgIaLrAbch7yGLwsODlavXr2UlZVlH6uqqlJWVpaSkpKq3SYpKclhviRt2bLF6fwrUV3WVZKeffZZzZ49W5s3b1bv3r09Uarfqe3adunSRZ9//rny8/Ptj1tvvVU2m035+fmKjY31ZPk+rS4/tzfddJO+/vprh8buwYMH1aZNGwUHB7u9Zn9Ql3U9c+aMAgIcW7UX/6GiplePonouybBaf+Up8DNpaWmmf//+Ji8vz+Fx9OhRk5iYaGJjY82bb75pvvnmG7Nz506TmppqmjZtanJzc+37SE5ONosXLza7du0yR44cMRs3bjSdO3e2fytxXl6eufXWW81bb71l9u7da7766iuzdOlS07RpUzNr1ixvvXXAK5YtW2YaN25sgoKCTGFhoX18xYoVJjQ01Egy//znP+3j7dq1M/Pnz3f6vLy83MTFxZmQkBCTnJzsgXcAwNPIasDzyGv4utWrVxur1WqWL19uvvzyS/Pggw+aiIgI+8/ryJEjzZQpU+zzt23bZoKCgsxzzz1n9u3bZzIyMkyjRo3M559/7q234JNqu67z5s0zwcHBZu3atebYsWP2x6lTp7z1FnxWbdf259LS0szQoUM9VK1/qe3aHj161ISGhprx48ebAwcOmA0bNphWrVqZp59+2ltvwSfVdl0zMjJMaGioeeONN8zhw4fNBx98YOLi4swdd9zhrbfgs06dOmX/TCPJ/OlPfzJ5eXnmm2++McYYM2XKFDNy5Ej7/MOHD5smTZqYP/7xj2bfvn1m4cKFJjAw0GzevLnGx6SJjnpLS0szki55jBkzxpSWlponn3zSdOrUyTRq1Mg0b97c/O53v7vkL1pz5841SUlJpnnz5iYkJMR07NjRTJgwwZw8edIYY8yJEyfMhAkTTPfu3U2zZs1MaGioSUhIMM8995yprKz0xtsGvObIkSNGkunSpYvDeEFBgZFkOnfu7DD+Sx/KjTFm1apVRhIfyoEGiqwGPI+8hj948cUXTdu2bU1wcLDp06eP+fTTT+2vJScnm7S0NIf5b775pomPjzfBwcHmmmuuMRs3bvRwxf6hNuvarl27ajM6IyPD84X7gdr+zP4UTfTLq+3abt++3SQmJhqr1Wo6duxo5syZYyoqKjxcte+rzbqeP3/ezJgxw/6P5rGxseahhx4yP/74o+cL93HZ2dnV/tl5cT3T0tIu+ftSdna26dmzpwkODjYdO3Y0r7/+eq2OaTGG6wEAAAAAAAAAAKgO90QHAAAAAAAAAMAJmugAAAAAAAAAADhBEx0AAAAAAAAAACdoogMAAAAAAAAA4ARNdAAAAAAAAAAAnKCJDgAAAAAAAACAEzTRAQAAAAAAAABwgiY6AAAAAAAAAABO0EQHUK377rtPqamp9uf9+/fXo48+6vE6cnJyZLFYVFRU5PFjAwDgy8hqAAAAwDNoogN+5L777pPFYpHFYlFwcLA6deqkWbNmqaKiwu3HXrdunWbPnl2juXyYBgBcqchqAAAAoOEJ8nYBAGrn5ptv1uuvv66ysjJt2rRJ48aNU6NGjTR16tRL5paXlys4ONglx23evLlL9gMAQENHVgMAAAANC2eiA37GarWqdevWateunf7whz8oJSVF7733nqT/v6x7zpw5io6OVufOnSVJ3377re644w5FRESoefPmGjp0qAoKCuz7rKysVHp6uiIiItSiRQs9/vjjMsY4HPfnl4iXlZVp8uTJio2NldVqVadOnfTaa6+poKBANptNkhQZGSmLxaL77rtPklRVVaXMzEx16NBBjRs3Vo8ePbR27VqH42zatEnx8fFq3LixbDabQ50AAPgDshoAAABoWGiiA36ucePGKi8vtz/PysrSgQMHtGXLFm3YsEHnz5/X4MGDFRoaqq1bt2rbtm1q1qyZbr75Zvt2zz//vJYvX65ly5bpk08+0Q8//KB33nnnsscdNWqU3njjDb3wwgvat2+fXnnlFTVr1kyxsbF6++23JUkHDhzQsWPH9F//9V+SpMzMTP35z3/W4sWLtXfvXk2cOFH33nuvPvroI0kXGgjDhg3TkCFDlJ+fr/vvv19Tpkxxx7IBAOAxZDUAAADg37idC+CnjDHKysrS+++/r4cfftg+3rRpUy1dutR+afhf/vIXVVVVaenSpbJYLJKk119/XREREcrJydGgQYO0YMECTZ06VcOGDZMkLV68WO+//77TYx88eFBvvvmmtmzZopSUFElSx44d7a9fvJy8VatWioiIkHThbLi5c+fqww8/VFJSkn2bTz75RK+88oqSk5O1aNEixcXF6fnnn5ckde7cWZ9//rmeeeYZVywZAAAeRVYDAAAADQNNdMDPbNiwQc2aNdP58+dVVVWlu+++WzNmzLC/npCQ4HBv1c8++0xff/21QkNDHfZz7tw5HTp0SMXFxTp27JgSExPtrwUFBal3796XXCZ+UX5+vgIDA5WcnFzjur/++mudOXNGAwcOdBgvLy/Xr3/9a0nSvn37HOqQZP8QDwCAvyCrAQAAgIaFJjrgZ2w2mxYtWqTg4GBFR0crKMjx17hp06YOz0+fPq1evXpp5cqVl+zrqquuqlMNjRs3rvU2p0+fliRt3LhRMTExDq9ZrdY61QEAgC8iqwEAAICGhSY64GeaNm2qTp061Xj+ddddpzVr1qhVq1YKCwurdk6bNm20Y8cO9evXT5JUUVGh3bt367rrrqt2fkJCgqqqqvTRRx/ZLxH/qYtn11VWVtrHunXrJqvVqqNHjzo9K65r1672L1676NNPP/3lNwkAgA8hqwEAAICGhS8WBRq4e+65Ry1bttTQoUO1detWHTlyRDk5OZowYYL+/ve/S5IeeeQRzZs3T+vXr9f+/fv10EMPqaioyOk+27dvr7S0NP3Hf/yH1q9fb9/nm2++KUlq166dLBaLNmzYoBMnTuj06dMKDQ3VpEmTNHHiRK1YsUKHDh3Snj179OKLL2rFihWSpLFjx+qrr77SH//4Rx04cECrVq3S8uXL3b1EAAB4FVkNAAAA+Daa6EAD16RJE3388cdq27athg0bpq5du2rMmDE6d+6c/Wy3xx57TCNHjlRaWpqSkpIUGhqq22677bL7XbRokYYPH66HHnpIXbp00QMPPKDS0lJJUkxMjGbOnKkpU6YoKipK48ePlyTNnj1b06ZNU2Zmprp27aqbb75ZGzduVIcOHSRJbdu21dtvv63169erR48eWrx4sebOnevG1QEAwPvIagAAAMC3WYyzbyMCAAAAAAAAAOAKx5noAAAAAAAAAAA4QRMdAAAAAAAAAAAnaKIDAAAAAAAAAOAETXQAAAAAAAAAAJygiQ4AAAAAAAAAgBM00QEAAAAAAAAAcIImOgAAAAAAAAAATtBEBwAAAAAAAADACZroAAAAAAAAAAA4QRMdAAAAAAAAAAAnaKIDAAAAAAAAAOAETXQAAAAAAAAAAJz4P2OZTgu6CA8DAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regular_models = {\n",
        "        'RandomForest': RF_model,\n",
        "        'XGBoost': XVG_model,\n",
        "        'Logistic Regression': LR_model,\n",
        "        'Voting Classifier': VC_model,\n",
        "        'Stacking Classifier': S_model\n",
        "    }\n",
        "# features_filtered = features_filtered[training_feature_cols]\n",
        "# overall_stats_df = overall_stats(df, features_filtered,models, training_feature_cols)\n",
        "\n",
        "overall_stats_df = overall_stats(X_test_P, X_test, regular_models, training_feature_cols)\n",
        "print(\"\\nOverall Statistics for Trades Predicted as 'Win' by Each Model:\")\n",
        "overall_stats_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "zt0tOOAmQ_uE",
        "outputId": "6b9f6748-b6b7-4222-9c6d-c15a80f023c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Statistics for Trades Predicted as 'Win' by Each Model:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Total Trades  Total Win Count  Total Loss Count  \\\n",
              "0         RandomForest             1                1                 0   \n",
              "1              XGBoost             1                1                 0   \n",
              "2  Logistic Regression             1                1                 0   \n",
              "3    Voting Classifier             1                1                 0   \n",
              "4  Stacking Classifier             1                1                 0   \n",
              "\n",
              "   Total Profit  Total Loss  Total Fee  Win Rate (%)  Average R  Max Profit  \\\n",
              "0          46.0         0.0    15.0345         100.0        3.5       30.97   \n",
              "1          46.0         0.0    15.0345         100.0        3.5       30.97   \n",
              "2          46.0         0.0    15.0345         100.0        3.5       30.97   \n",
              "3          46.0         0.0    15.0345         100.0        3.5       30.97   \n",
              "4          46.0         0.0    15.0345         100.0        3.5       30.97   \n",
              "\n",
              "   Average Profit  Average Loss  Total Time (hours)  Average Time (hours)  \\\n",
              "0           30.97             0                 0.5                   0.5   \n",
              "1           30.97             0                 0.5                   0.5   \n",
              "2           30.97             0                 0.5                   0.5   \n",
              "3           30.97             0                 0.5                   0.5   \n",
              "4           30.97             0                 0.5                   0.5   \n",
              "\n",
              "   Realized Profit/Loss     R  \n",
              "0                 30.97  3.06  \n",
              "1                 30.97  3.06  \n",
              "2                 30.97  3.06  \n",
              "3                 30.97  3.06  \n",
              "4                 30.97  3.06  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-936be5a4-2081-4919-9059-dc46b5770206\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Total Trades</th>\n",
              "      <th>Total Win Count</th>\n",
              "      <th>Total Loss Count</th>\n",
              "      <th>Total Profit</th>\n",
              "      <th>Total Loss</th>\n",
              "      <th>Total Fee</th>\n",
              "      <th>Win Rate (%)</th>\n",
              "      <th>Average R</th>\n",
              "      <th>Max Profit</th>\n",
              "      <th>Average Profit</th>\n",
              "      <th>Average Loss</th>\n",
              "      <th>Total Time (hours)</th>\n",
              "      <th>Average Time (hours)</th>\n",
              "      <th>Realized Profit/Loss</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0345</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>30.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0345</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>30.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0345</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>30.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Voting Classifier</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0345</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>30.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stacking Classifier</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0345</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>30.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30.97</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-936be5a4-2081-4919-9059-dc46b5770206')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-936be5a4-2081-4919-9059-dc46b5770206 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-936be5a4-2081-4919-9059-dc46b5770206');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e66b629-f3f0-4dee-8a59-cf9e50232705\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e66b629-f3f0-4dee-8a59-cf9e50232705')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e66b629-f3f0-4dee-8a59-cf9e50232705 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cc4cf741-6821-42f8-ae07-b19ef927b06a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('overall_stats_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cc4cf741-6821-42f8-ae07-b19ef927b06a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('overall_stats_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "overall_stats_df",
              "summary": "{\n  \"name\": \"overall_stats_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"XGBoost\",\n          \"Stacking Classifier\",\n          \"Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Trades\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Win Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Loss Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 46.0,\n        \"max\": 46.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          46.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Fee\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 15.0345,\n        \"max\": 15.0345,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          15.0345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Win Rate (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3.5,\n        \"max\": 3.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 30.97,\n        \"max\": 30.97,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 30.97,\n        \"max\": 30.97,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Time (hours)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Time (hours)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Realized Profit/Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 30.97,\n        \"max\": 30.97,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3.06,\n        \"max\": 3.06,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_input = \"20:00\"  #@param {type:\"string\"}\n",
        "date_input = \"6/25/2025\"  #@param {type:\"string\"}\n",
        "criteria_input = \"LG RGC UP\"  #@param {type:\"string\"}\n",
        "CL = 4 #@param {type:\"integer\"}\n",
        "CW = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "input_features = get_train_data_for_input(precomputed_stats, time_input, date_input, criteria_input, training_feature_cols)\n",
        "# Predict the result\n",
        "input_features['CL'] = [CL]\n",
        "input_features['CW'] = [CW]\n",
        "# input_features = input_features[training_feature_cols]\n",
        "# print(input_features.head())\n",
        "if not input_features.empty:\n",
        "    # Get predictions and probabilities for each model\n",
        "    rf_predicted_class, rf_predicted_probability = predict_trade_result(RF_model, input_features, training_feature_cols)\n",
        "    xgb_predicted_class, xgb_predicted_probability = predict_trade_result(XVG_model, input_features, training_feature_cols)\n",
        "    lr_predicted_class, lr_predicted_probability = predict_trade_result(LR_model, input_features, training_feature_cols)\n",
        "    VC_model_predicted_class, VC_model_predicted_probability = predict_trade_result(VC_model, input_features, training_feature_cols)\n",
        "    S_model_predicted_class, S_model_predicted_probability = predict_trade_result(S_model, input_features, training_feature_cols)\n",
        "\n",
        "    print(f\"\\n--- Predictions for Date: {date_input}, Time: {time_input}, Criteria: {criteria_input} ---\")\n",
        "\n",
        "    print(\"\\nRandomForest Model:\")\n",
        "    print(f\"  Test Set Accuracy: {RF_accuracy:.4f}\")\n",
        "    print(f\"  Predicted Result: {'Win' if rf_predicted_class == 1 else 'Loss'}\")\n",
        "    print(f\"  Predicted Probability of {'Win' if rf_predicted_class == 1 else 'Loss'}: {np.max(rf_predicted_probability):.4f}\")\n",
        "\n",
        "    print(\"\\nXGBoost Model:\")\n",
        "    print(f\"  Test Set Accuracy: {XVG_accuracy:.4f}\")\n",
        "    print(f\"  Predicted Result: {'Win' if xgb_predicted_class == 1 else 'Loss'}\")\n",
        "    print(f\"  Predicted Probability of {'Win' if rf_predicted_class == 1 else 'Loss'}: {np.max(xgb_predicted_probability):.4f}\")\n",
        "\n",
        "    print(\"\\nLogistic Regression Model:\")\n",
        "    print(f\"  Test Set Accuracy: {LR_accuracy:.4f}\")\n",
        "    print(f\"  Predicted Result: {'Win' if lr_predicted_class == 1 else 'Loss'}\")\n",
        "    print(f\"  Predicted Probability of {'Win' if rf_predicted_class == 1 else 'Loss'}: {np.max(lr_predicted_probability):.4f}\")\n",
        "\n",
        "    print(\"\\nVoting Classifier Model:\")\n",
        "    print(f\"  Test Set Accuracy: {VC_accuracy:.4f}\")\n",
        "    print(f\"  Predicted Result: {'Win' if VC_model_predicted_class == 1 else 'Loss'}\")\n",
        "    print(f\"  Predicted Probability of {'Win' if VC_model_predicted_class == 1 else 'Loss'}: {np.max(VC_model_predicted_probability):.4f}\")\n",
        "\n",
        "    print(\"\\nStacking Classifier Model:\")\n",
        "    print(f\"  Test Set Accuracy: {S_accuracy:.4f}\")\n",
        "    print(f\"  Predicted Result: {'Win' if S_model_predicted_class == 1 else 'Loss'}\")\n",
        "    print(f\"  Predicted Probability of {'Win' if S_model_predicted_class == 1 else 'Loss'}: {np.max(S_model_predicted_probability):.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"Prediction could not be made due to invalid inputs or data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUxsFN-0s8Li",
        "outputId": "d7052f80-7448-4436-fcf7-dcb70d3956d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predictions for Date: 6/25/2025, Time: 20:00, Criteria: LG RGC UP ---\n",
            "\n",
            "RandomForest Model:\n",
            "  Test Set Accuracy: 1.0000\n",
            "  Predicted Result: Loss\n",
            "  Predicted Probability of Loss: 0.9300\n",
            "\n",
            "XGBoost Model:\n",
            "  Test Set Accuracy: 1.0000\n",
            "  Predicted Result: Loss\n",
            "  Predicted Probability of Loss: 0.9934\n",
            "\n",
            "Logistic Regression Model:\n",
            "  Test Set Accuracy: 1.0000\n",
            "  Predicted Result: Loss\n",
            "  Predicted Probability of Loss: 0.9235\n",
            "\n",
            "Voting Classifier Model:\n",
            "  Test Set Accuracy: 1.0000\n",
            "  Predicted Result: Loss\n",
            "  Predicted Probability of Loss: 0.9490\n",
            "\n",
            "Stacking Classifier Model:\n",
            "  Test Set Accuracy: 1.0000\n",
            "  Predicted Result: Loss\n",
            "  Predicted Probability of Loss: 0.8901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiclass - Average R"
      ],
      "metadata": {
        "id": "ZO04V5lSTI8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Label Encode"
      ],
      "metadata": {
        "id": "4t-CgKGSiDw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_train_test(y_train_m, y_test_m):\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_enc = label_encoder.fit_transform(y_train_m)\n",
        "    y_test_enc = label_encoder.transform(y_test_m)\n",
        "\n",
        "    # Save the mapping for later decoding\n",
        "    class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "    reverse_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
        "    return label_encoder, y_train_enc, y_test_enc, class_mapping, reverse_mapping\n",
        "label_encoder, y_train_enc, y_test_enc, class_mapping, reverse_mapping = encode_train_test(y_train_m, y_test_m)"
      ],
      "metadata": {
        "id": "gnlasfdMCOaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "ZAJrzR_bLqW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RF_M(X_train, y_train_enc, X_test, y_test_enc, n_estimators= 100):\n",
        "    # Initialize and train the model\n",
        "    # RandomForestClassifier is a good choice for binary classification and handles various feature types well.\n",
        "    # It's relatively robust to outliers and doesn't require extensive feature scaling.\n",
        "    # The number of estimators (n_estimators) can be tuned. More trees generally improve performance but increase computation time.\n",
        "    # random_state for reproducibility\n",
        "    RF_model_m = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    RF_model_m.fit(X_train, y_train_enc)\n",
        "    end_time = time.time()\n",
        "    # print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "    importances = RF_model_m.feature_importances_\n",
        "    features_df = pd.DataFrame({\n",
        "        'Feature': X_train.columns,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot\n",
        "    # features_df.plot.bar(x='Feature', y='Importance', figsize=(12, 4), title='Feature Importances')\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    start_time = time.time()\n",
        "    y_pred_RF_m= RF_model_m.predict(X_test)\n",
        "    end_time = time.time()\n",
        "    # print(f\"Prediction time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    RF_accuracy_m = accuracy_score(y_test_enc, y_pred_RF_m)\n",
        "    RF_class_report_m = classification_report(y_test_enc, y_pred_RF_m)\n",
        "    return RF_model_m, y_pred_RF_m, RF_accuracy_m, RF_class_report_m\n",
        "\n",
        "RF_model_m, y_pred_RF_m, RF_accuracy_m, RF_class_report_m = RF_M(X_train, y_train_enc, X_test, y_test_enc, n_estimators=100)\n",
        "show_model_result(\"RandomForest Multi\", RF_accuracy_m, RF_class_report_m)"
      ],
      "metadata": {
        "id": "Rv2Re2raLpPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8a1557-db75-45e1-aedf-7a3ec4330018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: RandomForest Multi\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XVG Boost"
      ],
      "metadata": {
        "id": "rYK8BmfXMDQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def XVG_M(X_train, y_train_enc, X_test, y_test_enc,num_class=5, objective='multi:softmax', eval_metric = 'mlogloss', ul_enc = False):\n",
        "    # Initialize and train the model\n",
        "    XVG_model_m = XGBClassifier(\n",
        "        objective=objective,   # or 'multi:softprob' for probabilities\n",
        "        num_class=num_class,\n",
        "        eval_metric=eval_metric,      # Recommended for multi-class\n",
        "        use_label_encoder=ul_enc,     # Suppress warnings\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    XVG_model_m.fit(X_train, y_train_enc)\n",
        "    y_pred_XVG_m = XVG_model_m.predict(X_test)\n",
        "\n",
        "    print(\"Test class counts:\\n\", pd.Series(y_test_enc).value_counts())\n",
        "    print(\"Predicted class counts:\\n\", pd.Series(y_pred_XVG_m).value_counts())\n",
        "\n",
        "    XVG_accuracy_m = accuracy_score(y_test_enc, y_pred_XVG_m)\n",
        "    XVG_class_report_m = classification_report(y_test_enc, y_pred_XVG_m)\n",
        "    return XVG_model_m, y_pred_XVG_m, XVG_accuracy_m, XVG_class_report_m\n",
        "\n",
        "XVG_model_m, y_pred_XVG_m, XVG_accuracy_m, XVG_class_report_m = XVG_M(X_train, y_train_enc, X_test, y_test_enc, num_class=prediction_target['Result_R'].nunique(), objective='multi:softmax', eval_metric = 'mlogloss', ul_enc = False)\n",
        "show_model_result(\"XGBoost Multi\", XVG_accuracy_m, XVG_class_report_m)"
      ],
      "metadata": {
        "id": "qx8HsaNsMFMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b84b98-67dc-40d1-cefa-7744164860c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:15:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test class counts:\n",
            " 0    4\n",
            "2    1\n",
            "Name: count, dtype: int64\n",
            "Predicted class counts:\n",
            " 0    4\n",
            "1    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Model: XGBoost Multi\n",
            "Accuracy: 0.8000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.33      0.33      0.33         5\n",
            "weighted avg       0.80      0.80      0.80         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistic Regression"
      ],
      "metadata": {
        "id": "q1SB1r7sJ4D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LR_M(X_train, y_train_enc, X_test, y_test_enc, solver='lbfgs', max_iter=10000):\n",
        "\n",
        "    # Pipeline: Scaling + Logistic Regression\n",
        "    # lr_model_m = LogisticRegression(solver='lbfgs', max_iter=10000, class_weight='balanced', )\n",
        "    lr_model_m = LogisticRegression(solver=solver, max_iter=max_iter,random_state=42 )\n",
        "    LR_model_m = make_pipeline(StandardScaler(), lr_model_m)\n",
        "    # model = RandomForestClassifier()\n",
        "    # model = XGBClassifier(num_class=5, objective='multi:softmax')\n",
        "\n",
        "    LR_model_m.fit(X_train, y_train_enc)\n",
        "    y_pred_LR_m = LR_model_m.predict(X_test)\n",
        "\n",
        "    LR_accuracy_m = accuracy_score(y_test_enc, y_pred_LR_m)\n",
        "    LR_class_report_m = classification_report(y_test_enc, y_pred_LR_m)\n",
        "\n",
        "    return LR_model_m, y_pred_LR_m, LR_accuracy_m, LR_class_report_m\n",
        "\n",
        "LR_model_m, y_pred_LR_m, LR_accuracy_m, LR_class_report_m = LR_M(X_train, y_train_enc, X_test, y_test_enc, solver='lbfgs', max_iter=10000)\n",
        "show_model_result(\"Logistic Regression Multi\", LR_accuracy_m, LR_class_report_m)"
      ],
      "metadata": {
        "id": "tQHe54Lkyd4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voting Classifier"
      ],
      "metadata": {
        "id": "l6kPK7-jJ8CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VC_M(X_train, y_train_enc, X_test, y_test_enc, num_class=5, voting='soft', solver='lbfgs', max_iter=10000, objective='multi:softmax',  eval_metric='mlogloss', ul_enc=False):\n",
        "    lr = make_pipeline(StandardScaler(), LogisticRegression(solver=solver, max_iter=max_iter, random_state=42 )) #class_weight='balanced',\n",
        "\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    xgb = XGBClassifier(\n",
        "        objective=objective,\n",
        "        num_class=num_class,\n",
        "        eval_metric=eval_metric,\n",
        "        use_label_encoder=ul_enc,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Check all estimators before using\n",
        "    # for name, model in [('lr', lr), ('rf', rf), ('xgb', xgb)]:\n",
        "    #     model.fit(X_train, y_train_enc)\n",
        "    #     proba = model.predict_proba(X_test)\n",
        "    #     print(f\"{name} proba shape: {proba.shape}\")\n",
        "\n",
        "    VC_model_m = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', lr),\n",
        "            ('rf', rf),\n",
        "            ('xgb', xgb)\n",
        "        ],\n",
        "        voting=voting # Use 'soft' for probability averaging (recommended for multi-class)\n",
        "    )\n",
        "\n",
        "    VC_model_m.fit(X_train, y_train_enc)\n",
        "    y_pred_VC_m = VC_model_m.predict(X_test)\n",
        "\n",
        "    VC_accuracy_m = accuracy_score(y_test_enc, y_pred_VC_m)\n",
        "    VC_class_report_m = classification_report(y_test_enc, y_pred_VC_m)\n",
        "\n",
        "    return VC_model_m, y_pred_VC_m, VC_accuracy_m, VC_class_report_m\n",
        "print(X_train.shape, y_train_enc.shape, X_test.shape, y_test_enc.shape)\n",
        "VC_model_m, y_pred_VC_m, VC_accuracy_m, VC_class_report_m = VC_M(X_train, y_train_enc, X_test, y_test_enc, num_class=prediction_target['Result_R'].nunique(), voting='soft', solver='lbfgs', max_iter=1000, objective='multi:softmax', eval_metric='mlogloss', ul_enc=False)\n",
        "show_model_result(\"Voting Classifier Multi\", VC_accuracy_m, VC_class_report_m)"
      ],
      "metadata": {
        "id": "dATlp2cKJ-k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stacking Classifier"
      ],
      "metadata": {
        "id": "J3yxb3M4KIcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def S_M(X_train, y_train_enc, X_test, y_test_enc, num_class=5, solver='lbfgs', max_iter=10000, objective='multi:softmax', eval_metric='mlogloss',cv =5, n_jobs=-1, ul_enc=False):\n",
        "\n",
        "    lr_p2_m = make_pipeline(StandardScaler(), LogisticRegression(solver=solver, max_iter=max_iter, random_state=42 )) #class_weight='balanced',\n",
        "    base_models = [\n",
        "        ('lr', lr_p2_m),\n",
        "        ('rf', RandomForestClassifier(random_state=42)),\n",
        "        ('xgb', XGBClassifier(objective=objective, num_class=num_class, eval_metric=eval_metric, use_label_encoder=ul_enc,))\n",
        "    ]\n",
        "    final_estimator = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        LogisticRegression(max_iter=max_iter, random_state=42, ) #class_weight='balanced',\n",
        "    )\n",
        "    S_model_m = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=final_estimator,\n",
        "        passthrough=True,\n",
        "        cv=cv,\n",
        "        n_jobs=n_jobs\n",
        "    )\n",
        "\n",
        "    S_model_m .fit(X_train, y_train_enc)\n",
        "    y_pred_S_m = S_model_m .predict(X_test)\n",
        "\n",
        "    S_accuracy_m = accuracy_score(y_test_enc, y_pred_S_m)\n",
        "    S_class_report_m = classification_report(y_test_enc, y_pred_S_m)\n",
        "    return S_model_m, y_pred_S_m, S_accuracy_m, S_class_report_m\n",
        "\n",
        "S_model_m, y_pred_S_m, S_accuracy_m, S_class_report_m = S_M(X_train, y_train_enc, X_test, y_test_enc,num_class=prediction_target['Result_R'].nunique(), solver='lbfgs', max_iter=10000, objective='multi:softmax', eval_metric='mlogloss',cv =5, n_jobs=-1, ul_enc=False)\n",
        "show_model_result(\"Stacking Classifier Multi\", S_accuracy_m, S_class_report_m)"
      ],
      "metadata": {
        "id": "U93I2cS6KKn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of predictions from the trained models\n",
        "model_names = ['RandomForest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "\n",
        "regular_binary_predictions = [y_pred_RF, y_pred_XVG, y_pred_LR, y_pred_VC, y_pred_S]\n",
        "regular_multi_predictions= [y_pred_RF_m, y_pred_XVG_m, y_pred_LR_m, y_pred_VC_m, y_pred_S_m]\n",
        "\n",
        "regular_binary_models = [RF_model, XVG_model, LR_model, VC_model, S_model]\n",
        "regular_multi_models = [RF_model_m, XVG_model_m, LR_model_m, VC_model_m, S_model_m]\n",
        "\n",
        "regular_binary_accuracy= [RF_accuracy, XVG_accuracy, LR_accuracy, VC_accuracy, S_accuracy]\n",
        "regular_multi_accuracy = [RF_accuracy_m, XVG_accuracy_m, LR_accuracy_m, VC_accuracy_m, S_accuracy_m]\n",
        "\n",
        "regular_accuracies = {\n",
        "    'Model': model_names,\n",
        "    'Binary Accuracy': regular_binary_accuracy,\n",
        "    'Multi-Class (R Bucket) Accuracy': regular_multi_accuracy\n",
        "}\n",
        "\n",
        "regular_model_accuracies = pd.DataFrame(regular_accuracies)"
      ],
      "metadata": {
        "id": "Vq2_wmw7pj-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regular_multi_confusion_matrix = plot_confusion_matrices_horizontal(y_test, regular_multi_predictions, model_names,ticks = sorted(np.unique(y_test_enc)), multi=True)"
      ],
      "metadata": {
        "id": "qN1vZiTxrFle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Result Analysis & Visualization"
      ],
      "metadata": {
        "id": "U3oLgE6nb_fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_input = \"17:00\"  #@param {type:\"string\"}\n",
        "date_input = \"6/26/2025\"  #@param {type:\"string\"}\n",
        "criteria_input = \"ELC\"  #@param {type:\"string\"}\n",
        "CL = 6 #@param {type:\"integer\"}\n",
        "CW = 0 #@param {type:\"integer\"}\n",
        "\n",
        "# Define model base names\n",
        "model_names = ['RandomForest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "\n",
        "show_predictions(time_input, date_input, criteria_input,  CL, CW, training_feature_cols, model_names, model_keys, precomputed_stats=precomputed_stats,label_encoder=label_encoder, b_models=regular_binary_models, m_models=regular_multi_models, b_acc=regular_accuracies['Binary Accuracy'], m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                 w_threshold=1)\n",
        "\n",
        "# Plot the confusion matrices horizontally\n",
        "# plot_confusion_matrices_horizontal(y_test, all_predictions, model_names)"
      ],
      "metadata": {
        "id": "1iYrLv1TWngw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the final overall statistics DataFrame\n",
        "regular_models_m = {\n",
        "        'RandomForest': RF_model_m,\n",
        "        'XGBoost': XVG_model_m,\n",
        "        'Logistic Regression': LR_model_m,\n",
        "        'Voting Classifier': VC_model_m,\n",
        "        'Stacking Classifier': S_model_m\n",
        "    }\n",
        "# overall_stats_df = overall_stats(df, features_filtered,training_feature_cols)\n",
        "overall_stats_df = overall_stats(X_test_P, X_test, regular_models_m, training_feature_cols)\n",
        "print(\"\\nOverall Statistics for Trades Predicted as 'Win' by Each Model:\")\n",
        "overall_stats_df\n"
      ],
      "metadata": {
        "id": "WimHb6lBY3kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_trades_by_prediction(df, X_test, model):\n",
        "  # Predict on the feature set\n",
        "  pred_result = model.predict(X_test)\n",
        "\n",
        "  # Get the indices where the prediction is 'Win' (class 1)\n",
        "  win_indices = X_test.iloc[pred_result == 1].index\n",
        "\n",
        "  # Filter the original DataFrame using these indices\n",
        "  df_filtered_win = df.loc[win_indices]\n",
        "\n",
        "  return df_filtered_win\n",
        "\n",
        "def get_prediction_trade_files(df, X_test, models, file_dir):\n",
        "    predicted_win_dfs = []\n",
        "    for model_name, model in models.items():\n",
        "        # Filter the X_test_P DataFrame (which contains the original columns for the test set)\n",
        "        # based on the prediction from the corresponding binary model using the X_test features.\n",
        "        df_trades_predicted_win = filter_trades_by_prediction(df, X_test, model)\n",
        "        # print(df_trades_predicted_win.shape)\n",
        "        predicted_win_dfs.append(df_trades_predicted_win)\n",
        "\n",
        "        # Define the output filename\n",
        "        output_filename = f'{file_dir}{model_name}_Predicted_Wins.xlsx'\n",
        "        print(f\"Saved trades predicted as 'Win' by {model_name} to '{output_filename}'\")\n",
        "\n",
        "        # Save the filtered DataFrame to an Excel file\n",
        "        df_trades_predicted_win.to_excel(output_filename, index=False)\n",
        "    combined_predicted_wins = pd.concat(predicted_win_dfs, ignore_index=True)\n",
        "    combined_predicted_wins_unique = combined_predicted_wins.drop_duplicates(subset=['S/l']).sort_values(by='S/l')\n",
        "    return combined_predicted_wins_unique, predicted_win_dfs"
      ],
      "metadata": {
        "id": "Vj07C4OiLtyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_models = {\n",
        "    'RandomForest': RF_model,\n",
        "    'XGBoost': XVG_model,\n",
        "    'Logistic Regression': LR_model,\n",
        "    'Voting Classifier': VC_model,\n",
        "    'Stacking Classifier': S_model\n",
        "}\n",
        "\n",
        "file_dir = 'trade_files/'\n",
        "os.makedirs(file_dir, exist_ok=True)\n",
        "\n",
        "combined_predicted_wins_unique, predicted_win_dfs = get_prediction_trade_files(df, X_test, binary_models, file_dir)\n",
        "combined_predicted_wins_unique.to_excel(f'{file_dir}regular_combined_prediction.xlsx', index=False)\n",
        "print(\"\\nCombined and unique predicted wins saved to 'All_Models_Predicted_Wins_Unique.xlsx'\")\n",
        "\n",
        "RFS_LC_predicted_wins_unique = pd.concat([predicted_win_dfs[0], predicted_win_dfs[2]], ignore_index=True).drop_duplicates(subset=['S/l']).sort_values(by='S/l')\n",
        "RFS_LC_predicted_wins_unique.to_excel(f'{file_dir}RFS_LC.xlsx', index=False)\n",
        "combined_predicted_wins_unique.shape"
      ],
      "metadata": {
        "id": "u9lsbDvbogp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_predicted_wins_df = predicted_win_dfs[1] # XGBoost is at index 1\n",
        "\n",
        "# Combine predicted wins from all models EXCEPT XGBoost\n",
        "other_models_predicted_wins_dfs = [df for i, df in enumerate(predicted_win_dfs) if i != 1]\n",
        "combined_other_models_predicted_wins = pd.concat(other_models_predicted_wins_dfs, ignore_index=True)\n",
        "combined_other_models_predicted_wins_unique = combined_other_models_predicted_wins.drop_duplicates(subset=['S/l'])\n",
        "\n",
        "# Calculate losses for trades in each group\n",
        "# A trade is a 'Loss' if 'Profit/Loss' is negative\n",
        "xgboost_losses = xgboost_predicted_wins_df[xgboost_predicted_wins_df['Profit/Loss'] < 0]\n",
        "other_combined_losses = combined_other_models_predicted_wins_unique[combined_other_models_predicted_wins_unique['Profit/Loss'] < 0]\n",
        "\n",
        "# Compare the losses\n",
        "print(\"\\n--- Comparison of Losses ---\")\n",
        "print(f\"Number of Losses in Trades Predicted as 'Win' by XGBoost: {len(xgboost_losses)}\")\n",
        "print(f\"Total Loss Amount for XGBoost Predicted Wins: {xgboost_losses['Profit/Loss'].sum():.2f}\")\n",
        "print(f\"Average Loss Amount for XGBoost Predicted Wins: {xgboost_losses['Profit/Loss'].mean():.2f}\")\n",
        "\n",
        "print(f\"\\nNumber of Losses in Trades Predicted as 'Win' by Other Combined Models: {len(other_combined_losses)}\")\n",
        "print(f\"Total Loss Amount for Other Combined Models Predicted Wins: {other_combined_losses['Profit/Loss'].sum():.2f}\")\n",
        "print(f\"Average Loss Amount for Other Combined Models Predicted Wins: {other_combined_losses['Profit/Loss'].mean():.2f}\")\n"
      ],
      "metadata": {
        "id": "kHrIiEIqPEof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show xgb model predicted win that actully win s/l difference betwwen other model combine predicted win and actually win uniuqe\n",
        "\n",
        "# Filter trades predicted as 'Win' by XGBoost and see which ones were actually 'Win' or 'Loss'\n",
        "xgboost_predicted_wins_actual_results = xgboost_predicted_wins_df[['S/l', 'Result', 'Profit/Loss']]\n",
        "\n",
        "\n",
        "# Filter trades predicted as 'Win' by combined Other Models and see which ones were actually 'Win' or 'Loss'\n",
        "other_combined_predicted_wins_actual_results = combined_other_models_predicted_wins_unique[['S/l', 'Result', 'Profit/Loss']]\n",
        "\n",
        "\n",
        "# Find the unique S/l values where XGBoost predicted Win and the actual result was Win\n",
        "xgboost_actual_wins_sl = xgboost_predicted_wins_df[xgboost_predicted_wins_df['Result'] == 'W']['S/l'].unique()\n",
        "print(f\"\\nUnique S/l where XGBoost Predicted Win and Actually Won: {len(xgboost_actual_wins_sl)}\")\n",
        "\n",
        "# Find the unique S/l values where combined Other Models predicted Win and the actual result was Win\n",
        "other_combined_actual_wins_sl = combined_other_models_predicted_wins_unique[combined_other_models_predicted_wins_unique['Result'] == 'W']['S/l'].unique()\n",
        "print(f\"Unique S/l where Other Combined Models Predicted Win (Unique S/l) and Actually Won: {len(other_combined_actual_wins_sl)}\")\n",
        "\n",
        "# Find the S/l values that are unique to XGBoost (predicted Win and actually Won)\n",
        "unique_to_xgboost_actual_wins_sl = np.setdiff1d(xgboost_actual_wins_sl, other_combined_actual_wins_sl)\n",
        "print(f\"\\nUnique S/l where ONLY XGBoost Predicted Win and Actually Won: {len(unique_to_xgboost_actual_wins_sl)}\")\n",
        "print(f\"List of S/l unique to XGBoost actual wins: {unique_to_xgboost_actual_wins_sl.tolist()}\")\n",
        "\n",
        "# Find the S/l values that are unique to Other Combined Models (predicted Win and actually Won)\n",
        "unique_to_other_combined_actual_wins_sl = np.setdiff1d(other_combined_actual_wins_sl, xgboost_actual_wins_sl)\n",
        "print(f\"\\nUnique S/l where ONLY Other Combined Models Predicted Win (Unique S/l) and Actually Won: {len(unique_to_other_combined_actual_wins_sl)}\")\n",
        "print(f\"List of S/l unique to Other Combined Models actual wins: {unique_to_other_combined_actual_wins_sl.tolist()}\")\n",
        "\n",
        "# Find the S/l values where both predicted Win and actually Won\n",
        "common_actual_wins_sl = np.intersect1d(xgboost_actual_wins_sl, other_combined_actual_wins_sl)\n",
        "print(f\"\\nUnique S/l where Both XGBoost and Other Combined Models Predicted Win and Actually Won: {len(common_actual_wins_sl)}\")\n",
        "print(f\"List of S/l common actual wins: {common_actual_wins_sl.tolist()}\")\n",
        "\n",
        "\n",
        "# Filter trades predicted as 'Win' by XGBoost and the actual result was 'Loss'\n",
        "xgboost_predicted_win_actual_loss_sl = xgboost_predicted_wins_df[xgboost_predicted_wins_df['Result'] == 'L']['S/l'].unique()\n",
        "print(f\"\\nUnique S/l where XGBoost Predicted Win and Actually Lost: {len(xgboost_predicted_win_actual_loss_sl)}\")\n",
        "\n",
        "# Filter trades predicted as 'Win' by combined Other Models (unique S/l) and the actual result was 'Loss'\n",
        "other_combined_predicted_win_actual_loss_sl = combined_other_models_predicted_wins_unique[combined_other_models_predicted_wins_unique['Result'] == 'L']['S/l'].unique()\n",
        "print(f\"Unique S/l where Other Combined Models Predicted Win (Unique S/l) and Actually Lost: {len(other_combined_predicted_win_actual_loss_sl)}\")\n",
        "\n",
        "# Find the unique S/l values in XGBoost predicted win and actually loss\n",
        "unique_to_xgboost_predicted_win_actual_loss_sl = np.setdiff1d(xgboost_predicted_win_actual_loss_sl, other_combined_predicted_win_actual_loss_sl)\n",
        "print(f\"\\nUnique S/l where ONLY XGBoost Predicted Win and Actually Lost: {len(unique_to_xgboost_predicted_win_actual_loss_sl)}\")\n",
        "print(f\"List of S/l unique to XGBoost predicted win and actual loss: {unique_to_xgboost_predicted_win_actual_loss_sl.tolist()}\")\n",
        "\n",
        "# Find the S/l values that are unique to Other Combined Models (predicted Win and actually Loss)\n",
        "unique_to_other_combined_predicted_win_actual_loss_sl = np.setdiff1d(other_combined_predicted_win_actual_loss_sl, xgboost_predicted_win_actual_loss_sl)\n",
        "print(f\"\\nUnique S/l where ONLY Other Combined Models Predicted Win (Unique S/l) and Actually Lost: {len(unique_to_other_combined_predicted_win_actual_loss_sl)}\")\n",
        "print(f\"List of S/l unique to Other Combined Models predicted win and actual loss: {unique_to_other_combined_predicted_win_actual_loss_sl.tolist()}\")\n",
        "\n",
        "# Find the S/l values where both predicted Win and actually Lost\n",
        "common_predicted_win_actual_loss_sl = np.intersect1d(xgboost_predicted_win_actual_loss_sl, other_combined_predicted_win_actual_loss_sl)\n",
        "print(f\"\\nUnique S/l where Both XGBoost and Other Combined Models Predicted Win and Actually Lost: {len(common_predicted_win_actual_loss_sl)}\")\n",
        "print(f\"List of S/l common predicted win and actual loss: {common_predicted_win_actual_loss_sl.tolist()}\")\n"
      ],
      "metadata": {
        "id": "Y5k4EYZ8S1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save other_combined_losses\n",
        "\n",
        "# combined_other_models_predicted_wins_unique.to_excel('Other_Combined.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "hdZVQN6EUWqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ML-Max R"
      ],
      "metadata": {
        "id": "8KEg7trGqaZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_max_r = pd.read_excel('SSL_T_MR.xlsx')"
      ],
      "metadata": {
        "id": "JDmDxfChqj_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: count  of R value in df_max_r  that jave Result == 'W' greater than 5 and less then 9\n",
        "\n",
        "# Filter the DataFrame where 'Result' is 'W'\n",
        "df_wins = df_max_r[df_max_r['Result'] == 'W']\n",
        "\n",
        "# Count occurrences where 'R' is greater than 5 and less than 9\n",
        "r_count = df_wins[(df_wins['R'] > 8) & (df_wins['R'] < 100)].shape[0]\n",
        "\n",
        "print(f\"Count of 'R' values in df_max_r that have 'Result' == 'W' and are between 5 and 9: {r_count}\")\n"
      ],
      "metadata": {
        "id": "-i5PcMDF0M8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_max_r = prepare_data(df_max_r)\n",
        "df_max_r = calculate_prior_streaks(df_max_r)"
      ],
      "metadata": {
        "id": "R7et005WqgTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precomputed_stats_max_r = get_precomputed_stats(df_max_r)\n",
        "# Save precomputed_stats\n",
        "joblib.dump(precomputed_stats_max_r, 'precomputed_stats_max_r.pkl')\n",
        "precomputed_stats_max_r = joblib.load('precomputed_stats_max_r.pkl')"
      ],
      "metadata": {
        "id": "L76CATIR5xFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_max_r = get_train_data(df_max_r, precomputed_stats_max_r)\n",
        "train_data_max_r = processing_train_data(df_max_r, train_data_max_r, R_threshold=7)\n",
        "train_data_max_r = save_read_train_data(train_data_max_r, name = 'train_data_max_r')\n",
        "# train_data_max_r = convert_train_data_type(train_data_max_r)"
      ],
      "metadata": {
        "id": "AqZd42wiuS8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_max_r, features_filtered_max_r, prediction_target_max_r = extract_ptarget_feature(train_data_max_r)\n",
        "X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, y_train_m_max_r, y_test_m_max_r, X_train_P_max_r, X_test_P_max_r= split_data(features_max_r, prediction_target_max_r)\n",
        "show_split_data(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, y_train_m_max_r, y_test_m_max_r)"
      ],
      "metadata": {
        "id": "3PbvjANtuQCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_feature_cols_max_r = X_train_max_r.columns\n",
        "# X_train_max_r.info()"
      ],
      "metadata": {
        "id": "SetlREs3Tgxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model_max_r,y_pred_RF_max_r, RF_accuracy_max_r, RF_class_report_max_r = RF(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, n_estimators=100)\n",
        "show_model_result(\"Random Forest-Max R\", RF_accuracy, RF_class_report)\n",
        "\n",
        "XVG_model_max_r, y_pred_XVG_max_r, XVG_accuracy_max_r, XVG_class_report_max_r = XVG(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, eval_metric='logloss')\n",
        "show_model_result(\"XGBoost-Max R\", XVG_accuracy_max_r, XVG_class_report_max_r)\n",
        "\n",
        "LR_model_max_r,y_pred_LR_max_r, LR_accuracy_max_r, LR_class_report_max_r = LR(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, solver='lbfgs', max_iter=1000)\n",
        "show_model_result(\"Logistic Regression-Max R\", LR_accuracy_max_r, LR_class_report_max_r)\n",
        "\n",
        "VC_model_max_r,y_pred_VC_max_r, VC_accuracy_max_r, VC_class_report_max_r = VC(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, max_iter= 1000, eval_metric='logloss', voting='soft')\n",
        "show_model_result(\"Voting Classifier-Max R\", VC_accuracy_max_r, VC_class_report_max_r)\n",
        "\n",
        "S_model_max_r,y_pred_S_max_r, S_accuracy_max_r, S_class_report_max_r = S(X_train_max_r, X_test_max_r, y_train_max_r, y_test_max_r, max_iter= 1000, eval_metric='logloss', cv=5, n_jobs=-1, ul_enc=False)\n",
        "show_model_result(\"Stacking Classifier-Max R\", S_accuracy_max_r, S_class_report_max_r)"
      ],
      "metadata": {
        "id": "NGFKVSFquNPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of predictions from the trained models\n",
        "regular_binary_predictions_max_r = [y_pred_RF_max_r, y_pred_XVG_max_r, y_pred_LR_max_r, y_pred_VC_max_r, y_pred_S_max_r]\n",
        "\n",
        "# List of model names\n",
        "model_names_max_r = ['RandomForest-Max R', 'XGBoost-Max R', 'Logistic Regression-Max R', 'Voting Classifier-Max R', 'Stacking Classifier-Max R']\n",
        "\n",
        "# Plot the confusion matrices horizontally\n",
        "max_r_binary_confusion_matrix = plot_confusion_matrices_horizontal(y_test_max_r, regular_binary_predictions_max_r , model_names_max_r)"
      ],
      "metadata": {
        "id": "W7pyyuOjuKXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder_max_r, y_train_enc_max_r, y_test_enc_max_r, class_mapping_max_r, reverse_mapping_max_r = encode_train_test(y_train_m_max_r, y_test_m_max_r)"
      ],
      "metadata": {
        "id": "yx_4v2PnuJC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model_m_max_r, y_pred_RF_m_max_r, RF_accuracy_m_max_r, RF_class_report_m_max_r = RF_M(X_train_max_r, y_train_enc_max_r, X_test_max_r, y_test_enc_max_r, n_estimators=100)\n",
        "show_model_result(\"RandomForest Multi-Max R\", RF_accuracy_m_max_r, RF_class_report_m_max_r)\n",
        "\n",
        "XVG_model_m_max_r, y_pred_XVG_m_max_r, XVG_accuracy_m_max_r, XVG_class_report_m_max_r = XVG_M(X_train_max_r, y_train_enc_max_r, X_test_max_r, y_test_enc_max_r,num_class=prediction_target['Result_R'].nunique(), objective='multi:softmax', eval_metric = 'mlogloss', ul_enc = False)\n",
        "show_model_result(\"XGBoost Multi-Max R\", XVG_accuracy_m_max_r, XVG_class_report_m_max_r)\n",
        "\n",
        "LR_model_m_max_r, y_pred_LR_m_max_r, LR_accuracy_m_max_r, LR_class_report_m_max_r = LR_M(X_train_max_r, y_train_enc_max_r, X_test_max_r, y_test_enc_max_r, solver='lbfgs', max_iter=10000)\n",
        "show_model_result(\"Logistic Regression Multi-Max R\", LR_accuracy_m_max_r, LR_class_report_m_max_r)\n",
        "\n",
        "VC_model_m_max_r, y_pred_VC_m_max_r, VC_accuracy_m_max_r, VC_class_report_m_max_r = VC_M(X_train_max_r, y_train_enc_max_r, X_test_max_r, y_test_enc_max_r,num_class=prediction_target['Result_R'].nunique(), voting='soft', solver='lbfgs', max_iter=1000, objective='multi:softmax', eval_metric='mlogloss',ul_enc=False)\n",
        "show_model_result(\"Voting Classifier Multi-Max R\", VC_accuracy_m_max_r, VC_class_report_m_max_r)\n",
        "\n",
        "S_model_m_max_r, y_pred_S_m_max_r, S_accuracy_m_max_r, S_class_report_m_max_r = S_M(X_train_max_r, y_train_enc_max_r, X_test_max_r, y_test_enc_max_r,num_class=prediction_target['Result_R'].nunique(), solver='lbfgs', max_iter=10000, objective='multi:softmax', eval_metric='mlogloss',cv =5, n_jobs=-1, ul_enc=False)\n",
        "show_model_result(\"Stacking Classifier Multi-Max R\", S_accuracy_m_max_r, S_class_report_m_max_r)"
      ],
      "metadata": {
        "id": "5A9F2xiKuGny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of predictions from the trained models\n",
        "regular_multi_predictions_max_r = [y_pred_RF_m_max_r, y_pred_XVG_m_max_r, y_pred_LR_m_max_r, y_pred_VC_m_max_r, y_pred_S_m_max_r]\n",
        "# List of model names\n",
        "model_names_m_max_r = ['RandomForest Multi-Max R', 'XGBoost Multi-Max R', 'Logistic Regression Multi-Max R', 'Voting Classifier Multi-Max R', 'Stacking Classifier Multi-Max R']\n",
        "\n",
        "# Plot the confusion matrices horizontally\n",
        "max_r_multi_confusion_matrix = plot_confusion_matrices_horizontal(y_test_enc_max_r, regular_multi_predictions_max_r, model_names_m_max_r ,ticks = sorted(np.unique(y_test_enc_max_r)), multi=True)"
      ],
      "metadata": {
        "id": "CTOSlvDyuAkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names_max_r = ['RandomForest Multi-Max R', 'XGBoost Multi-Max R', 'Logistic Regression Multi-Max R', 'Voting Classifier Multi-Max R', 'Stacking Classifier Multi-Max R']\n",
        "regular_binary_models_max_r = [RF_model_max_r, XVG_model_max_r, LR_model_max_r, VC_model_max_r, S_model_max_r]\n",
        "regular_multi_models_max_r = [RF_model_m_max_r, XVG_model_m_max_r, LR_model_m_max_r, VC_model_m_max_r, S_model_m_max_r]\n",
        "\n",
        "regular_binary_accuracy_max_r= [RF_accuracy_max_r, XVG_accuracy_max_r, LR_accuracy_max_r, VC_accuracy_max_r, S_accuracy_max_r]\n",
        "regular_multi_accuracy_max_r = [RF_accuracy_m_max_r, XVG_accuracy_m_max_r, LR_accuracy_m_max_r, VC_accuracy_m_max_r, S_accuracy_m_max_r]\n",
        "\n",
        "regular_accuracies_max_r = {\n",
        "    'Model': model_names_m_max_r,\n",
        "    'Binary Accuracy': regular_binary_accuracy_max_r,\n",
        "    'Multi-Class (R Bucket) Accuracy': regular_multi_accuracy_max_r\n",
        "}\n",
        "\n",
        "regular_model_accuracies_max_r = pd.DataFrame(regular_accuracies_max_r)"
      ],
      "metadata": {
        "id": "PF9Y06QA9iYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_input = \"15:00\"  #@param {type:\"string\"}\n",
        "date_input = \"7/3/2025\"  #@param {type:\"string\"}\n",
        "criteria_input = \"LG PWH\"  #@param {type:\"string\"}\n",
        "CL = 3 #@param {type:\"integer\"}\n",
        "CW = 0 #@param {type:\"integer\"}\n",
        "\n",
        "model_names_max_r = ['RandomForest Max R', 'XGBoost Max R', 'Logistic Regression Max R', 'Voting Classifier Max R', 'Stacking Classifier Max R']\n",
        "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "show_predictions(time_input, date_input, criteria_input, CL, CW, training_feature_cols, model_names_max_r, model_keys,precomputed_stats=precomputed_stats,label_encoder=label_encoder, b_models=regular_binary_models_max_r, m_models=regular_multi_models_max_r, b_acc=regular_accuracies_max_r['Binary Accuracy'], m_acc=regular_accuracies_max_r['Multi-Class (R Bucket) Accuracy'],\n",
        "                 Max_R=True, w_threshold=1)\n",
        "# Plot the confusion matrices horizontally\n",
        "regular_binary_confusion_matrix = plot_confusion_matrices_horizontal(y_test_max_r, regular_binary_predictions_max_r, model_names_max_r)"
      ],
      "metadata": {
        "id": "Nn-LNtAA_8Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_r_models = {\n",
        "        'RandomForest-MaxR': RF_model_max_r,\n",
        "        'XGBoost-MaxR': XVG_model_max_r,\n",
        "        'Logistic Regression-MaxR': LR_model_max_r,\n",
        "        'Voting Classifier-MaxR': VC_model_max_r,\n",
        "        'Stacking Classifier-MaxR': S_model_max_r\n",
        "    }\n",
        "overall_stats_df_max_r = overall_stats(X_test_P_max_r, X_test_max_r,max_r_models, training_feature_cols)\n",
        "print(\"\\nOverall Statistics for Trades Predicted as 'Win' by Each Model:\")\n",
        "overall_stats_df_max_r"
      ],
      "metadata": {
        "id": "bhlkkXmpm-Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns==X_train_max_r.columns"
      ],
      "metadata": {
        "id": "2OR2eVGhX87e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_models_max_r = {\n",
        "    'RandomForest-MaxR': RF_model_max_r,\n",
        "    'XGBoost-MaxR': XVG_model_max_r,\n",
        "    'Logistic Regression-MaxR': LR_model_max_r,\n",
        "    'Voting Classifier-MaxR': VC_model_max_r,\n",
        "    'Stacking Classifier-MaxR': S_model_max_r\n",
        "}\n",
        "\n",
        "file_dir = 'trade_files_max_r/'\n",
        "os.makedirs(file_dir, exist_ok=True)\n",
        "\n",
        "combined_predicted_wins_unique_max_r, predicted_win_dfs_max_r = get_prediction_trade_files(df, X_test_max_r, binary_models_max_r, file_dir)\n",
        "combined_predicted_wins_unique_max_r.to_excel(f'{file_dir}regular_combined_prediction_max_R.xlsx', index=False)\n",
        "print(f\"\\nCombined and unique predicted wins saved to '{file_dir}regular_combined_prediction_max_R.xlsx'\")\n",
        "\n",
        "RFS_LC_predicted_wins_unique_max_r = pd.concat([predicted_win_dfs_max_r[0], predicted_win_dfs_max_r[2]], ignore_index=True).drop_duplicates(subset=['S/l']).sort_values(by='S/l')\n",
        "RFS_LC_predicted_wins_unique_max_r.to_excel(f'{file_dir}RFS_LC_max_R.xlsx', index=False)\n",
        "combined_predicted_wins_unique_max_r.shape"
      ],
      "metadata": {
        "id": "sW57yTD-qfwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine combined_predicted_wins_unique and combined_predicted_wins_unique_max_r\n",
        "combined_predicted_wins_all = pd.concat([combined_predicted_wins_unique, combined_predicted_wins_unique_max_r], ignore_index=True).drop_duplicates(subset=['S/l']).sort_values(by='S/l')\n",
        "# Save the combined DataFrame\n",
        "combined_predicted_wins_all.to_excel(f'BR_combined_predicted_wins_all.xlsx', index=False)\n",
        "print(f\"Combined and sorted unique predicted wins from all models (regular and max_r) saved to '{file_dir}combined_predicted_wins_all.xlsx'\")\n",
        "\n",
        "# Combine RFS_LC_predicted_wins_unique and RFS_LC_predicted_wins_unique_max_r\n",
        "combined_RFS_LC_all = pd.concat([RFS_LC_predicted_wins_unique, RFS_LC_predicted_wins_unique_max_r], ignore_index=True).drop_duplicates(subset=['S/l']).sort_values(by='S/l')\n",
        "\n",
        "combined_RFS_LC_all.to_excel(f'BR_combined_RFS_LC_all.xlsx', index=False)\n",
        "print(f\"Combined and sorted unique RFS_LC predicted wins (regular and max_r) saved to '{file_dir}combined_RFS_LC_all.xlsx'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9zGhrl_LtFid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving All Data"
      ],
      "metadata": {
        "id": "cidayzdHRvMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save all models\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create a directory to save the models if it doesn't exist\n",
        "model_dir = 'saved_models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Define a dictionary of models to save\n",
        "models_to_save = {\n",
        "    'RF_model': RF_model,\n",
        "    'XVG_model': XVG_model,\n",
        "    'LR_model': LR_model,\n",
        "    'VC_model': VC_model,\n",
        "    'S_model': S_model,\n",
        "    'RF_model_m': RF_model_m,\n",
        "    'XVG_model_m': XVG_model_m,\n",
        "    'LR_model_m': LR_model_m,\n",
        "    'VC_model_m': VC_model_m,\n",
        "    'S_model_m': S_model_m,\n",
        "    # Include Max R models if they were successfully trained\n",
        "    'RF_model_max_r': RF_model_max_r if 'RF_model_max_r' in globals() else None,\n",
        "    'XVG_model_max_r': XVG_model_max_r if 'XVG_model_max_r' in globals() else None,\n",
        "    'LR_model_max_r': LR_model_max_r if 'LR_model_max_r' in globals() else None,\n",
        "    'VC_model_max_r': VC_model_max_r if 'VC_model_max_r' in globals() else None,\n",
        "    'S_model_max_r': S_model_max_r if 'S_model_max_r' in globals() else None,\n",
        "    'RF_model_m_max_r': RF_model_m_max_r if 'RF_model_m_max_r' in globals() else None,\n",
        "    'XVG_model_m_max_r': XVG_model_m_max_r if 'XVG_model_m_max_r' in globals() else None,\n",
        "    'LR_model_m_max_r': LR_model_m_max_r if 'LR_model_m_max_r' in globals() else None,\n",
        "    'VC_model_m_max_r': VC_model_m_max_r if 'VC_model_m_max_r' in globals() else None,\n",
        "    'S_model_m_max_r': S_model_m_max_r if 'S_model_m_max_r' in globals() else None,\n",
        "    # Save the label encoder\n",
        "    'label_encoder': label_encoder if 'label_encoder' in globals() else None,\n",
        "    'label_encoder_max_r': label_encoder_max_r if 'label_encoder_max_r' in globals() else None,\n",
        "}\n",
        "\n",
        "# Save each model\n",
        "for name, model in models_to_save.items():\n",
        "    if model is not None: # Check if the model variable exists (especially for Max R models)\n",
        "        filename = os.path.join(model_dir, f'{name}.pkl')\n",
        "        try:\n",
        "            joblib.dump(model, filename)\n",
        "            print(f\"Saved {name} to '{filename}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving {name}: {e}\")\n",
        "    else:\n",
        "        print(f\"Model '{name}' not found, skipping save.\")\n"
      ],
      "metadata": {
        "id": "eK4BmkQ7vsnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get current UTC datetime\n",
        "current_utc_datetime = datetime.now(timezone.utc)\n",
        "\n",
        "# Get the shapes of the training and test sets\n",
        "train_size = X_train.shape[0]\n",
        "test_size = X_test.shape[0]\n",
        "\n",
        "# Format the datetime for the filename and content\n",
        "formatted_datetime = current_utc_datetime.strftime(\"%Y%m%d_%H%M%S_UTC\")\n",
        "\n",
        "# Create a string with the details\n",
        "model_info = f\"Model Training Details\\n\"\n",
        "model_info += f\"Date and Time (UTC): {current_utc_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')}\\n\"\n",
        "model_info += f\"Training Set Size: {train_size} rows\"\n",
        "model_info += f\"----- Test Set Size: {test_size} rows ---- Total: {train_size + test_size} rows in dataset.\\n\"\n",
        "model_info += f\"Train-From S/L: {df.iloc[0]['S/l']} - {df.iloc[train_size-1]['S/l']} Date: {df.iloc[0]['startDateTime'].strftime('%d/%m/%Y %H:%M')} - {df.iloc[train_size-1]['startDateTime'].strftime('%d/%m/%Y %H:%M')}\\n\"\n",
        "model_info +=f\"Test-From S/L: {df.iloc[train_size]['S/l']} - S/L: {df.iloc[-1]['S/l']} Date: {df.iloc[train_size]['startDateTime'].strftime('%d/%m/%Y %H:%M')} - {df.iloc[-1]['startDateTime'].strftime('%d/%m/%Y %H:%M')}\\n\"\n",
        "# model_info += f\"Prediction Targets: {prediction_target['Result_R'].nunique()} unique values\"\n",
        "\n",
        "\n",
        "details_filename = f\"saved_models/model_details.txt\"\n",
        "\n",
        "# Save the details to a text file\n",
        "with open(details_filename, 'w') as f:\n",
        "    f.write(model_info)\n",
        "\n",
        "print(f\"Saved model details to '{details_filename}'\")\n",
        "\n",
        "unique_criteria_list = df['Criteria'].unique().tolist()\n",
        "criteria_filename = os.path.join('saved_models/unique_criteria.txt')\n",
        "with open(criteria_filename, 'w') as f:\n",
        "          for item in unique_criteria_list:\n",
        "            f.write(f\"{item}\\n\")\n",
        "\n",
        "          print(f\"\\nSaved unique criteria to '{criteria_filename}'\")"
      ],
      "metadata": {
        "id": "brwgBgU2KWBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_dir = 'saved_models/accuracies/'\n",
        "os.makedirs(accuracies_dir, exist_ok=True)\n",
        "\n",
        "regular_model_accuracies.to_excel(f\"{accuracies_dir}regular_model_accuracies.xlsx\", index=False)\n",
        "print(f\"\\nSaved regular model accuracies to {accuracies_dir}regular_model_accuracies.xlsx\")\n",
        "\n",
        "# Combine accuracies for Max R models\n",
        "regular_model_accuracies_max_r.to_excel(f\"{accuracies_dir}max_r_model_accuracies.xlsx\", index=False)\n",
        "print(f\"\\nSaved Max R model accuracies to {accuracies_dir}max_r_model_accuracies.xlsx\")\n",
        "\n",
        "joblib.dump(training_feature_cols, f\"{accuracies_dir}training_feature_cols.pkl\")\n",
        "joblib.dump(precomputed_stats, f\"{accuracies_dir}precomputed_stats.pkl\")\n",
        "joblib.dump(precomputed_stats_max_r, f\"{accuracies_dir}precomputed_stats_max_r.pkl\")"
      ],
      "metadata": {
        "id": "o08Hw63SH4Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read Require Data"
      ],
      "metadata": {
        "id": "YdQ5kQYqVKJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_accuracy_dataframes(file_dir):\n",
        "    try:\n",
        "      precomputed_stats = joblib.load(f'{file_dir}/precomputed_stats.pkl')\n",
        "      max_r_precomputed_stats = joblib.load(f'{file_dir}/precomputed_stats_max_r.pkl')\n",
        "      training_feature_cols = joblib.load(f'{file_dir}/training_feature_cols.pkl')\n",
        "      regular_accuracies = pd.read_excel(f'{file_dir}/regular_model_accuracies.xlsx')\n",
        "      max_r_accuracies = pd.read_excel(f'{file_dir}/max_r_model_accuracies.xlsx')\n",
        "\n",
        "      print(\"\\n--- Regular Model Accuracies ---\")\n",
        "      print(tabulate(regular_accuracies, headers='keys', tablefmt='psql'))\n",
        "\n",
        "      print(\"\\n--- Max R Model Accuracies ---\")\n",
        "      print(tabulate(max_r_accuracies, headers='keys', tablefmt='psql'))\n",
        "\n",
        "      return precomputed_stats,max_r_precomputed_stats, training_feature_cols, regular_accuracies, max_r_accuracies\n",
        "\n",
        "    except FileNotFoundError:\n",
        "      print(\"Accuracy files not found. Please run the model training section first.\")\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred while reading the accuracy files: {e}\")"
      ],
      "metadata": {
        "id": "T0cSCV36I5AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_dir = 'saved_models/accuracies'\n",
        "precomputed_stats,precomputed_stats_max_r, training_feature_cols, regular_accuracies, max_r_accuracies = read_accuracy_dataframes(accuracies_dir)"
      ],
      "metadata": {
        "id": "b01yrnKHaQiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_models(model_dir):\n",
        "\n",
        "    # Define lists to store the loaded models\n",
        "    regular_binary_models = []\n",
        "    regular_multi_models = []\n",
        "    max_r_binary_models = []\n",
        "    max_r_multi_models = []\n",
        "\n",
        "    # List of model base names (keys used in filenames)\n",
        "    model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "\n",
        "    # Load regular binary models\n",
        "    print(\"Loading regular binary models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            regular_binary_models.append(model)\n",
        "            print(f\"Loaded {key}_model\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model: {e}\")\n",
        "\n",
        "    # Load regular multi-class models\n",
        "    print(\"\\nLoading regular multi-class models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_m.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            regular_multi_models.append(model)\n",
        "            print(f\"Loaded {key}_model_m\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_m.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_m: {e}\")\n",
        "\n",
        "    # Load max R binary models\n",
        "    print(\"\\nLoading Max R binary models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_max_r.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            max_r_binary_models.append(model)\n",
        "            print(f\"Loaded {key}_model_max_r\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_max_r.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_max_r: {e}\")\n",
        "\n",
        "    # Load max R multi-class models\n",
        "    print(\"\\nLoading Max R multi-class models...\")\n",
        "    for key in model_keys:\n",
        "        filename = os.path.join(model_dir, f'{key}_model_m_max_r.pkl')\n",
        "        try:\n",
        "            model = joblib.load(filename)\n",
        "            max_r_multi_models.append(model)\n",
        "            print(f\"Loaded {key}_model_m_max_r\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: {key}_model_m_max_r.pkl not found. Please run the saving section first.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {key}_model_m_max_r: {e}\")\n",
        "\n",
        "    # Load Label Encoders\n",
        "    print(\"\\nLoading Label Encoders...\")\n",
        "    try:\n",
        "        label_encoder = joblib.load(os.path.join(model_dir, 'label_encoder.pkl'))\n",
        "        print(\"Loaded label_encoder\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: label_encoder.pkl not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label_encoder: {e}\")\n",
        "\n",
        "    try:\n",
        "        label_encoder_max_r = joblib.load(os.path.join(model_dir, 'label_encoder_max_r.pkl'))\n",
        "        print(\"Loaded label_encoder_max_r\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: label_encoder_max_r.pkl not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label_encoder_max_r: {e}\")\n",
        "\n",
        "    try:\n",
        "      # Load the saved model details file\n",
        "        filename = os.path.join(model_dir, 'model_details.txt')\n",
        "        with open(filename, 'r') as f:\n",
        "          model_details = f.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model details.txt, {e}\")\n",
        "    try:\n",
        "      criteria_filename = os.path.join(model_dir, 'unique_criteria.txt')\n",
        "      with open(criteria_filename, 'r') as f:\n",
        "        unique_criteria = [line.strip() for line in f]\n",
        "        print(\"Successfully read unique criteria from file.\")\n",
        "        print(\"Read Criteria:\", unique_criteria)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "\n",
        "\n",
        "    return regular_binary_models, regular_multi_models, max_r_binary_models, max_r_multi_models, label_encoder, label_encoder_max_r, model_details, unique_criteria"
      ],
      "metadata": {
        "id": "3vtlJirpHqOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'saved_models'\n",
        "regular_binary_models, regular_multi_models, max_r_binary_models, max_r_multi_models, label_encoder, label_encoder_max_r, regular_model_details, unique_criteria = read_models(model_dir)"
      ],
      "metadata": {
        "id": "KmJCK_AlaB1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Outputs"
      ],
      "metadata": {
        "id": "FzXOMK39WUjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_input = \"04:00\"  #@param {type:\"string\"}\n",
        "date_input = \"7/2/2025\"  #@param {type:\"string\"}\n",
        "criteria_input = \"ELC\"  #@param {type:\"string\"}\n",
        "CL = 1 #@param {type:\"integer\"}\n",
        "CW = 0 #@param {type:\"integer\"}\n",
        "\n",
        "model_names = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_names_max_r = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_keys = ['RF', 'XVG', 'LR', 'VC', 'S']\n",
        "\n",
        "print('...........................Average R Models...........................')\n",
        "print(regular_model_details)\n",
        "show_predictions(time_input, date_input, criteria_input,  CL, CW, training_feature_cols, model_names, model_keys, precomputed_stats=precomputed_stats,label_encoder=label_encoder, b_models=regular_binary_models, m_models=regular_multi_models, b_acc=regular_accuracies['Binary Accuracy'], m_acc=regular_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                 w_threshold=1)\n",
        "\n",
        "print('...........................Max R Models...........................')\n",
        "show_predictions(time_input, date_input, criteria_input, CL, CW, training_feature_cols, model_names_max_r, model_keys, precomputed_stats=precomputed_stats_max_r,label_encoder=label_encoder, b_models=max_r_binary_models, m_models=max_r_multi_models, b_acc=max_r_accuracies['Binary Accuracy'], m_acc=max_r_accuracies['Multi-Class (R Bucket) Accuracy'],\n",
        "                 Max_R=True, w_threshold=1)"
      ],
      "metadata": {
        "id": "V8tR2C5XEVh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overall Stats Dataframe"
      ],
      "metadata": {
        "id": "79fdmETLWW0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_stats_df = overall_stats(X_test_P, X_test, regular_models, training_feature_cols)\n",
        "print(\"\\nOverall Statistics for Trades Predicted as 'Win' by Each Model:\")\n",
        "overall_stats_df"
      ],
      "metadata": {
        "id": "XRaiPWtXUEbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_stats_df_max_r = overall_stats(X_test_P_max_r, X_test_max_r, max_r_models, training_feature_cols)\n",
        "print(\"\\nOverall Statistics for Trades Predicted as 'Win' by Each Model (Max_R):\")\n",
        "overall_stats_df_max_r"
      ],
      "metadata": {
        "id": "j_ViDAzKrEYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_stats_dir = 'saved_models/accuracies/overall_stats/'\n",
        "os.makedirs(overall_stats_dir, exist_ok=True)\n",
        "\n",
        "overall_stats_df.to_excel(os.path.join(overall_stats_dir, 'regular_overall_stats.xlsx'), index=False)\n",
        "print(f\"Saved overall stats DataFrame to {overall_stats_dir}regular_overall_stats.xlsx\")\n",
        "\n",
        "# Save the overall_stats_df_max_r\n",
        "overall_stats_df_max_r.to_excel(os.path.join(overall_stats_dir, 'max_r_overall_stats.xlsx'), index=False)\n",
        "print(f\"Saved Max R overall stats DataFrame to {overall_stats_dir}max_r_overall_stats.xlsx\")"
      ],
      "metadata": {
        "id": "VvwcKGjJKoiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confustion Matrics"
      ],
      "metadata": {
        "id": "vb5trDBgWvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# List of model names for the regular models\n",
        "model_names_regular = ['RandomForest', 'XGBoost', 'Logistic Regression', 'Voting Classifier', 'Stacking Classifier']\n",
        "model_names_multi_regular = ['RandomForest Multi', 'XGBoost Multi', 'Logistic Regression Multi', 'Voting Classifier Multi', 'Stacking Classifier Multi']\n",
        "model_names_max_r = ['RandomForest-Max R', 'XGBoost-Max R', 'Logistic Regression-Max R', 'Voting Classifier-Max R', 'Stacking Classifier-Max R']\n",
        "model_names_m_max_r = ['RandomForest Multi-Max R', 'XGBoost Multi-Max R', 'Logistic Regression Multi-Max R', 'Voting Classifier Multi-Max R', 'Stacking Classifier Multi-Max R']\n",
        "\n",
        "\n",
        "reg_fig = plot_confusion_matrices_horizontal(y_test, regular_binary_predictions, model_names_regular)\n",
        "reg_fig_m = plot_confusion_matrices_horizontal(y_test_enc, regular_multi_predictions, model_names_multi_regular, ticks=sorted(np.unique(y_test_enc)), multi=True)\n",
        "\n",
        "max_r_fig = plot_confusion_matrices_horizontal(y_test_max_r, regular_binary_predictions_max_r, model_names_max_r)\n",
        "max_r_m_fig = plot_confusion_matrices_horizontal(y_test_enc_max_r, regular_multi_predictions_max_r, model_names_m_max_r, ticks=sorted(np.unique(y_test_enc_max_r)), multi=True)\n"
      ],
      "metadata": {
        "id": "InJrnPlfW4p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = 'saved_models/accuracies/confusion_metrix/'\n",
        "os.makedirs(f'{output_dir}', exist_ok=True)\n",
        "\n",
        "reg_fig.savefig(f'{output_dir}regular_binary.png', bbox_inches='tight')\n",
        "plt.close(reg_fig)\n",
        "\n",
        "reg_fig_m.savefig(f'{output_dir}regular_multi.png', bbox_inches='tight')\n",
        "plt.close(reg_fig_m)\n",
        "\n",
        "max_r_fig.savefig(f'{output_dir}max_R_binary.png', bbox_inches='tight')\n",
        "plt.close(max_r_fig)\n",
        "max_r_m_fig.savefig(f'{output_dir}max_R_multi.png', bbox_inches='tight')\n",
        "plt.close(max_r_m_fig)\n",
        "\n",
        "print(f\"Confusion matrix figures saved to {output_dir}\")"
      ],
      "metadata": {
        "id": "_Lh-Ow1oGU-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download All Saved Files"
      ],
      "metadata": {
        "id": "wJzULtREWmiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download all files in save_models folder to my pc\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Specify the directory you want to download from\n",
        "directory_to_download = '/content/'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_to_download):\n",
        "    # Create a zip file of the directory\n",
        "    zip_filename = f\"SMC_{datetime.now(timezone.utc).strftime('%m_%d_%Y')}.zip\"\n",
        "    !zip -r {zip_filename} {directory_to_download}\n",
        "\n",
        "    # Download the zip file\n",
        "    files.download(zip_filename)\n",
        "else:\n",
        "    print(f\"Directory '{directory_to_download}' does not exist.\")"
      ],
      "metadata": {
        "id": "em7umUkvrCzh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}